{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","scrolled":true,"execution":{"iopub.status.busy":"2021-11-30T04:17:35.531195Z","iopub.execute_input":"2021-11-30T04:17:35.531530Z","iopub.status.idle":"2021-11-30T04:17:38.596331Z","shell.execute_reply.started":"2021-11-30T04:17:35.531453Z","shell.execute_reply":"2021-11-30T04:17:38.595651Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## **Business Understanding**\n\nBrain tumors in particular are very difficult to diagnose from an MRI image, and artificial intelligence methods of identifying and classifying tumors are oftentimes more accurate than manual identification by a radiologist. That is why the development of neural networks and other AI processes for tumor classification is so valuable and important.\n\nThe survival rate for patients diagnosed with a brain tumor is around 35%. This survival rate could be increased if tumors could be identified earlier and more accurately, which AI methods could help with. Additionally, in third world countries, seasoned neurosurgeons (a neurosurgeon is required to make the diagnoses from looking at the MRI) are hard to come by, so a machine learning tool (Decision Support Tool) which could accurately identify tumors would be of great value in these developing nations. This decision support tool would be beneficial to the health industry, and the target audience would be Doctors without Borders, an organization which sends doctors from the US to developing countries to help improve their healthcare. ","metadata":{}},{"cell_type":"code","source":"# Set random state for numpy operations\nfrom numpy.random import seed\nseed(42)\n# Set random state for tensorflow operations\nfrom tensorflow.random import set_seed\nset_seed(42)\n# General imports\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import regularizers\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.models import load_model\nimport seaborn as sns\nfrom mlxtend.plotting import plot_decision_regions\nfrom sklearn.metrics import confusion_matrix\nimport cv2\nimport PIL","metadata":{"execution":{"iopub.status.busy":"2021-11-30T04:44:18.268058Z","iopub.execute_input":"2021-11-30T04:44:18.268378Z","iopub.status.idle":"2021-11-30T04:44:18.303635Z","shell.execute_reply.started":"2021-11-30T04:44:18.268344Z","shell.execute_reply":"2021-11-30T04:44:18.303026Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"\ndef visualize_training_results(history):\n    '''\n    From https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/\n    \n    Input: keras history object (output from trained model)\n    '''\n    fig, (ax1, ax2) = plt.subplots(2, sharex=True)\n    fig.suptitle('Model Results')\n\n    # summarize history for accuracy\n    ax1.plot(history.history['acc'])\n    ax1.plot(history.history['val_acc'])\n    ax1.set_ylabel('Accuracy')\n    ax1.legend(['train', 'test'], loc='upper left')\n    # summarize history for loss\n    ax2.plot(history.history['loss'])\n    ax2.plot(history.history['val_loss'])\n    ax2.set_ylabel('Loss')\n    ax2.legend(['train', 'test'], loc='upper left')\n    \n    plt.xlabel('Epoch')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-30T04:17:53.920123Z","iopub.execute_input":"2021-11-30T04:17:53.920573Z","iopub.status.idle":"2021-11-30T04:17:53.927392Z","shell.execute_reply.started":"2021-11-30T04:17:53.920534Z","shell.execute_reply":"2021-11-30T04:17:53.926490Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Set up ImageDataGenerator\ntrain_imagegen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\n                                   zoom_range=([0.6,1]),\n                                   rotation_range=10,                           \n                                   brightness_range=([0.6, 1.5]),\n                                   horizontal_flip=True,\n                                   validation_split=0.06) # this will set aside a part of training set for validation data\ntest_imagegen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\n                                   zoom_range=([0.6,1]),\n                                   rotation_range=10,\n                                   brightness_range=([0.6,1.5]),\n                                   horizontal_flip=True)\n# Bring the data in\ntrain_generator = train_imagegen.flow_from_directory(\n                                    '../input/resortedbraintumorclassificationmridata/Brain_MRI_Tumor_Images/Training',\n                                    target_size=(200,200),\n                                    batch_size=20,\n                                    seed=42,\n                                    class_mode='binary',\n                                    subset='training')\n\ntest_generator = test_imagegen.flow_from_directory(\n                                    '../input/resortedbraintumorclassificationmridata/Brain_MRI_Tumor_Images/Testing',\n                                    target_size=(200,200),\n                                    batch_size=20,\n                                    seed=42,\n                                    class_mode='binary')\n\nval_generator = train_imagegen.flow_from_directory(\n                                    '../input/resortedbraintumorclassificationmridata/Brain_MRI_Tumor_Images/Training',\n                                    target_size=(200,200),\n                                    batch_size=20,\n                                    seed=42,\n                                    class_mode='binary',\n                                    subset='validation')","metadata":{"execution":{"iopub.status.busy":"2021-11-30T04:18:01.132872Z","iopub.execute_input":"2021-11-30T04:18:01.133436Z","iopub.status.idle":"2021-11-30T04:18:01.854846Z","shell.execute_reply.started":"2021-11-30T04:18:01.133395Z","shell.execute_reply":"2021-11-30T04:18:01.853811Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## **Data Understanding**","metadata":{}},{"cell_type":"code","source":"# Visualize (code from https://github.com/austint1121/OES-PneumoniaClassification/blob/main/Final_Notebook.ipynb)\ntrain_batch = train_generator.next()\nfig, axes = plt.subplots(2, 5, figsize=(16, 8))\n    \nfor i in range(10):\n    # Load image into numpy array and re-scale\n    img = np.array(train_batch[0][i] * 255, dtype='uint8')\n    ax = axes[i // 5, i % 5]\n    ax.imshow(img)\nfig.suptitle('Training Images')\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-29T15:24:57.897094Z","iopub.execute_input":"2021-11-29T15:24:57.897374Z","iopub.status.idle":"2021-11-29T15:24:59.557642Z","shell.execute_reply.started":"2021-11-29T15:24:57.897341Z","shell.execute_reply":"2021-11-29T15:24:59.55695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(10):\n    ax = axes[i // 5, i % 5]\n    for image, label in train_batch:\n        if label == 1:\n            ax.imshow(np.array(image[i] * 255, dtype='uint8'))\nfig.suptitle('No Tumor')\nplt.tight_layout()\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Taking a Look at a few different individual images**","metadata":{}},{"cell_type":"code","source":"tumor1 = PIL.Image.open('../input/resortedbraintumorclassificationmridata/Brain_MRI_Tumor_Images/Training/AllTumorsTrain/gg (108).jpg')\ntumor1","metadata":{"execution":{"iopub.status.busy":"2021-11-24T02:36:06.518695Z","iopub.execute_input":"2021-11-24T02:36:06.518991Z","iopub.status.idle":"2021-11-24T02:36:06.610621Z","shell.execute_reply.started":"2021-11-24T02:36:06.51896Z","shell.execute_reply":"2021-11-24T02:36:06.609107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Figuring out the number of color channels\ntumor1.mode","metadata":{"execution":{"iopub.status.busy":"2021-11-23T16:37:36.520784Z","iopub.execute_input":"2021-11-23T16:37:36.521099Z","iopub.status.idle":"2021-11-23T16:37:36.525967Z","shell.execute_reply.started":"2021-11-23T16:37:36.521067Z","shell.execute_reply":"2021-11-23T16:37:36.525224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Taking a look at the class imbalance**","metadata":{}},{"cell_type":"markdown","source":"First looking at training data imbalance","metadata":{}},{"cell_type":"code","source":"train_generator.class_indices","metadata":{"execution":{"iopub.status.busy":"2021-11-30T00:58:11.458798Z","iopub.execute_input":"2021-11-30T00:58:11.459065Z","iopub.status.idle":"2021-11-30T00:58:11.465070Z","shell.execute_reply.started":"2021-11-30T00:58:11.459037Z","shell.execute_reply":"2021-11-30T00:58:11.464105Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"train_generator.classes","metadata":{"execution":{"iopub.status.busy":"2021-11-30T00:58:07.628231Z","iopub.execute_input":"2021-11-30T00:58:07.628522Z","iopub.status.idle":"2021-11-30T00:58:07.637691Z","shell.execute_reply.started":"2021-11-30T00:58:07.628492Z","shell.execute_reply":"2021-11-30T00:58:07.636883Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"train_tumors = pd.DataFrame(train_generator.classes)\ntrain_values = train_tumors.value_counts()\ntrain_values","metadata":{"execution":{"iopub.status.busy":"2021-11-30T00:58:19.799957Z","iopub.execute_input":"2021-11-30T00:58:19.800292Z","iopub.status.idle":"2021-11-30T00:58:19.821679Z","shell.execute_reply.started":"2021-11-30T00:58:19.800255Z","shell.execute_reply":"2021-11-30T00:58:19.820229Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"The ratio of images with tumors to those without is 2327:372, or 6.255:1.","metadata":{}},{"cell_type":"code","source":"train_tumors.rename(columns={0:'Tumor/No Tumor'}, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-30T00:58:31.490057Z","iopub.execute_input":"2021-11-30T00:58:31.490305Z","iopub.status.idle":"2021-11-30T00:58:31.496325Z","shell.execute_reply.started":"2021-11-30T00:58:31.490278Z","shell.execute_reply":"2021-11-30T00:58:31.495637Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"train_tumors[train_tumors['Tumor/No Tumor'] == 0]","metadata":{"execution":{"iopub.status.busy":"2021-11-30T00:58:33.996289Z","iopub.execute_input":"2021-11-30T00:58:33.997008Z","iopub.status.idle":"2021-11-30T00:58:34.015899Z","shell.execute_reply.started":"2021-11-30T00:58:33.996966Z","shell.execute_reply":"2021-11-30T00:58:34.015225Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"train_no_tumor = len(train_tumors[train_tumors['Tumor/No Tumor'] == 1])\ntrain_tumor = len(train_tumors[train_tumors['Tumor/No Tumor'] == 0])","metadata":{"execution":{"iopub.status.busy":"2021-11-30T00:58:37.329543Z","iopub.execute_input":"2021-11-30T00:58:37.330399Z","iopub.status.idle":"2021-11-30T00:58:37.337149Z","shell.execute_reply.started":"2021-11-30T00:58:37.330347Z","shell.execute_reply":"2021-11-30T00:58:37.336338Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"#plt.figure(figsize=(10,6))\n#sns.set(font_scale=1.4)\n#sns.barplot(tumors.index, tumors.values)\n#plt.ylabel(\"Number of Images\")\n#plt.title('Distribution of Brain MRIs with and without Tumor');\n\nfig, ax = plt.subplots(figsize=(10,8))\nax.bar(x=['No Tumor', 'Tumor'],height = [train_no_tumor, train_tumor])\nax.set(xlabel='', ylabel='Number of Images', title='Distribution of Brain MRIs with and without Tumor');","metadata":{"execution":{"iopub.status.busy":"2021-11-30T00:58:41.460928Z","iopub.execute_input":"2021-11-30T00:58:41.461233Z","iopub.status.idle":"2021-11-30T00:58:41.714252Z","shell.execute_reply.started":"2021-11-30T00:58:41.461201Z","shell.execute_reply":"2021-11-30T00:58:41.713341Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"Now taking a look at the test data imbalance","metadata":{}},{"cell_type":"code","source":"test_tumors = pd.DataFrame(test_generator.classes)\ntest_values = test_tumors.value_counts()\ntest_values","metadata":{"execution":{"iopub.status.busy":"2021-11-24T18:35:29.054029Z","iopub.execute_input":"2021-11-24T18:35:29.0543Z","iopub.status.idle":"2021-11-24T18:35:29.071402Z","shell.execute_reply.started":"2021-11-24T18:35:29.054273Z","shell.execute_reply":"2021-11-24T18:35:29.07061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"the ratio of images with tumors to those without is 289:105, or 2.75:1","metadata":{}},{"cell_type":"code","source":"test_tumors.rename(columns={0:'Tumor/No Tumor'}, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T18:35:56.658726Z","iopub.execute_input":"2021-11-24T18:35:56.659424Z","iopub.status.idle":"2021-11-24T18:35:56.666481Z","shell.execute_reply.started":"2021-11-24T18:35:56.659386Z","shell.execute_reply":"2021-11-24T18:35:56.665507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_no_tumor = len(test_tumors[test_tumors['Tumor/No Tumor'] == 1])\ntest_tumor = len(test_tumors[test_tumors['Tumor/No Tumor'] == 0])","metadata":{"execution":{"iopub.status.busy":"2021-11-24T18:36:26.681854Z","iopub.execute_input":"2021-11-24T18:36:26.68212Z","iopub.status.idle":"2021-11-24T18:36:26.691224Z","shell.execute_reply.started":"2021-11-24T18:36:26.682091Z","shell.execute_reply":"2021-11-24T18:36:26.690093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfig, ax = plt.subplots(figsize=(10,8))\nax.bar(x=['No Tumor', 'Tumor'],height = [test_no_tumor, test_tumor])\nax.set(xlabel='', ylabel='Number of Images', title='Distribution of Brain MRIs with and without Tumor in Testing Data');","metadata":{"execution":{"iopub.status.busy":"2021-11-24T18:36:51.234446Z","iopub.execute_input":"2021-11-24T18:36:51.234704Z","iopub.status.idle":"2021-11-24T18:36:51.426277Z","shell.execute_reply.started":"2021-11-24T18:36:51.234676Z","shell.execute_reply":"2021-11-24T18:36:51.425541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Baseline CNN Model**","metadata":{}},{"cell_type":"code","source":"# Building the first baseline model; structure is modified from one shown on:\n# https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\nbaseline = keras.Sequential()\nbaseline.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(200,200,3)))\nbaseline.add(layers.MaxPooling2D(2,2))\nbaseline.add(layers.Conv2D(64, (3,3), activation='relu'))\nbaseline.add(layers.MaxPooling2D(2,2))\n\nbaseline.add(layers.Flatten())\nbaseline.add(layers.Dense(128, activation='relu'))\nbaseline.add(layers.Dense(1, activation='sigmoid'))\n\nbaseline.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])","metadata":{"execution":{"iopub.status.busy":"2021-11-24T02:45:33.336344Z","iopub.execute_input":"2021-11-24T02:45:33.33662Z","iopub.status.idle":"2021-11-24T02:45:33.407653Z","shell.execute_reply.started":"2021-11-24T02:45:33.336589Z","shell.execute_reply":"2021-11-24T02:45:33.406686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"baseline_results = baseline.fit_generator(train_generator,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=10,\n                                         validation_data=test_generator)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T02:45:36.641381Z","iopub.execute_input":"2021-11-24T02:45:36.642247Z","iopub.status.idle":"2021-11-24T02:52:53.595216Z","shell.execute_reply.started":"2021-11-24T02:45:36.642183Z","shell.execute_reply":"2021-11-24T02:52:53.594217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(baseline_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T02:53:36.320213Z","iopub.execute_input":"2021-11-24T02:53:36.320509Z","iopub.status.idle":"2021-11-24T02:53:36.675247Z","shell.execute_reply.started":"2021-11-24T02:53:36.320477Z","shell.execute_reply":"2021-11-24T02:53:36.674256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Analysis of Model**\n\nLooking at the above graphs, it is obvious that this first baseline cnn model is overfitting; accuracy for training data ends up at around 94%, whereas testing data ends up at around 65%. Additionally, the loss for testing data is fairly high; for training the loss ends up at 15%, and for testing it ends up at 69%. In the next model iteration, I will add another dense layer, which will hopefully help the model pick up on more patterns, and some dropout layers for a form of regularization.","metadata":{}},{"cell_type":"markdown","source":"## **Adding another Dense layer and Dropout layers**","metadata":{}},{"cell_type":"code","source":"# Adding another dense layer and a couple of dropout layers; structure is modified from one shown on:\n# https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\nnp.random.seed(42)\nlayers_drop = keras.Sequential()\nlayers_drop.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(200,200,3)))\nlayers_drop.add(layers.MaxPooling2D(2,2))\nlayers_drop.add(layers.Conv2D(64, (3,3), activation='relu'))\nlayers_drop.add(layers.MaxPooling2D(2,2))\n\nlayers_drop.add(layers.Flatten())\nlayers_drop.add(layers.Dense(128, activation='relu'))\nlayers_drop.add(layers.Dropout(0.3))\nlayers_drop.add(layers.Dense(64, activation='relu'))\nlayers_drop.add(layers.Dropout(0.3))\nlayers_drop.add(layers.Dense(1, activation='sigmoid'))\n\nlayers_drop.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])","metadata":{"execution":{"iopub.status.busy":"2021-11-24T02:54:28.093148Z","iopub.execute_input":"2021-11-24T02:54:28.093473Z","iopub.status.idle":"2021-11-24T02:54:28.179478Z","shell.execute_reply.started":"2021-11-24T02:54:28.093441Z","shell.execute_reply":"2021-11-24T02:54:28.178548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fitting the model\nlayers_drop_results = layers_drop.fit_generator(train_generator,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=10,\n                                         validation_data=test_generator)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T02:54:31.190723Z","iopub.execute_input":"2021-11-24T02:54:31.191013Z","iopub.status.idle":"2021-11-24T03:02:25.353712Z","shell.execute_reply.started":"2021-11-24T02:54:31.190981Z","shell.execute_reply":"2021-11-24T03:02:25.352707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(layers_drop_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T03:02:25.35707Z","iopub.execute_input":"2021-11-24T03:02:25.357721Z","iopub.status.idle":"2021-11-24T03:02:25.713956Z","shell.execute_reply.started":"2021-11-24T03:02:25.357652Z","shell.execute_reply":"2021-11-24T03:02:25.712924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Analysis of Model**\n\nIn this iteration, training accuracy ends up at 93%, and testing ends up at 73%, so the model is overfitting, but less so than the baseline model. As for loss, training loss is 14% and testing loss is 65%, which is not drastically different from the last model. Adding another layer and dropout layers helped decrease overfitting. In the next model iteration I am going to account for the class imabalance, and the added layer and dropout layers might perform better in this iteration.","metadata":{}},{"cell_type":"markdown","source":"## **Accounting for class imbalance**","metadata":{}},{"cell_type":"code","source":"# Accounting for class imbalance; structure is modified from one shown on:\n# https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\n\nclass_ld = keras.Sequential()\nclass_ld.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(200,200,3)))\nclass_ld.add(layers.MaxPooling2D(2,2))\nclass_ld.add(layers.Conv2D(64, (3,3), activation='relu'))\nclass_ld.add(layers.MaxPooling2D(2,2))\n\nclass_ld.add(layers.Flatten())\nclass_ld.add(layers.Dense(128, activation='relu'))\nclass_ld.add(layers.Dropout(0.3))\nclass_ld.add(layers.Dense(64, activation='relu'))\nclass_ld.add(layers.Dropout(0.3))\nclass_ld.add(layers.Dense(1, activation='sigmoid'))\n\nclass_ld.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])\nweights = {0: 1, # TUMOR\n          1:6.255} # NO TUMOR \n# there are 6.255 times as many images of MRIs with tumors than without","metadata":{"execution":{"iopub.status.busy":"2021-11-26T09:50:15.985361Z","iopub.execute_input":"2021-11-26T09:50:15.985895Z","iopub.status.idle":"2021-11-26T09:50:16.057161Z","shell.execute_reply.started":"2021-11-26T09:50:15.985855Z","shell.execute_reply":"2021-11-26T09:50:16.056473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fitting the model\nclass_ld_results = class_ld.fit_generator(train_generator,\n                                          class_weight=weights,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=10,\n                                         validation_data=test_generator)","metadata":{"execution":{"iopub.status.busy":"2021-11-26T09:50:21.032446Z","iopub.execute_input":"2021-11-26T09:50:21.033137Z","iopub.status.idle":"2021-11-26T09:57:13.911394Z","shell.execute_reply.started":"2021-11-26T09:50:21.033085Z","shell.execute_reply":"2021-11-26T09:57:13.910554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(class_ld_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T03:13:43.566832Z","iopub.execute_input":"2021-11-24T03:13:43.567244Z","iopub.status.idle":"2021-11-24T03:13:44.024906Z","shell.execute_reply.started":"2021-11-24T03:13:43.567184Z","shell.execute_reply":"2021-11-24T03:13:44.023198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Analysis of Model**\n\nIn this model iteration, training accuracy was about 89% and testing accuracy is about 57%, so the model is still overfitting compared to the last model. Loss for training is at around 51% and testing loss is around 99%. In terms of acuracy and loss, the model is doing worse than the previous model. However, recall has increased significantly, so it seems that adding class weights is beneficial to the model, even though it requires further tuning.","metadata":{}},{"cell_type":"markdown","source":"## **Adding another Convolution layer**","metadata":{}},{"cell_type":"code","source":"# Another Convolution layer; structure is modified from one shown on:\n# https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\nnp.random.seed(42)\nclass_con = keras.Sequential()\nclass_con.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(200,200,3)))\nclass_con.add(layers.MaxPooling2D(2,2))\nclass_con.add(layers.Conv2D(64, (3,3), activation='relu'))\nclass_con.add(layers.MaxPooling2D(2,2))\nclass_con.add(layers.Conv2D(128, (3,3), activation='relu'))\nclass_con.add(layers.MaxPooling2D(2,2))\n\nclass_con.add(layers.Flatten())\nclass_con.add(layers.Dense(128, activation='relu'))\nclass_con.add(layers.Dropout(0.3))\nclass_con.add(layers.Dense(64, activation='relu'))\nclass_con.add(layers.Dropout(0.3))\nclass_con.add(layers.Dense(1, activation='sigmoid'))\n\nclass_con.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])\nweights = {0: 1, \n          1:6.255}","metadata":{"execution":{"iopub.status.busy":"2021-11-24T03:14:05.878911Z","iopub.execute_input":"2021-11-24T03:14:05.879766Z","iopub.status.idle":"2021-11-24T03:14:06.063157Z","shell.execute_reply.started":"2021-11-24T03:14:05.879717Z","shell.execute_reply":"2021-11-24T03:14:06.062124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_con_results = class_con.fit_generator(train_generator,\n                                          class_weight=weights,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=10,\n                                         validation_data=test_generator)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T03:14:12.111234Z","iopub.execute_input":"2021-11-24T03:14:12.111527Z","iopub.status.idle":"2021-11-24T03:25:18.319845Z","shell.execute_reply.started":"2021-11-24T03:14:12.111496Z","shell.execute_reply":"2021-11-24T03:25:18.318546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(class_con_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T03:27:36.196Z","iopub.execute_input":"2021-11-24T03:27:36.19698Z","iopub.status.idle":"2021-11-24T03:27:36.549589Z","shell.execute_reply.started":"2021-11-24T03:27:36.19693Z","shell.execute_reply":"2021-11-24T03:27:36.548584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Analysis of Model**\n\nTraining accuracy is at 89% while testing accuracy is at 50%, so model is still overfitting, slightly worse than the previous model. Training loss is 50%, and testing loss is 93%; training loss is 50% and testing loss is 93%, which is similar to the loss values of the previous model. In the next model iteration, I will see if changing the dimensions of the pooling layer will improve the model.\n","metadata":{}},{"cell_type":"markdown","source":"## **Adjusting the Pooling Strategy**","metadata":{}},{"cell_type":"code","source":"# Another Convolution layer; structure is modified from one shown on:\n# https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\nclass_pool = keras.Sequential()\nclass_pool.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(200,200,3)))\nclass_pool.add(layers.MaxPooling2D(2,2))\nclass_pool.add(layers.Conv2D(64, (3,3), activation='relu'))\nclass_pool.add(layers.MaxPooling2D(3,3))\nclass_pool.add(layers.Conv2D(128, (3,3), activation='relu'))\nclass_pool.add(layers.MaxPooling2D(5,5))\n\nclass_pool.add(layers.Flatten())\nclass_pool.add(layers.Dense(128, activation='relu'))\nclass_pool.add(layers.Dropout(0.3))\nclass_pool.add(layers.Dense(64, activation='relu'))\nclass_pool.add(layers.Dropout(0.3))\nclass_pool.add(layers.Dense(1, activation='sigmoid'))\n\nclass_pool.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])\nweights = {0: 1, # TUMOR\n          1:6.255} # NO TUMOR\n# there are 6.255 times as many images of MRIs with tumors than without","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:24:02.186653Z","iopub.execute_input":"2021-11-24T15:24:02.187103Z","iopub.status.idle":"2021-11-24T15:24:02.264486Z","shell.execute_reply.started":"2021-11-24T15:24:02.187067Z","shell.execute_reply":"2021-11-24T15:24:02.263742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_pool_results = class_pool.fit_generator(train_generator,\n                                          class_weight=weights,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=10,\n                                         validation_data=test_generator)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:24:08.574651Z","iopub.execute_input":"2021-11-24T15:24:08.574914Z","iopub.status.idle":"2021-11-24T15:31:30.586701Z","shell.execute_reply.started":"2021-11-24T15:24:08.574885Z","shell.execute_reply":"2021-11-24T15:31:30.585989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(class_pool_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:32:11.71962Z","iopub.execute_input":"2021-11-24T15:32:11.719903Z","iopub.status.idle":"2021-11-24T15:32:12.00353Z","shell.execute_reply.started":"2021-11-24T15:32:11.719871Z","shell.execute_reply":"2021-11-24T15:32:12.002842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Analysis of Model**\n\nTraining accuracy is at about 89%, and testing accuracy is at about 48%, so model is still overfitting quite a bit. Training loss is 48%, and testing loss is 101%; testing loss has increased quite a lot since the last model. Maybe increasing the pooling matrix is not beneficial to the model,so I will return the pooling strategy to all be (2,2) matrices and introduce padding, as this may help.. In this next model, I will introduce some padding to reduce image loss, to see if this improves model.","metadata":{}},{"cell_type":"markdown","source":"## **Model with Padding**","metadata":{}},{"cell_type":"code","source":"# Another Convolution layer; structure is modified from one shown on:\n# https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\nnp.random.seed(42)\nclass_pad = keras.Sequential()\nclass_pad.add(layers.Conv2D(32, (3,3), activation='relu', padding='same', input_shape=(200,200,3)))\nclass_pad.add(layers.MaxPooling2D(2,2))\nclass_pad.add(layers.Conv2D(64, (3,3), activation='relu', padding='same'))\nclass_pad.add(layers.MaxPooling2D(2,2))\nclass_pad.add(layers.Conv2D(128, (3,3), activation='relu', padding='same'))\nclass_pad.add(layers.MaxPooling2D(2,2))\n\nclass_pad.add(layers.Flatten())\nclass_pad.add(layers.Dense(128, activation='relu'))\nclass_pad.add(layers.Dropout(0.3))\nclass_pad.add(layers.Dense(64, activation='relu'))\nclass_pad.add(layers.Dropout(0.3))\nclass_pad.add(layers.Dense(1, activation='sigmoid'))\n\nclass_pad.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])\nweights = {0: 1, # TUMOR\n          1:6.255} # NO TUMOR\n# there are 6.255 times as many images of MRIs with tumors than without","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:32:31.33241Z","iopub.execute_input":"2021-11-24T15:32:31.332959Z","iopub.status.idle":"2021-11-24T15:32:31.408883Z","shell.execute_reply.started":"2021-11-24T15:32:31.332915Z","shell.execute_reply":"2021-11-24T15:32:31.408165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stop = [EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n            ModelCheckpoint(filepath='best_model.h5', monitor='val_loss',\n                           save_best_only=True)]","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:32:35.347465Z","iopub.execute_input":"2021-11-24T15:32:35.347722Z","iopub.status.idle":"2021-11-24T15:32:35.352267Z","shell.execute_reply.started":"2021-11-24T15:32:35.347693Z","shell.execute_reply":"2021-11-24T15:32:35.351054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_pad_results = class_pad.fit_generator(train_generator,\n                                          class_weight=weights,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=10,\n                                         validation_data=test_generator)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-11-24T15:32:53.418499Z","iopub.execute_input":"2021-11-24T15:32:53.419181Z","iopub.status.idle":"2021-11-24T15:39:39.820639Z","shell.execute_reply.started":"2021-11-24T15:32:53.419142Z","shell.execute_reply":"2021-11-24T15:39:39.81988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(class_pad_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:40:34.568115Z","iopub.execute_input":"2021-11-24T15:40:34.568831Z","iopub.status.idle":"2021-11-24T15:40:34.8518Z","shell.execute_reply.started":"2021-11-24T15:40:34.56879Z","shell.execute_reply":"2021-11-24T15:40:34.851097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Analysis of Model**\n\nTraining accuracy is 89%, testing accuracy is 40%, so the model is overfitting more so than in the \"Adding another Convolutional layer\" model, which is identical to this one excpet for the padding. Training loss is 50% and testing loss is 129%; testing loss increased significantly from the \"Adding another Convolutional Layer\" model. It looks like this strategy of padding is making the model worse, so I will remove it. Additionally, because loss is a big problem, I am going to try decreasing network size and increasing dropout layers.","metadata":{}},{"cell_type":"markdown","source":"## **Model without Padding, a deleted Dense layer, Early Stopping, and more Epochs**","metadata":{}},{"cell_type":"code","source":"# Another Convolution layer; structure is modified from one shown on:\n# https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\nclass_ee = keras.Sequential()\nclass_ee.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(200,200,3)))\nclass_ee.add(layers.MaxPooling2D(2,2))\nclass_ee.add(layers.Conv2D(64, (3,3), activation='relu'))\nclass_ee.add(layers.MaxPooling2D(2,2))\nclass_ee.add(layers.Conv2D(128, (3,3), activation='relu'))\nclass_ee.add(layers.MaxPooling2D(2,2))\n\nclass_ee.add(layers.Flatten())\nclass_ee.add(layers.Dense(128, activation='relu'))\nclass_ee.add(layers.Dropout(0.3))\nclass_ee.add(layers.Dense(1, activation='sigmoid'))\n\nclass_ee.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])\nweights = {0: 1, # TUMOR\n          1:6.255} # NO TUMOR\n# there are 6.255 times as many images of MRIs with tumors than without","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:49:18.106011Z","iopub.execute_input":"2021-11-24T15:49:18.106705Z","iopub.status.idle":"2021-11-24T15:49:18.176293Z","shell.execute_reply.started":"2021-11-24T15:49:18.106666Z","shell.execute_reply":"2021-11-24T15:49:18.175564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stop2 = [EarlyStopping(monitor='val_loss', patience=12, restore_best_weights=True),\n            ModelCheckpoint(filepath='best_model.h5', monitor='val_loss',\n                           save_best_only=True)]","metadata":{"execution":{"iopub.status.busy":"2021-11-30T04:18:20.031726Z","iopub.execute_input":"2021-11-30T04:18:20.032041Z","iopub.status.idle":"2021-11-30T04:18:20.036290Z","shell.execute_reply.started":"2021-11-30T04:18:20.031982Z","shell.execute_reply":"2021-11-30T04:18:20.035352Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class_ee_results = class_ee.fit_generator(train_generator,\n                                          class_weight=weights,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=50,\n                                         validation_data=test_generator)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:49:24.335841Z","iopub.execute_input":"2021-11-24T15:49:24.336092Z","iopub.status.idle":"2021-11-24T15:54:51.330888Z","shell.execute_reply.started":"2021-11-24T15:49:24.336062Z","shell.execute_reply":"2021-11-24T15:54:51.330009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(class_ee_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:56:15.911933Z","iopub.execute_input":"2021-11-24T15:56:15.912213Z","iopub.status.idle":"2021-11-24T15:56:16.212917Z","shell.execute_reply.started":"2021-11-24T15:56:15.912184Z","shell.execute_reply":"2021-11-24T15:56:16.212124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Analysis of Model**\n\nTraining accuracy of the best epoch (epoch4) is around 88%, and testing accuracy is around 50%. Training loss is around 60% and testing loss is around 113%. Testing accuracy has improved by 10% since the last model, and testing loss has decreased by about sixteen percentage points, so removing a dense layer seems to be a slight improvement. I will try batch normalization to see if this helps train the model faster.","metadata":{}},{"cell_type":"markdown","source":"## **Model with Batch Normalization** ","metadata":{}},{"cell_type":"code","source":"# Another Convolution layer; structure is modified from one shown on:\n# https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\nclass_n = keras.Sequential()\nclass_n.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(200,200,3)))\nclass_n.add(layers.BatchNormalization())\nclass_n.add(layers.MaxPooling2D(2,2))\nclass_n.add(layers.Conv2D(64, (3,3), activation='relu'))\nclass_n.add(layers.BatchNormalization())\nclass_n.add(layers.MaxPooling2D(2,2))\nclass_n.add(layers.Conv2D(128, (3,3), activation='relu'))\nclass_n.add(layers.BatchNormalization())\nclass_n.add(layers.MaxPooling2D(2,2))\n\nclass_n.add(layers.Flatten())\nclass_n.add(layers.Dense(128, activation='relu'))\nclass_n.add(layers.Dropout(0.3))\nclass_n.add(layers.Dense(1, activation='sigmoid'))\n\nclass_n.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])\nweights = {0: 1, # TUMOR\n          1:6.255} # NO TUMOR\n# there are 6.255 times as many images of MRIs with tumors than without","metadata":{"execution":{"iopub.status.busy":"2021-11-24T16:05:30.443029Z","iopub.execute_input":"2021-11-24T16:05:30.443316Z","iopub.status.idle":"2021-11-24T16:05:30.831081Z","shell.execute_reply.started":"2021-11-24T16:05:30.443284Z","shell.execute_reply":"2021-11-24T16:05:30.830285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_n_results = class_n.fit_generator(train_generator,\n                                          class_weight=weights,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=20,\n                                         callbacks=early_stop2,\n                                         validation_data=test_generator)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T16:41:12.069124Z","iopub.execute_input":"2021-11-24T16:41:12.069453Z","iopub.status.idle":"2021-11-24T16:55:23.585424Z","shell.execute_reply.started":"2021-11-24T16:41:12.069417Z","shell.execute_reply":"2021-11-24T16:55:23.584724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(class_n_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T16:55:43.00109Z","iopub.execute_input":"2021-11-24T16:55:43.001723Z","iopub.status.idle":"2021-11-24T16:55:43.297814Z","shell.execute_reply.started":"2021-11-24T16:55:43.001684Z","shell.execute_reply":"2021-11-24T16:55:43.297117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The best model from epoch 14 had a training accuracy of around 94%, a testing accuracy of around 70%, a training loss of 30%, and a testing loss of around 84%. Accuracy and loss for both training and testing data is much improved since the last model and it is less overfit, so batch normalization is definitely an improvement. \nBecause batch normalization makes the network more stable, it is possible to use larger learning rates, which could potentially help the model reach optimal accuracy and minimal loss more quickly, so that is what I will try next.","metadata":{}},{"cell_type":"markdown","source":"## **Using a Bigger Learning Rate since I am using Batch Normalization**","metadata":{}},{"cell_type":"code","source":"adam_mlr = keras.optimizers.Adam(epsilon=0.01)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T20:35:11.092629Z","iopub.execute_input":"2021-11-24T20:35:11.092904Z","iopub.status.idle":"2021-11-24T20:35:11.09773Z","shell.execute_reply.started":"2021-11-24T20:35:11.092873Z","shell.execute_reply":"2021-11-24T20:35:11.096463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Another Convolution layer; structure is modified from one shown on:\n# https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\nclass_na = keras.Sequential()\nclass_na.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(200,200,3)))\nclass_na.add(layers.BatchNormalization())\nclass_na.add(layers.MaxPooling2D(2,2))\nclass_na.add(layers.Conv2D(64, (3,3), activation='relu'))\nclass_na.add(layers.BatchNormalization())\nclass_na.add(layers.MaxPooling2D(2,2))\nclass_na.add(layers.Conv2D(128, (3,3), activation='relu'))\nclass_na.add(layers.BatchNormalization())\nclass_na.add(layers.MaxPooling2D(2,2))\n\nclass_na.add(layers.Flatten())\nclass_na.add(layers.Dense(128, activation='relu'))\nclass_na.add(layers.Dropout(0.3))\nclass_na.add(layers.Dense(1, activation='sigmoid'))\n\nclass_na.compile(loss='binary_crossentropy',\n                optimizer=adam_mlr,\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])\nweights = {0: 1, # TUMOR\n          1:6.255} # NO TUMOR\n# there are 6.255 times as many images of MRIs with tumors than without","metadata":{"execution":{"iopub.status.busy":"2021-11-24T20:37:38.586941Z","iopub.execute_input":"2021-11-24T20:37:38.587241Z","iopub.status.idle":"2021-11-24T20:38:27.859592Z","shell.execute_reply.started":"2021-11-24T20:37:38.587208Z","shell.execute_reply":"2021-11-24T20:38:27.858869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_na_results = class_na.fit_generator(train_generator,\n                                          class_weight=weights,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=20,\n                                         callbacks=early_stop2,\n                                         validation_data=test_generator)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T20:38:32.583159Z","iopub.execute_input":"2021-11-24T20:38:32.584003Z","iopub.status.idle":"2021-11-24T20:58:02.248221Z","shell.execute_reply.started":"2021-11-24T20:38:32.583948Z","shell.execute_reply":"2021-11-24T20:58:02.247411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(class_na_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T20:59:06.074505Z","iopub.execute_input":"2021-11-24T20:59:06.074784Z","iopub.status.idle":"2021-11-24T20:59:06.404638Z","shell.execute_reply.started":"2021-11-24T20:59:06.074756Z","shell.execute_reply":"2021-11-24T20:59:06.403949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the best epoch of the model (epoch 20) training accuracy is 95% while testing accuracy is 74%. Training loss is 33%, while testing loss is 55%. Testing accuracy is higher by four percentage points than the last model, and loss has decreased by about 30%! Additionally, testing recall is 93%, which is important for the context of this problem. Since the last epoch was the best, it might be that the model has not yet reached optimal accuracy and minimal loss, so I am going to increase the number of epochs in the next model iteration.","metadata":{}},{"cell_type":"markdown","source":"## **Model with Batch Normalization, bigger learning rate, and more Epochs**","metadata":{}},{"cell_type":"code","source":"# Another Convolution layer; structure is modified from one shown on:\n# https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\nclass_nae = keras.Sequential()\nclass_nae.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(200,200,3)))\nclass_nae.add(layers.BatchNormalization())\nclass_nae.add(layers.MaxPooling2D(2,2))\nclass_nae.add(layers.Conv2D(64, (3,3), activation='relu'))\nclass_nae.add(layers.BatchNormalization())\nclass_nae.add(layers.MaxPooling2D(2,2))\nclass_nae.add(layers.Conv2D(128, (3,3), activation='relu'))\nclass_nae.add(layers.BatchNormalization())\nclass_nae.add(layers.MaxPooling2D(2,2))\n\nclass_nae.add(layers.Flatten())\nclass_nae.add(layers.Dense(128, activation='relu'))\nclass_nae.add(layers.Dropout(0.3))\nclass_nae.add(layers.Dense(1, activation='sigmoid'))\n\nclass_nae.compile(loss='binary_crossentropy',\n                optimizer=adam_mlr,\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])\nweights = {0: 1, # TUMOR\n          1:6.255} # NO TUMOR\n# there are 6.255 times as many images of MRIs with tumors than without","metadata":{"execution":{"iopub.status.busy":"2021-11-24T21:02:11.067909Z","iopub.execute_input":"2021-11-24T21:02:11.068417Z","iopub.status.idle":"2021-11-24T21:02:11.169888Z","shell.execute_reply.started":"2021-11-24T21:02:11.06838Z","shell.execute_reply":"2021-11-24T21:02:11.168969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_nae_results = class_nae.fit_generator(train_generator,\n                                          class_weight=weights,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=50,\n                                         callbacks=early_stop2,\n                                         validation_data=test_generator)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T21:02:58.392174Z","iopub.execute_input":"2021-11-24T21:02:58.392426Z","iopub.status.idle":"2021-11-24T21:33:45.998534Z","shell.execute_reply.started":"2021-11-24T21:02:58.392395Z","shell.execute_reply":"2021-11-24T21:33:45.997842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(class_nae_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T21:42:39.777787Z","iopub.execute_input":"2021-11-24T21:42:39.778071Z","iopub.status.idle":"2021-11-24T21:43:27.489562Z","shell.execute_reply.started":"2021-11-24T21:42:39.778042Z","shell.execute_reply":"2021-11-24T21:43:27.488863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Model with Batch Normalization and more Dropout Layers**","metadata":{}},{"cell_type":"code","source":"# Another Convolution layer; structure is modified from one shown on:\n# https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\nclass_nd = keras.Sequential()\n\nclass_nd.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(200,200,3)))\nclass_nd.add(layers.BatchNormalization())\nclass_nd.add(layers.MaxPooling2D(2,2))\nclass_nd.add(layers.Dropout(0.25))\n\nclass_nd.add(layers.Conv2D(64, (3,3), activation='relu'))\nclass_nd.add(layers.BatchNormalization())\nclass_nd.add(layers.MaxPooling2D(2,2))\nclass_nd.add(layers.Dropout(0.25))\n\nclass_nd.add(layers.Conv2D(128, (3,3), activation='relu'))\nclass_nd.add(layers.BatchNormalization())\nclass_nd.add(layers.MaxPooling2D(2,2))\nclass_nd.add(layers.Dropout(0.25))\n\nclass_nd.add(layers.Flatten())\nclass_nd.add(layers.Dense(128, activation='relu'))\nclass_nd.add(layers.Dropout(0.4))\nclass_nd.add(layers.Dense(1, activation='sigmoid'))\n\nclass_nd.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])\nweights = {0: 1, # TUMOR\n          1:6.255} # NO TUMOR\n# there are 6.255 times as many images of MRIs with tumors than without","metadata":{"execution":{"iopub.status.busy":"2021-11-24T18:13:21.068639Z","iopub.execute_input":"2021-11-24T18:13:21.069188Z","iopub.status.idle":"2021-11-24T18:13:21.173025Z","shell.execute_reply.started":"2021-11-24T18:13:21.06915Z","shell.execute_reply":"2021-11-24T18:13:21.172321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_nd_results = class_nd.fit_generator(train_generator,\n                                          class_weight=weights,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=20,\n                                          callbacks=early_stop2,\n                                         validation_data=test_generator)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T16:56:31.74861Z","iopub.execute_input":"2021-11-24T16:56:31.748868Z","iopub.status.idle":"2021-11-24T17:05:06.030348Z","shell.execute_reply.started":"2021-11-24T16:56:31.748838Z","shell.execute_reply":"2021-11-24T17:05:06.029565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(class_nd_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T19:12:36.682836Z","iopub.execute_input":"2021-11-24T19:12:36.683404Z","iopub.status.idle":"2021-11-24T19:12:36.705413Z","shell.execute_reply.started":"2021-11-24T19:12:36.683362Z","shell.execute_reply":"2021-11-24T19:12:36.704411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Training accuracy of the best epoch (epoch 1) is 91% while testing accuracy is 73%. Training loss is 56% while testing loss is 82%. This model is similar to the last one, except for the fact that training loss is significantly increased. The dropout layers added after each max pooling step may not be particularly beneficial to the model.","metadata":{}},{"cell_type":"markdown","source":"## **Going Back to Baseline, but adding Batch Normalization Layers**","metadata":{}},{"cell_type":"code","source":"# Building the first baseline model; structure is modified from one shown on:\n# https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\nbaseline_n = keras.Sequential()\nbaseline_n.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(200,200,3)))\nbaseline_n.add(layers.BatchNormalization())\nbaseline_n.add(layers.MaxPooling2D(2,2))\n\nbaseline_n.add(layers.Conv2D(64, (3,3), activation='relu'))\nbaseline_n.add(layers.BatchNormalization())\nbaseline_n.add(layers.MaxPooling2D(2,2))\n\nbaseline_n.add(layers.Flatten())\nbaseline_n.add(layers.Dense(128, activation='relu'))\nbaseline_n.add(layers.BatchNormalization())\nbaseline_n.add(layers.Dense(1, activation='sigmoid'))\n\nbaseline_n.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])","metadata":{"execution":{"iopub.status.busy":"2021-11-26T20:45:06.604785Z","iopub.execute_input":"2021-11-26T20:45:06.605114Z","iopub.status.idle":"2021-11-26T20:45:09.657872Z","shell.execute_reply.started":"2021-11-26T20:45:06.605081Z","shell.execute_reply":"2021-11-26T20:45:09.655924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"baseline_n_results = baseline_n.fit_generator(train_generator,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=20,\n                                        callbacks=early_stop2,\n                                         validation_data=test_generator)","metadata":{"execution":{"iopub.status.busy":"2021-11-26T20:45:13.320817Z","iopub.execute_input":"2021-11-26T20:45:13.321139Z","iopub.status.idle":"2021-11-26T21:00:34.306331Z","shell.execute_reply.started":"2021-11-26T20:45:13.321106Z","shell.execute_reply":"2021-11-26T21:00:34.305325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(baseline_n_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-26T21:10:51.512747Z","iopub.execute_input":"2021-11-26T21:10:51.5131Z","iopub.status.idle":"2021-11-26T21:10:51.891166Z","shell.execute_reply.started":"2021-11-26T21:10:51.513067Z","shell.execute_reply":"2021-11-26T21:10:51.890211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Getting the predicted labels for all images in testing data\nbaseline_n_pred = baseline_n.predict(test_generator)\nlen(baseline_n_pred)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-11-26T21:11:02.067353Z","iopub.execute_input":"2021-11-26T21:11:02.067707Z","iopub.status.idle":"2021-11-26T21:11:07.267239Z","shell.execute_reply.started":"2021-11-26T21:11:02.067661Z","shell.execute_reply":"2021-11-26T21:11:07.266256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Rounding the predictions and making sure all values are integer type so that they can be directly compared to the true labels, which are all ints\nbase_npred_round = np.round(baseline_n_pred)\nnpred_int = []\nfor entry in base_npred_round:\n    npred_int.append(int(entry))\nnpred_int","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-11-26T09:17:08.969587Z","iopub.execute_input":"2021-11-26T09:17:08.970185Z","iopub.status.idle":"2021-11-26T09:17:08.988228Z","shell.execute_reply.started":"2021-11-26T09:17:08.970137Z","shell.execute_reply":"2021-11-26T09:17:08.987532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Looking at true labels\ntest_generator.classes","metadata":{"execution":{"iopub.status.busy":"2021-11-26T09:13:10.584739Z","iopub.execute_input":"2021-11-26T09:13:10.585145Z","iopub.status.idle":"2021-11-26T09:13:10.591006Z","shell.execute_reply.started":"2021-11-26T09:13:10.585111Z","shell.execute_reply":"2021-11-26T09:13:10.590368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# I want to find out all of the indices of the incorrectly classified images, as well as their label\nwrong_index = []\nwrong_entry = []\nfor index, entry in enumerate(npred_int):\n    if entry != test_generator.classes[index]:\n        wrong_index.append(index)\n        wrong_entry.append(entry)\nwrong_index_entry = list(zip(wrong_index, wrong_entry))","metadata":{"execution":{"iopub.status.busy":"2021-11-26T22:03:59.328834Z","iopub.execute_input":"2021-11-26T22:03:59.329199Z","iopub.status.idle":"2021-11-26T22:03:59.358381Z","shell.execute_reply.started":"2021-11-26T22:03:59.329154Z","shell.execute_reply":"2021-11-26T22:03:59.356676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Getting a list of all file names of incorrectly classified tumors, so that I can view the images\nfnames = test_generator.filenames \nwrong_fnames = []\nfor i in wrong_index:\n    wrong_fnames.append(fnames[i])\nwrong_fnames","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-11-26T09:28:41.651268Z","iopub.execute_input":"2021-11-26T09:28:41.651964Z","iopub.status.idle":"2021-11-26T09:28:41.661439Z","shell.execute_reply.started":"2021-11-26T09:28:41.651921Z","shell.execute_reply":"2021-11-26T09:28:41.660575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Getting the predicted labels for all images in testing data\nbaseline_n_pred = baseline_n.predict(test_generator)\nlen(baseline_n_pred)\n\n# Rounding the predictions and making sure all values are integer type so that they can be directly compared to the true labels, which are all ints\nbase_npred_round = np.round(baseline_n_pred)\nnpred_int = []\nfor entry in base_npred_round:\n    npred_int.append(int(entry))\nnpred_int\n\n# Looking at true labels\ntest_generator.classes\n\n# I want to find out all of the indices of the incorrectly classified images, as well as their label\nwrong_index = []\nwrong_entry = []\nfor index, entry in enumerate(npred_int):\n    if entry != test_generator.classes[index]:\n        wrong_index.append(index)\n        wrong_entry.append(entry)\nwrong_index_entry = list(zip(wrong_index, wrong_entry))\n\n# Getting a list of all file names of incorrectly classified tumors, so that I can view the images\nfnames = test_generator.filenames \nwrong_fnames = []\nfor i in wrong_index:\n    wrong_fnames.append(fnames[i])\nwrong_fnames\n\n# A Glioma the network mislabelled as not having a tumor\nPIL.Image.open('../input/resortedbraintumorclassificationmridata/Brain_MRI_Tumor_Images/Testing/AllTumorsTest/Glioma14.jpg')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# A Glioma the network mislabelled as not having a tumor\nPIL.Image.open('../input/resortedbraintumorclassificationmridata/Brain_MRI_Tumor_Images/Testing/AllTumorsTest/Glioma14.jpg')","metadata":{"execution":{"iopub.status.busy":"2021-11-26T09:25:14.141862Z","iopub.execute_input":"2021-11-26T09:25:14.142606Z","iopub.status.idle":"2021-11-26T09:25:14.196823Z","shell.execute_reply.started":"2021-11-26T09:25:14.142567Z","shell.execute_reply":"2021-11-26T09:25:14.196122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# A Glioma the network mislabelled as not having a tumor\nPIL.Image.open('../input/resortedbraintumorclassificationmridata/Brain_MRI_Tumor_Images/Testing/AllTumorsTest/Glioma2.jpg')","metadata":{"execution":{"iopub.status.busy":"2021-11-26T09:36:41.928684Z","iopub.execute_input":"2021-11-26T09:36:41.929134Z","iopub.status.idle":"2021-11-26T09:36:42.017869Z","shell.execute_reply.started":"2021-11-26T09:36:41.929094Z","shell.execute_reply":"2021-11-26T09:36:42.017153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# A Glioma the network mislabelled as not having a tumor\nPIL.Image.open('../input/resortedbraintumorclassificationmridata/Brain_MRI_Tumor_Images/Testing/AllTumorsTest/Glioma23.jpg')","metadata":{"execution":{"iopub.status.busy":"2021-11-26T09:37:24.266691Z","iopub.execute_input":"2021-11-26T09:37:24.267213Z","iopub.status.idle":"2021-11-26T09:37:24.342003Z","shell.execute_reply.started":"2021-11-26T09:37:24.267177Z","shell.execute_reply":"2021-11-26T09:37:24.341216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# A Meningioma the network mislabelled as not having a tumor\nPIL.Image.open('../input/resortedbraintumorclassificationmridata/Brain_MRI_Tumor_Images/Testing/AllTumorsTest/Meningioma10.jpg')","metadata":{"execution":{"iopub.status.busy":"2021-11-26T09:38:10.570886Z","iopub.execute_input":"2021-11-26T09:38:10.571155Z","iopub.status.idle":"2021-11-26T09:38:10.594268Z","shell.execute_reply.started":"2021-11-26T09:38:10.571114Z","shell.execute_reply":"2021-11-26T09:38:10.593601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# A Meningioma the network mislabelled as not having a tumor\nPIL.Image.open('../input/resortedbraintumorclassificationmridata/Brain_MRI_Tumor_Images/Testing/AllTumorsTest/Meningioma17.jpg')","metadata":{"execution":{"iopub.status.busy":"2021-11-26T09:38:48.959811Z","iopub.execute_input":"2021-11-26T09:38:48.960067Z","iopub.status.idle":"2021-11-26T09:38:48.983851Z","shell.execute_reply.started":"2021-11-26T09:38:48.960038Z","shell.execute_reply":"2021-11-26T09:38:48.983156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# A Meningioma the network correctly identified as having a tumor\nPIL.Image.open('../input/resortedbraintumorclassificationmridata/Brain_MRI_Tumor_Images/Testing/AllTumorsTest/Meningioma19.jpg')","metadata":{"execution":{"iopub.status.busy":"2021-11-26T09:40:06.562196Z","iopub.execute_input":"2021-11-26T09:40:06.563079Z","iopub.status.idle":"2021-11-26T09:40:06.585006Z","shell.execute_reply.started":"2021-11-26T09:40:06.563037Z","shell.execute_reply":"2021-11-26T09:40:06.584362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The best epoch of this model has a training accuracy of 93% and a testing accuracy of 80%. It has a training loss of 17% and a testing loss of 54%. This model has much better accuracy and much less loss than the last model, so adding batch normalization really helped.\n* look at epoch 10!","metadata":{}},{"cell_type":"markdown","source":"## **Going Back to Baseline, but adding Batch Normalization and a Dropout layer**","metadata":{}},{"cell_type":"code","source":"# Building the first baseline model; structure is modified from one shown on:\n# https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\nbaseline_nd = keras.Sequential()\nbaseline_nd.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(200,200,3)))\nbaseline_nd.add(layers.BatchNormalization())\nbaseline_nd.add(layers.MaxPooling2D(2,2))\n\nbaseline_nd.add(layers.Conv2D(64, (3,3), activation='relu'))\nbaseline_nd.add(layers.BatchNormalization())\nbaseline_nd.add(layers.MaxPooling2D(2,2))\n\nbaseline_nd.add(layers.Flatten())\nbaseline_nd.add(layers.Dense(128, activation='relu'))\nbaseline_nd.add(layers.Dropout(0.3))\nbaseline_nd.add(layers.BatchNormalization())\nbaseline_nd.add(layers.Dense(1, activation='sigmoid'))\n\nbaseline_nd.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])","metadata":{"execution":{"iopub.status.busy":"2021-11-24T18:19:34.322848Z","iopub.execute_input":"2021-11-24T18:19:34.323564Z","iopub.status.idle":"2021-11-24T18:19:34.408757Z","shell.execute_reply.started":"2021-11-24T18:19:34.323528Z","shell.execute_reply":"2021-11-24T18:19:34.408036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"baseline_nd_results = baseline_nd.fit_generator(train_generator,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=20,\n                                        callbacks=early_stop2,\n                                         validation_data=test_generator)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T18:19:38.541124Z","iopub.execute_input":"2021-11-24T18:19:38.541667Z","iopub.status.idle":"2021-11-24T18:33:28.949374Z","shell.execute_reply.started":"2021-11-24T18:19:38.541629Z","shell.execute_reply":"2021-11-24T18:33:28.948603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(baseline_nd_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T18:47:43.989569Z","iopub.execute_input":"2021-11-24T18:47:43.9902Z","iopub.status.idle":"2021-11-24T18:47:44.320407Z","shell.execute_reply.started":"2021-11-24T18:47:43.990159Z","shell.execute_reply":"2021-11-24T18:47:44.319676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The epoch with the best model (epoch 20) had a training accuracy of 94% and a testing accuracy of 76%. Training loss is 16% and testing loss is 54%.Testing accuracy is slightly less than the last model, so further tuning is necessary. Next I will try incorporating the class weights to account for the class imbalance.","metadata":{}},{"cell_type":"markdown","source":"## **Going back to Baseline, adding Class Weights**","metadata":{}},{"cell_type":"code","source":"\nbase_class = keras.Sequential()\nbase_class.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(200,200,3)))\nbase_class.add(layers.BatchNormalization())\nbase_class.add(layers.MaxPooling2D(2,2))\n\nbase_class.add(layers.Conv2D(64, (3,3), activation='relu'))\nbase_class.add(layers.BatchNormalization())\nbase_class.add(layers.MaxPooling2D(2,2))\n\nbase_class.add(layers.Flatten())\nbase_class.add(layers.Dense(128, activation='relu'))\nbase_class.add(layers.Dropout(0.3))\nbase_class.add(layers.BatchNormalization())\nbase_class.add(layers.Dense(1, activation='sigmoid'))\n\nbase_class.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])\nclass_weights2 = {0:1,\n                 1:6.255}","metadata":{"execution":{"iopub.status.busy":"2021-11-28T23:08:32.856289Z","iopub.execute_input":"2021-11-28T23:08:32.857127Z","iopub.status.idle":"2021-11-28T23:08:32.943995Z","shell.execute_reply.started":"2021-11-28T23:08:32.857073Z","shell.execute_reply":"2021-11-28T23:08:32.943304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_class_results =base_class.fit_generator(train_generator,\n                                        class_weight = class_weights2,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=20,\n                                        callbacks=early_stop2,\n                                         validation_data=test_generator)","metadata":{"execution":{"iopub.status.busy":"2021-11-28T23:08:55.839319Z","iopub.execute_input":"2021-11-28T23:08:55.839578Z","iopub.status.idle":"2021-11-28T23:18:15.455158Z","shell.execute_reply.started":"2021-11-28T23:08:55.839549Z","shell.execute_reply":"2021-11-28T23:18:15.45442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Analysis of Model**\n\nThe epoch with the lowest testing loss has a training accuracy of around 86% and a testing accuracy of around 62%, with a training loss of 55% and a testing loss of 76%. Testing recall is 76%. These results are worse than the last model iteration, so it looks like adding class weights did not help in this case.","metadata":{}},{"cell_type":"markdown","source":"## **Using the Pre-Trained VGG-19 Weights (this is my FSM and may be my Final Model!)**","metadata":{"execution":{"iopub.status.busy":"2021-11-24T20:11:41.921375Z","iopub.execute_input":"2021-11-24T20:11:41.921882Z","iopub.status.idle":"2021-11-24T20:11:41.943521Z","shell.execute_reply.started":"2021-11-24T20:11:41.92184Z","shell.execute_reply":"2021-11-24T20:11:41.942711Z"}}},{"cell_type":"code","source":"from keras.applications.vgg19 import VGG19\ncnn_vgg = VGG19(weights='imagenet',\n               include_top=False,\n               input_shape=(200,200,3))","metadata":{"execution":{"iopub.status.busy":"2021-11-30T04:18:34.772327Z","iopub.execute_input":"2021-11-30T04:18:34.772863Z","iopub.status.idle":"2021-11-30T04:18:38.107040Z","shell.execute_reply.started":"2021-11-30T04:18:34.772824Z","shell.execute_reply":"2021-11-30T04:18:38.106072Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"cnn_vgg.summary()\n","metadata":{"execution":{"iopub.status.busy":"2021-11-30T04:18:42.504976Z","iopub.execute_input":"2021-11-30T04:18:42.505259Z","iopub.status.idle":"2021-11-30T04:18:42.522456Z","shell.execute_reply.started":"2021-11-30T04:18:42.505230Z","shell.execute_reply":"2021-11-30T04:18:42.521617Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Build first model using pretrained VGG 19 as first layer, and then some dense layers on top\npretrained = keras.Sequential()\npretrained.add(cnn_vgg)\npretrained.add(layers.Flatten())\npretrained.add(layers.Dense(128, activation='relu'))\npretrained.add(layers.Dense(1, activation='sigmoid'))","metadata":{"execution":{"iopub.status.busy":"2021-11-30T00:59:25.806903Z","iopub.execute_input":"2021-11-30T00:59:25.807332Z","iopub.status.idle":"2021-11-30T00:59:26.145142Z","shell.execute_reply.started":"2021-11-30T00:59:25.807288Z","shell.execute_reply":"2021-11-30T00:59:26.144376Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"def Freeze_Pretrained_Base(pretrain, network):\n    pretrain.trainable = False\n    for layer in network.layers:\n        print(layer.name, layer.trainable)\n    print(len(network.trainable_weights))","metadata":{"execution":{"iopub.status.busy":"2021-11-30T04:18:49.599412Z","iopub.execute_input":"2021-11-30T04:18:49.599668Z","iopub.status.idle":"2021-11-30T04:18:49.604707Z","shell.execute_reply.started":"2021-11-30T04:18:49.599639Z","shell.execute_reply":"2021-11-30T04:18:49.604042Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"Freeze_Pretrained_Base(cnn_vgg, pretrained)","metadata":{"execution":{"iopub.status.busy":"2021-11-30T00:59:40.392030Z","iopub.execute_input":"2021-11-30T00:59:40.392283Z","iopub.status.idle":"2021-11-30T00:59:40.399368Z","shell.execute_reply.started":"2021-11-30T00:59:40.392255Z","shell.execute_reply":"2021-11-30T00:59:40.398240Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"\npretrained.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])\n\npretrained_results = pretrained.fit_generator(train_generator,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=20,\n                                        callbacks= early_stop2,\n                                         validation_data=test_generator)","metadata":{"execution":{"iopub.status.busy":"2021-11-30T00:59:46.050978Z","iopub.execute_input":"2021-11-30T00:59:46.051520Z","iopub.status.idle":"2021-11-30T01:04:44.507182Z","shell.execute_reply.started":"2021-11-30T00:59:46.051486Z","shell.execute_reply":"2021-11-30T01:04:44.504743Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(pretrained_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-26T22:24:37.259247Z","iopub.execute_input":"2021-11-26T22:24:37.259579Z","iopub.status.idle":"2021-11-26T22:24:37.647134Z","shell.execute_reply.started":"2021-11-26T22:24:37.259548Z","shell.execute_reply":"2021-11-26T22:24:37.646176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Analysis of Model**\nThe epoch with the lowest loss had a training accuracy of ~98% and a loss of ~4%, while the testing data had an accuracy of ~93% and a loss of ~21%! This is the best model yet! Additionally, testing recall is ~95%, which means that false negatives are being minimized. Using the VGG19 pretrained weights was a game changer! However, it would be great if the testing loss could be just a bit lower, so in the next model iteration I will use the SGD optimizer with momentum, since it is known for rapidly decreasing loss.","metadata":{}},{"cell_type":"markdown","source":"## **Unfreezing Layers in the Pretrained VGG-19 Network**","metadata":{}},{"cell_type":"code","source":"# Build first model using pretrained VGG 19 as first layer, and then some dense layers on top\nb5c1c2 = keras.Sequential()\nb5c1c2.add(cnn_vgg)\nb5c1c2.add(layers.Flatten())\nb5c1c2.add(layers.Dense(128, activation='relu'))\nb5c1c2.add(layers.Dense(1, activation='sigmoid'))","metadata":{"execution":{"iopub.status.busy":"2021-11-30T01:08:54.431012Z","iopub.execute_input":"2021-11-30T01:08:54.431267Z","iopub.status.idle":"2021-11-30T01:08:54.508865Z","shell.execute_reply.started":"2021-11-30T01:08:54.431238Z","shell.execute_reply":"2021-11-30T01:08:54.508158Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"unfreeze = ['block5_conv1', 'block5_conv2']","metadata":{"execution":{"iopub.status.busy":"2021-11-30T04:19:21.403534Z","iopub.execute_input":"2021-11-30T04:19:21.403791Z","iopub.status.idle":"2021-11-30T04:19:21.409063Z","shell.execute_reply.started":"2021-11-30T04:19:21.403763Z","shell.execute_reply":"2021-11-30T04:19:21.408084Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Re-freezing everything except for the last layer of the pretrained CNN\n# Code structure from https://github.com/learn-co-curriculum/dsc-using-pretrained-networks-codealong\ndef Unfreeze_Layers(pretrain, layer_list):\n    pretrain.trainable = True\n    for layer in  pretrain.layers:\n        if layer.name in layer_list:\n            layer.trainable = True\n        else:\n            layer.trainable = False\n        \n    for layer in pretrain.layers:\n        print(layer.name, layer.trainable)\n    print(len(pretrain.trainable_weights))","metadata":{"execution":{"iopub.status.busy":"2021-11-30T04:19:10.485012Z","iopub.execute_input":"2021-11-30T04:19:10.485702Z","iopub.status.idle":"2021-11-30T04:19:10.492605Z","shell.execute_reply.started":"2021-11-30T04:19:10.485664Z","shell.execute_reply":"2021-11-30T04:19:10.490118Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"Unfreeze_Layers(cnn_vgg, unfreeze)","metadata":{"execution":{"iopub.status.busy":"2021-11-30T04:19:23.962868Z","iopub.execute_input":"2021-11-30T04:19:23.963670Z","iopub.status.idle":"2021-11-30T04:19:23.977700Z","shell.execute_reply.started":"2021-11-30T04:19:23.963618Z","shell.execute_reply":"2021-11-30T04:19:23.976588Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"b5c1c2.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])\n\nb5c1c2_results = b5c1c2.fit_generator(train_generator,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=20,\n                                        callbacks= early_stop2,\n                                         validation_data=test_generator)","metadata":{"execution":{"iopub.status.busy":"2021-11-30T01:09:17.539772Z","iopub.execute_input":"2021-11-30T01:09:17.540564Z","iopub.status.idle":"2021-11-30T01:10:13.761025Z","shell.execute_reply.started":"2021-11-30T01:09:17.540518Z","shell.execute_reply":"2021-11-30T01:10:13.756730Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"**Analysis of Model**\n\nThe epoch with the lowest testing los has a trining accuracy of 98% and a testing accuracy of 92%, with a training loss of 5% and a testing loss of 27%. Testing recall is 75%. Other than recall, the results are similar to the previous model; maybe including class weights will help improve the model.","metadata":{}},{"cell_type":"code","source":"# Build first model using pretrained VGG 19 as first layer, and then some dense layers on top\nw_b5c1c2 = keras.Sequential()\nw_b5c1c2.add(cnn_vgg)\nw_b5c1c2.add(layers.Flatten())\nw_b5c1c2.add(layers.Dense(128, activation='relu'))\nw_b5c1c2.add(layers.Dense(1, activation='sigmoid'))","metadata":{"execution":{"iopub.status.busy":"2021-11-30T01:10:31.655333Z","iopub.execute_input":"2021-11-30T01:10:31.656093Z","iopub.status.idle":"2021-11-30T01:10:31.744496Z","shell.execute_reply.started":"2021-11-30T01:10:31.656056Z","shell.execute_reply":"2021-11-30T01:10:31.743743Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"\nweights = {0: 1, # TUMOR\n          1:6.255} # NO TUMOR \n# there are 6.255 times as many images of MRIs with tumors than without\n\n\nw_b5c1c2.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])\n\nw_b5c1c2_results = w_b5c1c2.fit_generator(train_generator,\n                                          class_weight = weights,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=20,\n                                        callbacks= early_stop2,\n                                         validation_data=test_generator)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-30T01:10:34.800025Z","iopub.execute_input":"2021-11-30T01:10:34.800965Z","iopub.status.idle":"2021-11-30T01:15:30.464979Z","shell.execute_reply.started":"2021-11-30T01:10:34.800915Z","shell.execute_reply":"2021-11-30T01:15:30.462589Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"**Analysis of Model**\n\nThe epoch with the lowest testing loss had a training accuracy of 98% and a testing accuracy of 94%, with a training loss of 7% and a testing loss of 22%. Testing recall 97%. Overall, because the recall is higher, this model is better than the first model iteration done using the pretrained VGG19 network.","metadata":{}},{"cell_type":"markdown","source":"## **Adjusting Class Weights and adding a Dropout Layer**","metadata":{}},{"cell_type":"code","source":"# Build first model using pretrained VGG 19 as first layer, and then some dense layers on top\nw2_b5c1c2 = keras.Sequential()\nw2_b5c1c2.add(cnn_vgg)\nw2_b5c1c2.add(layers.Dropout(0.4))\nw2_b5c1c2.add(layers.Flatten())\nw2_b5c1c2.add(layers.Dense(128, activation='relu'))\nw2_b5c1c2.add(layers.Dense(1, activation='sigmoid'))","metadata":{"execution":{"iopub.status.busy":"2021-11-30T04:19:42.362100Z","iopub.execute_input":"2021-11-30T04:19:42.362801Z","iopub.status.idle":"2021-11-30T04:19:42.448843Z","shell.execute_reply.started":"2021-11-30T04:19:42.362760Z","shell.execute_reply":"2021-11-30T04:19:42.448128Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"Freeze_Pretrained_Base(cnn_vgg, w2_b5c1c2 )","metadata":{"execution":{"iopub.status.busy":"2021-11-30T00:46:30.293239Z","iopub.execute_input":"2021-11-30T00:46:30.294195Z","iopub.status.idle":"2021-11-30T00:46:30.302413Z","shell.execute_reply.started":"2021-11-30T00:46:30.294148Z","shell.execute_reply":"2021-11-30T00:46:30.301460Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"Unfreeze_Layers(cnn_vgg, unfreeze)","metadata":{"execution":{"iopub.status.busy":"2021-11-30T00:46:50.649168Z","iopub.execute_input":"2021-11-30T00:46:50.649857Z","iopub.status.idle":"2021-11-30T00:46:50.663713Z","shell.execute_reply.started":"2021-11-30T00:46:50.649817Z","shell.execute_reply":"2021-11-30T00:46:50.662857Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"\nweights2 = {0: 1, # TUMOR\n          1:4} # NO TUMOR \n\n\n\nw2_b5c1c2.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])\n\nw2_b5c1c2_results = w2_b5c1c2.fit_generator(train_generator,\n                                          class_weight = weights2,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=20,\n                                        callbacks= early_stop2,\n                                         validation_data=test_generator)","metadata":{"execution":{"iopub.status.busy":"2021-11-30T04:44:49.081083Z","iopub.execute_input":"2021-11-30T04:44:49.082059Z","iopub.status.idle":"2021-11-30T05:00:44.362802Z","shell.execute_reply.started":"2021-11-30T04:44:49.082013Z","shell.execute_reply":"2021-11-30T05:00:44.362034Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"The epoch with the lowest testing loss has a training accuracy of 98% and a testing accuracy of 94%, with a training loss of 7% and a testing loss of 21%. Testing recall is 99%. This model is better than all iterations using VGG19 thus far, due to the high recall percentage in this epoch, as well as all epochs.","metadata":{}},{"cell_type":"markdown","source":"## **Unfreezing more layers of VGG-19 Base, including Adjusted Class Weights**","metadata":{}},{"cell_type":"code","source":"# Build first model using pretrained VGG 19 as first layer, and then some dense layers on top\nw2_b5c1c2 = keras.Sequential()\nw2_b5c1c2.add(cnn_vgg)\nw2_b5c1c2.add(layers.Dropout(0.4))\nw2_b5c1c2.add(layers.Flatten())\nw2_b5c1c2.add(layers.Dense(128, activation='relu'))\nw2_b5c1c2.add(layers.Dense(1, activation='sigmoid'))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Using the Pretrained VGG-19 network again, but with an SGD Optimizer**","metadata":{}},{"cell_type":"code","source":"# Build first model using pretrained VGG 19 as first layer, and then some dense layers on top\nvgg19_sgd = keras.Sequential()\nvgg19_sgd.add(cnn_vgg)\nvgg19_sgd.add(layers.Flatten())\nvgg19_sgd.add(layers.Dense(128, activation='relu'))\nvgg19_sgd.add(layers.Dense(1, activation='sigmoid'))","metadata":{"execution":{"iopub.status.busy":"2021-11-29T16:07:36.772058Z","iopub.execute_input":"2021-11-29T16:07:36.772323Z","iopub.status.idle":"2021-11-29T16:07:36.851006Z","shell.execute_reply.started":"2021-11-29T16:07:36.772281Z","shell.execute_reply":"2021-11-29T16:07:36.850169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make the pretrianed layer untrainable so that during optimization, its weights don't change\ncnn_vgg.trainable = False","metadata":{"execution":{"iopub.status.busy":"2021-11-28T21:57:30.618449Z","iopub.execute_input":"2021-11-28T21:57:30.619255Z","iopub.status.idle":"2021-11-28T21:57:30.624643Z","shell.execute_reply.started":"2021-11-28T21:57:30.619205Z","shell.execute_reply":"2021-11-28T21:57:30.623936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check to see that the pretrained layer is not trainable but that all others are\nfor layer in vgg19_sgd.layers:\n    print(layer.name, layer.trainable)\n    \nprint(len(vgg19_sgd.trainable_weights))","metadata":{"execution":{"iopub.status.busy":"2021-11-28T21:57:32.742766Z","iopub.execute_input":"2021-11-28T21:57:32.743383Z","iopub.status.idle":"2021-11-28T21:57:32.75018Z","shell.execute_reply.started":"2021-11-28T21:57:32.743342Z","shell.execute_reply":"2021-11-28T21:57:32.749121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sgd_momen = keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n\n\n\nvgg19_sgd.compile(loss='binary_crossentropy',\n                optimizer= sgd_momen,\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])\n\nvgg19_sgd_results = vgg19_sgd.fit_generator(train_generator,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=20,\n                                        callbacks= early_stop2,\n                                         validation_data=test_generator)","metadata":{"execution":{"iopub.status.busy":"2021-11-28T22:14:02.14284Z","iopub.execute_input":"2021-11-28T22:14:02.143511Z","iopub.status.idle":"2021-11-28T22:28:33.71107Z","shell.execute_reply.started":"2021-11-28T22:14:02.143474Z","shell.execute_reply":"2021-11-28T22:28:33.710353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Analysis of Model**\n\nThe epoch with the lowest testing loss had a training accuracy of 96% and a testing accuracy of 83%, with a training loss of 11% and a testing loss of 33%. Testing recall is 71%. Although the results from this model iteration, using SGD with momentum instead of Adam as an optimizer, they are not as good as the previous model iteration which used Adam, so it looks like Adam is the best optimizer to use in this situation.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}