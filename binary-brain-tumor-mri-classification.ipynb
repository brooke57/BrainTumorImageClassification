{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","scrolled":true,"execution":{"iopub.status.busy":"2021-11-24T02:09:29.752669Z","iopub.execute_input":"2021-11-24T02:09:29.753108Z","iopub.status.idle":"2021-11-24T02:09:34.463073Z","shell.execute_reply.started":"2021-11-24T02:09:29.752963Z","shell.execute_reply":"2021-11-24T02:09:34.460700Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# General imports\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import regularizers\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.models import load_model\nimport seaborn as sns\nfrom mlxtend.plotting import plot_decision_regions\nfrom sklearn.metrics import confusion_matrix\nimport cv2\nimport PIL","metadata":{"execution":{"iopub.status.busy":"2021-11-24T02:09:34.464724Z","iopub.execute_input":"2021-11-24T02:09:34.465188Z","iopub.status.idle":"2021-11-24T02:09:41.609880Z","shell.execute_reply.started":"2021-11-24T02:09:34.465002Z","shell.execute_reply":"2021-11-24T02:09:41.608919Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"\ndef visualize_training_results(history):\n    '''\n    From https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/\n    \n    Input: keras history object (output from trained model)\n    '''\n    fig, (ax1, ax2) = plt.subplots(2, sharex=True)\n    fig.suptitle('Model Results')\n\n    # summarize history for accuracy\n    ax1.plot(history.history['acc'])\n    ax1.plot(history.history['val_acc'])\n    ax1.set_ylabel('Accuracy')\n    ax1.legend(['train', 'test'], loc='upper left')\n    # summarize history for loss\n    ax2.plot(history.history['loss'])\n    ax2.plot(history.history['val_loss'])\n    ax2.set_ylabel('Loss')\n    ax2.legend(['train', 'test'], loc='upper left')\n    \n    plt.xlabel('Epoch')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-24T02:18:04.636024Z","iopub.execute_input":"2021-11-24T02:18:04.636354Z","iopub.status.idle":"2021-11-24T02:18:04.645005Z","shell.execute_reply.started":"2021-11-24T02:18:04.636322Z","shell.execute_reply":"2021-11-24T02:18:04.643717Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Set up ImageDataGenerator\ntrain_imagegen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\n                                   zoom_range=([0.6,1]),\n                                   rotation_range=10,                           \n                                   brightness_range=([0.6, 1.5]),\n                                   horizontal_flip=True,\n                                   validation_split=0.06) # this will set aside a part of training set for validation data\ntest_imagegen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\n                                   zoom_range=([0.6,1]),\n                                   rotation_range=10,\n                                   brightness_range=([0.6,1.5]),\n                                   horizontal_flip=True)\n# Bring the data in\ntrain_generator = train_imagegen.flow_from_directory(\n                                    '../input/resortedbraintumorclassificationmridata/Brain_MRI_Tumor_Images/Training',\n                                    target_size=(200,200),\n                                    batch_size=20,\n                                    seed=42,\n                                    class_mode='binary',\n                                    subset='training')\n\ntest_generator = test_imagegen.flow_from_directory(\n                                    '../input/resortedbraintumorclassificationmridata/Brain_MRI_Tumor_Images/Testing',\n                                    target_size=(200,200),\n                                    batch_size=20,\n                                    seed=42,\n                                    class_mode='binary')\n\nval_generator = train_imagegen.flow_from_directory(\n                                    '../input/resortedbraintumorclassificationmridata/Brain_MRI_Tumor_Images/Training',\n                                    target_size=(200,200),\n                                    batch_size=20,\n                                    seed=42,\n                                    class_mode='binary',\n                                    subset='validation')","metadata":{"execution":{"iopub.status.busy":"2021-11-24T02:43:38.187360Z","iopub.execute_input":"2021-11-24T02:43:38.187641Z","iopub.status.idle":"2021-11-24T02:43:38.616901Z","shell.execute_reply.started":"2021-11-24T02:43:38.187612Z","shell.execute_reply":"2021-11-24T02:43:38.615802Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Visualize (code from https://github.com/austint1121/OES-PneumoniaClassification/blob/main/Final_Notebook.ipynb)\ntrain_batch = train_generator.next()\nfig, axes = plt.subplots(2, 5, figsize=(16, 8))\n    \nfor i in range(10):\n    # Load image into numpy array and re-scale\n    img = np.array(train_batch[0][i] * 255, dtype='uint8')\n    ax = axes[i // 5, i % 5]\n    ax.imshow(img)\nfig.suptitle('Training Images')\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-24T02:44:53.158565Z","iopub.execute_input":"2021-11-24T02:44:53.158936Z","iopub.status.idle":"2021-11-24T02:44:55.108780Z","shell.execute_reply.started":"2021-11-24T02:44:53.158874Z","shell.execute_reply":"2021-11-24T02:44:55.107948Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"## **Taking a Look at a few different individual images**","metadata":{}},{"cell_type":"code","source":"tumor1 = PIL.Image.open('../input/resortedbraintumorclassificationmridata/Brain_MRI_Tumor_Images/Training/AllTumorsTrain/gg (108).jpg')\ntumor1","metadata":{"execution":{"iopub.status.busy":"2021-11-24T02:36:06.518695Z","iopub.execute_input":"2021-11-24T02:36:06.518991Z","iopub.status.idle":"2021-11-24T02:36:06.610621Z","shell.execute_reply.started":"2021-11-24T02:36:06.518960Z","shell.execute_reply":"2021-11-24T02:36:06.609107Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Figuring out the number of color channels\ntumor1.mode","metadata":{"execution":{"iopub.status.busy":"2021-11-23T16:37:36.520784Z","iopub.execute_input":"2021-11-23T16:37:36.521099Z","iopub.status.idle":"2021-11-23T16:37:36.525967Z","shell.execute_reply.started":"2021-11-23T16:37:36.521067Z","shell.execute_reply":"2021-11-23T16:37:36.525224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Taking a look at the class imbalance**","metadata":{}},{"cell_type":"code","source":"train_generator.class_indices","metadata":{"execution":{"iopub.status.busy":"2021-11-23T18:33:26.691505Z","iopub.execute_input":"2021-11-23T18:33:26.691794Z","iopub.status.idle":"2021-11-23T18:33:26.699461Z","shell.execute_reply.started":"2021-11-23T18:33:26.691747Z","shell.execute_reply":"2021-11-23T18:33:26.698656Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"train_generator.classes","metadata":{"execution":{"iopub.status.busy":"2021-11-23T18:33:29.907326Z","iopub.execute_input":"2021-11-23T18:33:29.908170Z","iopub.status.idle":"2021-11-23T18:33:29.916177Z","shell.execute_reply.started":"2021-11-23T18:33:29.908100Z","shell.execute_reply":"2021-11-23T18:33:29.915311Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"tumors = pd.DataFrame(train_generator.classes)\nvalues = tumors.value_counts()\nvalues","metadata":{"execution":{"iopub.status.busy":"2021-11-23T18:33:31.972073Z","iopub.execute_input":"2021-11-23T18:33:31.972355Z","iopub.status.idle":"2021-11-23T18:33:31.989591Z","shell.execute_reply.started":"2021-11-23T18:33:31.972325Z","shell.execute_reply":"2021-11-23T18:33:31.988657Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"tumors.rename(columns={0:'Tumor/No Tumor'}, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T18:33:34.860138Z","iopub.execute_input":"2021-11-23T18:33:34.860846Z","iopub.status.idle":"2021-11-23T18:33:34.866837Z","shell.execute_reply.started":"2021-11-23T18:33:34.860804Z","shell.execute_reply":"2021-11-23T18:33:34.866055Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"tumors[tumors['Tumor/No Tumor'] == 0]","metadata":{"execution":{"iopub.status.busy":"2021-11-23T18:33:44.849433Z","iopub.execute_input":"2021-11-23T18:33:44.849686Z","iopub.status.idle":"2021-11-23T18:33:44.869583Z","shell.execute_reply.started":"2021-11-23T18:33:44.849657Z","shell.execute_reply":"2021-11-23T18:33:44.868649Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"no_tumor = len(tumors[tumors['Tumor/No Tumor'] == 1])\ntumor = len(tumors[tumors['Tumor/No Tumor'] == 0])","metadata":{"execution":{"iopub.status.busy":"2021-11-23T18:33:47.798591Z","iopub.execute_input":"2021-11-23T18:33:47.798852Z","iopub.status.idle":"2021-11-23T18:33:47.805715Z","shell.execute_reply.started":"2021-11-23T18:33:47.798821Z","shell.execute_reply":"2021-11-23T18:33:47.804561Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"#plt.figure(figsize=(10,6))\n#sns.set(font_scale=1.4)\n#sns.barplot(tumors.index, tumors.values)\n#plt.ylabel(\"Number of Images\")\n#plt.title('Distribution of Brain MRIs with and without Tumor');\n\nfig, ax = plt.subplots(figsize=(10,8))\nax.bar(x=['No Tumor', 'Tumor'],height = [no_tumor, tumor])\nax.set(xlabel='', ylabel='Number of Images', title='Distribution of Brain MRIs with and without Tumor');","metadata":{"execution":{"iopub.status.busy":"2021-11-23T18:34:04.436315Z","iopub.execute_input":"2021-11-23T18:34:04.436583Z","iopub.status.idle":"2021-11-23T18:34:04.627427Z","shell.execute_reply.started":"2021-11-23T18:34:04.436552Z","shell.execute_reply":"2021-11-23T18:34:04.626744Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"## **Baseline CNN Model**","metadata":{}},{"cell_type":"code","source":"# Building the first baseline model; structure is modified from one shown on:\n# https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\nbaseline = keras.Sequential()\nbaseline.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(200,200,3)))\nbaseline.add(layers.MaxPooling2D(2,2))\nbaseline.add(layers.Conv2D(64, (3,3), activation='relu'))\nbaseline.add(layers.MaxPooling2D(2,2))\n\nbaseline.add(layers.Flatten())\nbaseline.add(layers.Dense(128, activation='relu'))\nbaseline.add(layers.Dense(1, activation='sigmoid'))\n\nbaseline.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])","metadata":{"execution":{"iopub.status.busy":"2021-11-24T02:45:33.336344Z","iopub.execute_input":"2021-11-24T02:45:33.336620Z","iopub.status.idle":"2021-11-24T02:45:33.407653Z","shell.execute_reply.started":"2021-11-24T02:45:33.336589Z","shell.execute_reply":"2021-11-24T02:45:33.406686Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"baseline_results = baseline.fit_generator(train_generator,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=10,\n                                         validation_data=test_generator)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T02:45:36.641381Z","iopub.execute_input":"2021-11-24T02:45:36.642247Z","iopub.status.idle":"2021-11-24T02:52:53.595216Z","shell.execute_reply.started":"2021-11-24T02:45:36.642183Z","shell.execute_reply":"2021-11-24T02:52:53.594217Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(baseline_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T02:53:36.320213Z","iopub.execute_input":"2021-11-24T02:53:36.320509Z","iopub.status.idle":"2021-11-24T02:53:36.675247Z","shell.execute_reply.started":"2021-11-24T02:53:36.320477Z","shell.execute_reply":"2021-11-24T02:53:36.674256Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"### **Analysis of Model**\n\nLooking at the above graphs, it is obvious that this first baseline cnn model is overfitting; accuracy for training data ends up at around 94%, whereas testing data ends up at around 65%. Additionally, the loss for testing data is fairly high; for training the loss ends up at 15%, and for testing it ends up at 69%. In the next model iteration, I will add another dense layer, which will hopefully help the model pick up on more patterns, and some dropout layers for a form of regularization.","metadata":{}},{"cell_type":"markdown","source":"## **Adding another Dense layer and Dropout layers**","metadata":{}},{"cell_type":"code","source":"# Adding another dense layer and a couple of dropout layers; structure is modified from one shown on:\n# https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\nnp.random.seed(42)\nlayers_drop = keras.Sequential()\nlayers_drop.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(200,200,3)))\nlayers_drop.add(layers.MaxPooling2D(2,2))\nlayers_drop.add(layers.Conv2D(64, (3,3), activation='relu'))\nlayers_drop.add(layers.MaxPooling2D(2,2))\n\nlayers_drop.add(layers.Flatten())\nlayers_drop.add(layers.Dense(128, activation='relu'))\nlayers_drop.add(layers.Dropout(0.3))\nlayers_drop.add(layers.Dense(64, activation='relu'))\nlayers_drop.add(layers.Dropout(0.3))\nlayers_drop.add(layers.Dense(1, activation='sigmoid'))\n\nlayers_drop.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])","metadata":{"execution":{"iopub.status.busy":"2021-11-24T02:54:28.093148Z","iopub.execute_input":"2021-11-24T02:54:28.093473Z","iopub.status.idle":"2021-11-24T02:54:28.179478Z","shell.execute_reply.started":"2021-11-24T02:54:28.093441Z","shell.execute_reply":"2021-11-24T02:54:28.178548Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Fitting the model\nlayers_drop_results = layers_drop.fit_generator(train_generator,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=10,\n                                         validation_data=test_generator)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T02:54:31.190723Z","iopub.execute_input":"2021-11-24T02:54:31.191013Z","iopub.status.idle":"2021-11-24T03:02:25.353712Z","shell.execute_reply.started":"2021-11-24T02:54:31.190981Z","shell.execute_reply":"2021-11-24T03:02:25.352707Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(layers_drop_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T03:02:25.357070Z","iopub.execute_input":"2021-11-24T03:02:25.357721Z","iopub.status.idle":"2021-11-24T03:02:25.713956Z","shell.execute_reply.started":"2021-11-24T03:02:25.357652Z","shell.execute_reply":"2021-11-24T03:02:25.712924Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"### **Analysis of Model**\n\nIn this iteration, training accuracy ends up at 93%, and testing ends up at 73%, so the model is overfitting, but less so than the baseline model. As for loss, training loss is 14% and testing loss is 65%, which is not drastically different from the last model. Adding another layer and dropout layers did not seem to help very much, but in the next model iteration I am going to account for the class imabalance, and the added layer and dropout layers might perform better in this iteration.","metadata":{}},{"cell_type":"markdown","source":"## **Accounting for class imbalance**","metadata":{}},{"cell_type":"code","source":"# Accounting for class imbalance; structure is modified from one shown on:\n# https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\n\nclass_ld = keras.Sequential()\nclass_ld.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(200,200,3)))\nclass_ld.add(layers.MaxPooling2D(2,2))\nclass_ld.add(layers.Conv2D(64, (3,3), activation='relu'))\nclass_ld.add(layers.MaxPooling2D(2,2))\n\nclass_ld.add(layers.Flatten())\nclass_ld.add(layers.Dense(128, activation='relu'))\nclass_ld.add(layers.Dropout(0.3))\nclass_ld.add(layers.Dense(64, activation='relu'))\nclass_ld.add(layers.Dropout(0.3))\nclass_ld.add(layers.Dense(1, activation='sigmoid'))\n\nclass_ld.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])\nweights = {0: 1, # TUMOR\n          1:6.255} # NO TUMOR \n# there are 6.255 times as many images of MRIs with tumors than without","metadata":{"execution":{"iopub.status.busy":"2021-11-24T03:02:34.325807Z","iopub.execute_input":"2021-11-24T03:02:34.326570Z","iopub.status.idle":"2021-11-24T03:02:34.412784Z","shell.execute_reply.started":"2021-11-24T03:02:34.326534Z","shell.execute_reply":"2021-11-24T03:02:34.411870Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# Fitting the model\nclass_ld_results = class_ld.fit_generator(train_generator,\n                                          class_weight=weights,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=10,\n                                         validation_data=test_generator)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T03:02:38.201806Z","iopub.execute_input":"2021-11-24T03:02:38.202128Z","iopub.status.idle":"2021-11-24T03:13:43.563982Z","shell.execute_reply.started":"2021-11-24T03:02:38.202095Z","shell.execute_reply":"2021-11-24T03:13:43.563027Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(class_ld_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T03:13:43.566832Z","iopub.execute_input":"2021-11-24T03:13:43.567244Z","iopub.status.idle":"2021-11-24T03:13:44.024906Z","shell.execute_reply.started":"2021-11-24T03:13:43.567184Z","shell.execute_reply":"2021-11-24T03:13:44.023198Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"### **Analysis of Model**\n\nIn this model iteration, training accuracy was about 89% and testing accuracy is about 57%, so the model is still overfitting compared to the last model. Loss for training is at around 51% and testing loss is around 99%. In terms of acuracy and loss, the model is doing worse than the previous model. However, recall has increased significantly, so it seems that adding weights is beneficial to the model, even though it requires further tuning.","metadata":{}},{"cell_type":"markdown","source":"## **Adding another Convolution layer**","metadata":{}},{"cell_type":"code","source":"# Another Convolution layer; structure is modified from one shown on:\n# https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\nnp.random.seed(42)\nclass_con = keras.Sequential()\nclass_con.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(200,200,3)))\nclass_con.add(layers.MaxPooling2D(2,2))\nclass_con.add(layers.Conv2D(64, (3,3), activation='relu'))\nclass_con.add(layers.MaxPooling2D(2,2))\nclass_con.add(layers.Conv2D(128, (3,3), activation='relu'))\nclass_con.add(layers.MaxPooling2D(2,2))\n\nclass_con.add(layers.Flatten())\nclass_con.add(layers.Dense(128, activation='relu'))\nclass_con.add(layers.Dropout(0.3))\nclass_con.add(layers.Dense(64, activation='relu'))\nclass_con.add(layers.Dropout(0.3))\nclass_con.add(layers.Dense(1, activation='sigmoid'))\n\nclass_con.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])\nweights = {0: 1, \n          1:6.255}","metadata":{"execution":{"iopub.status.busy":"2021-11-24T03:14:05.878911Z","iopub.execute_input":"2021-11-24T03:14:05.879766Z","iopub.status.idle":"2021-11-24T03:14:06.063157Z","shell.execute_reply.started":"2021-11-24T03:14:05.879717Z","shell.execute_reply":"2021-11-24T03:14:06.062124Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"class_con_results = class_con.fit_generator(train_generator,\n                                          class_weight=weights,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=10,\n                                         validation_data=test_generator)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T03:14:12.111234Z","iopub.execute_input":"2021-11-24T03:14:12.111527Z","iopub.status.idle":"2021-11-24T03:25:18.319845Z","shell.execute_reply.started":"2021-11-24T03:14:12.111496Z","shell.execute_reply":"2021-11-24T03:25:18.318546Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(class_con_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T03:27:36.196000Z","iopub.execute_input":"2021-11-24T03:27:36.196980Z","iopub.status.idle":"2021-11-24T03:27:36.549589Z","shell.execute_reply.started":"2021-11-24T03:27:36.196930Z","shell.execute_reply":"2021-11-24T03:27:36.548584Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"### **Analysis of Model**\n\nTraining accuracy is at 89% while testing accuracy is at 50%, so model is still overfitting, slightly worse than the previous model. Training loss is 50%, and testing loss is 93%; training loss is 50% and testing loss is 93%, which is similar to the loss values of the previous model. In the next model iteration, I will see if changing the dimensions of the pooling layer will improve the model.\n","metadata":{}},{"cell_type":"markdown","source":"## **Adjusting the Pooling Strategy**","metadata":{}},{"cell_type":"code","source":"# Another Convolution layer; structure is modified from one shown on:\n# https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\nnp.random.seed(42)\nclass_pool = keras.Sequential()\nclass_pool.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(200,200,3)))\nclass_pool.add(layers.MaxPooling2D(2,2))\nclass_pool.add(layers.Conv2D(64, (3,3), activation='relu'))\nclass_pool.add(layers.MaxPooling2D(3,3))\nclass_pool.add(layers.Conv2D(128, (3,3), activation='relu'))\nclass_pool.add(layers.MaxPooling2D(5,5))\n\nclass_pool.add(layers.Flatten())\nclass_pool.add(layers.Dense(128, activation='relu'))\nclass_pool.add(layers.Dropout(0.3))\nclass_pool.add(layers.Dense(64, activation='relu'))\nclass_pool.add(layers.Dropout(0.3))\nclass_pool.add(layers.Dense(1, activation='sigmoid'))\n\nclass_pool.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])\nweights = {0: 1, # TUMOR\n          1:6.255} # NO TUMOR\n# there are 6.255 times as many images of MRIs with tumors than without","metadata":{"execution":{"iopub.status.busy":"2021-11-24T03:27:52.729014Z","iopub.execute_input":"2021-11-24T03:27:52.729876Z","iopub.status.idle":"2021-11-24T03:27:53.335735Z","shell.execute_reply.started":"2021-11-24T03:27:52.729801Z","shell.execute_reply":"2021-11-24T03:27:53.334577Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"class_pool_results = class_pool.fit_generator(train_generator,\n                                          class_weight=weights,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=10,\n                                         validation_data=test_generator)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T03:28:03.212006Z","iopub.execute_input":"2021-11-24T03:28:03.212359Z","iopub.status.idle":"2021-11-24T03:39:48.779321Z","shell.execute_reply.started":"2021-11-24T03:28:03.212312Z","shell.execute_reply":"2021-11-24T03:39:48.778112Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(class_pool_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T03:39:48.782433Z","iopub.execute_input":"2021-11-24T03:39:48.782833Z","iopub.status.idle":"2021-11-24T03:39:49.182011Z","shell.execute_reply.started":"2021-11-24T03:39:48.782787Z","shell.execute_reply":"2021-11-24T03:39:49.180919Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"### **Analysis of Model**\n\nTraining accuracy is at about 89%, and testing accuracy is at about 48%, so model is still overfitting quite a bit. Training loss is 48%, and testing loss is 101%; testing loss has increased quite a lot since the last model. Maybe increasing the pooling matrix is not beneficial to the model, but maybe padding will help. In this next model, I will introduce some padding to reduce image loss, to see if this improves model. I will also increase the number of epochs.","metadata":{}},{"cell_type":"markdown","source":"## **Model with Padding, More Epochs**","metadata":{}},{"cell_type":"code","source":"# Another Convolution layer; structure is modified from one shown on:\n# https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\nnp.random.seed(42)\nclass_pad = keras.Sequential()\nclass_pad.add(layers.Conv2D(32, (3,3), activation='relu', padding='same', input_shape=(200,200,3)))\nclass_pad.add(layers.MaxPooling2D(2,2))\nclass_pad.add(layers.Conv2D(64, (3,3), activation='relu', padding='same'))\nclass_pad.add(layers.MaxPooling2D(3,3))\nclass_pad.add(layers.Conv2D(128, (3,3), activation='relu', padding='same'))\nclass_pad.add(layers.MaxPooling2D(5,5))\n\nclass_pad.add(layers.Flatten())\nclass_pad.add(layers.Dense(128, activation='relu'))\nclass_pad.add(layers.Dropout(0.3))\nclass_pad.add(layers.Dense(64, activation='relu'))\nclass_pad.add(layers.Dropout(0.3))\nclass_pad.add(layers.Dense(1, activation='sigmoid'))\n\nclass_pad.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])\nweights = {0: 1, # TUMOR\n          1:6.255} # NO TUMOR\n# there are 6.255 times as many images of MRIs with tumors than without","metadata":{"execution":{"iopub.status.busy":"2021-11-24T03:44:27.133234Z","iopub.execute_input":"2021-11-24T03:44:27.133543Z","iopub.status.idle":"2021-11-24T03:44:27.236939Z","shell.execute_reply.started":"2021-11-24T03:44:27.133510Z","shell.execute_reply":"2021-11-24T03:44:27.235891Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"early_stop = [EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n            ModelCheckpoint(filepath='best_model.h5', monitor='val_loss',\n                           save_best_only=True)]","metadata":{"execution":{"iopub.status.busy":"2021-11-24T03:44:29.609314Z","iopub.execute_input":"2021-11-24T03:44:29.609961Z","iopub.status.idle":"2021-11-24T03:44:29.615582Z","shell.execute_reply.started":"2021-11-24T03:44:29.609924Z","shell.execute_reply":"2021-11-24T03:44:29.614108Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"class_pad_results = class_pad.fit_generator(train_generator,\n                                          class_weight=weights,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=50,\n                                         validation_data=test_generator)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T03:50:14.714189Z","iopub.execute_input":"2021-11-24T03:50:14.714545Z","iopub.status.idle":"2021-11-24T04:37:38.066312Z","shell.execute_reply.started":"2021-11-24T03:50:14.714499Z","shell.execute_reply":"2021-11-24T04:37:38.065284Z"},"scrolled":true,"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(class_pad_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T04:38:36.464217Z","iopub.execute_input":"2021-11-24T04:38:36.464526Z","iopub.status.idle":"2021-11-24T04:38:36.814590Z","shell.execute_reply.started":"2021-11-24T04:38:36.464495Z","shell.execute_reply":"2021-11-24T04:38:36.811615Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"### **Analysis of Model**\n\nTraining accuracy is 96%, testing accuracy is 68%, so the model is overfitting a bit less than in the previous model. Training loss is 29% and testing loss is 78%; testing loss increased significantly from the last model. It looks like this strategy of padding is not very good for this data.","metadata":{}},{"cell_type":"markdown","source":"## **Model without Padding, Early Stopping, and more Epochs**","metadata":{}},{"cell_type":"code","source":"# Another Convolution layer; structure is modified from one shown on:\n# https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\nnp.random.seed(42)\nclass_ee = keras.Sequential()\nclass_ee.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(200,200,3)))\nclass_ee.add(layers.MaxPooling2D(2,2))\nclass_ee.add(layers.Conv2D(64, (3,3), activation='relu'))\nclass_ee.add(layers.MaxPooling2D(3,3))\nclass_ee.add(layers.Conv2D(128, (3,3), activation='relu'))\nclass_ee.add(layers.MaxPooling2D(5,5))\n\nclass_ee.add(layers.Flatten())\nclass_ee.add(layers.Dense(128, activation='relu'))\nclass_ee.add(layers.Dropout(0.3))\nclass_ee.add(layers.Dense(64, activation='relu'))\nclass_ee.add(layers.Dropout(0.3))\nclass_ee.add(layers.Dense(1, activation='sigmoid'))\n\nclass_ee.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])\nweights = {0: 1, # TUMOR\n          1:6.255} # NO TUMOR\n# there are 6.255 times as many images of MRIs with tumors than without","metadata":{"execution":{"iopub.status.busy":"2021-11-24T04:39:03.292892Z","iopub.execute_input":"2021-11-24T04:39:03.293787Z","iopub.status.idle":"2021-11-24T04:39:03.393442Z","shell.execute_reply.started":"2021-11-24T04:39:03.293751Z","shell.execute_reply":"2021-11-24T04:39:03.392279Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"early_stop2 = [EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True),\n            ModelCheckpoint(filepath='best_model.h5', monitor='val_loss',\n                           save_best_only=True)]","metadata":{"execution":{"iopub.status.busy":"2021-11-24T04:39:13.336534Z","iopub.execute_input":"2021-11-24T04:39:13.336840Z","iopub.status.idle":"2021-11-24T04:39:13.342643Z","shell.execute_reply.started":"2021-11-24T04:39:13.336808Z","shell.execute_reply":"2021-11-24T04:39:13.341578Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"class_ee_results = class_ee.fit_generator(train_generator,\n                                          class_weight=weights,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=50,\n                                        callbacks=early_stop2,\n                                         validation_data=test_generator)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T04:39:20.728344Z","iopub.execute_input":"2021-11-24T04:39:20.728814Z","iopub.status.idle":"2021-11-24T04:47:43.650277Z","shell.execute_reply.started":"2021-11-24T04:39:20.728777Z","shell.execute_reply":"2021-11-24T04:47:43.649273Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(class_ee_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T05:02:00.166857Z","iopub.execute_input":"2021-11-24T05:02:00.167658Z","iopub.status.idle":"2021-11-24T05:02:00.537838Z","shell.execute_reply.started":"2021-11-24T05:02:00.167623Z","shell.execute_reply":"2021-11-24T05:02:00.536933Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}