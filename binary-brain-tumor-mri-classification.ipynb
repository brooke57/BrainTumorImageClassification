{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","scrolled":true,"execution":{"iopub.status.busy":"2021-11-26T04:28:18.168020Z","iopub.execute_input":"2021-11-26T04:28:18.168376Z","iopub.status.idle":"2021-11-26T04:28:22.086147Z","shell.execute_reply.started":"2021-11-26T04:28:18.168297Z","shell.execute_reply":"2021-11-26T04:28:22.085431Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# General imports\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import regularizers\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.models import load_model\nimport seaborn as sns\nfrom mlxtend.plotting import plot_decision_regions\nfrom sklearn.metrics import confusion_matrix\nimport cv2\nimport PIL","metadata":{"execution":{"iopub.status.busy":"2021-11-26T04:28:26.872598Z","iopub.execute_input":"2021-11-26T04:28:26.873149Z","iopub.status.idle":"2021-11-26T04:28:33.102932Z","shell.execute_reply.started":"2021-11-26T04:28:26.873111Z","shell.execute_reply":"2021-11-26T04:28:33.102167Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"\ndef visualize_training_results(history):\n    '''\n    From https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/\n    \n    Input: keras history object (output from trained model)\n    '''\n    fig, (ax1, ax2) = plt.subplots(2, sharex=True)\n    fig.suptitle('Model Results')\n\n    # summarize history for accuracy\n    ax1.plot(history.history['acc'])\n    ax1.plot(history.history['val_acc'])\n    ax1.set_ylabel('Accuracy')\n    ax1.legend(['train', 'test'], loc='upper left')\n    # summarize history for loss\n    ax2.plot(history.history['loss'])\n    ax2.plot(history.history['val_loss'])\n    ax2.set_ylabel('Loss')\n    ax2.legend(['train', 'test'], loc='upper left')\n    \n    plt.xlabel('Epoch')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-26T04:28:38.129475Z","iopub.execute_input":"2021-11-26T04:28:38.130001Z","iopub.status.idle":"2021-11-26T04:28:38.137195Z","shell.execute_reply.started":"2021-11-26T04:28:38.129962Z","shell.execute_reply":"2021-11-26T04:28:38.136541Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Set up ImageDataGenerator\ntrain_imagegen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\n                                   zoom_range=([0.6,1]),\n                                   rotation_range=10,                           \n                                   brightness_range=([0.6, 1.5]),\n                                   horizontal_flip=True,\n                                   validation_split=0.06) # this will set aside a part of training set for validation data\ntest_imagegen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\n                                   zoom_range=([0.6,1]),\n                                   rotation_range=10,\n                                   brightness_range=([0.6,1.5]),\n                                   horizontal_flip=True)\n# Bring the data in\ntrain_generator = train_imagegen.flow_from_directory(\n                                    '../input/resortedbraintumorclassificationmridata/Brain_MRI_Tumor_Images/Training',\n                                    target_size=(200,200),\n                                    batch_size=20,\n                                    seed=42,\n                                    class_mode='binary',\n                                    subset='training')\n\ntest_generator = test_imagegen.flow_from_directory(\n                                    '../input/resortedbraintumorclassificationmridata/Brain_MRI_Tumor_Images/Testing',\n                                    target_size=(200,200),\n                                    batch_size=20,\n                                    seed=42,\n                                    class_mode='binary')\n\nval_generator = train_imagegen.flow_from_directory(\n                                    '../input/resortedbraintumorclassificationmridata/Brain_MRI_Tumor_Images/Training',\n                                    target_size=(200,200),\n                                    batch_size=20,\n                                    seed=42,\n                                    class_mode='binary',\n                                    subset='validation')","metadata":{"execution":{"iopub.status.busy":"2021-11-26T04:28:55.133202Z","iopub.execute_input":"2021-11-26T04:28:55.133833Z","iopub.status.idle":"2021-11-26T04:28:55.649834Z","shell.execute_reply.started":"2021-11-26T04:28:55.133788Z","shell.execute_reply":"2021-11-26T04:28:55.649092Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Visualize (code from https://github.com/austint1121/OES-PneumoniaClassification/blob/main/Final_Notebook.ipynb)\ntrain_batch = train_generator.next()\nfig, axes = plt.subplots(2, 5, figsize=(16, 8))\n    \nfor i in range(10):\n    # Load image into numpy array and re-scale\n    img = np.array(train_batch[0][i] * 255, dtype='uint8')\n    ax = axes[i // 5, i % 5]\n    ax.imshow(img)\nfig.suptitle('Training Images')\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:09:49.193265Z","iopub.execute_input":"2021-11-24T15:09:49.193683Z","iopub.status.idle":"2021-11-24T15:09:51.005621Z","shell.execute_reply.started":"2021-11-24T15:09:49.193638Z","shell.execute_reply":"2021-11-24T15:09:51.004209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Taking a Look at a few different individual images**","metadata":{}},{"cell_type":"code","source":"tumor1 = PIL.Image.open('../input/resortedbraintumorclassificationmridata/Brain_MRI_Tumor_Images/Training/AllTumorsTrain/gg (108).jpg')\ntumor1","metadata":{"execution":{"iopub.status.busy":"2021-11-24T02:36:06.518695Z","iopub.execute_input":"2021-11-24T02:36:06.518991Z","iopub.status.idle":"2021-11-24T02:36:06.610621Z","shell.execute_reply.started":"2021-11-24T02:36:06.51896Z","shell.execute_reply":"2021-11-24T02:36:06.609107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Figuring out the number of color channels\ntumor1.mode","metadata":{"execution":{"iopub.status.busy":"2021-11-23T16:37:36.520784Z","iopub.execute_input":"2021-11-23T16:37:36.521099Z","iopub.status.idle":"2021-11-23T16:37:36.525967Z","shell.execute_reply.started":"2021-11-23T16:37:36.521067Z","shell.execute_reply":"2021-11-23T16:37:36.525224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Taking a look at the class imbalance**","metadata":{}},{"cell_type":"markdown","source":"First looking at training data imbalance","metadata":{}},{"cell_type":"code","source":"train_generator.class_indices","metadata":{"execution":{"iopub.status.busy":"2021-11-23T18:33:26.691505Z","iopub.execute_input":"2021-11-23T18:33:26.691794Z","iopub.status.idle":"2021-11-23T18:33:26.699461Z","shell.execute_reply.started":"2021-11-23T18:33:26.691747Z","shell.execute_reply":"2021-11-23T18:33:26.698656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator.classes","metadata":{"execution":{"iopub.status.busy":"2021-11-23T18:33:29.907326Z","iopub.execute_input":"2021-11-23T18:33:29.90817Z","iopub.status.idle":"2021-11-23T18:33:29.916177Z","shell.execute_reply.started":"2021-11-23T18:33:29.9081Z","shell.execute_reply":"2021-11-23T18:33:29.915311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_tumors = pd.DataFrame(train_generator.classes)\ntrain_values = train_tumors.value_counts()\ntrain_values","metadata":{"execution":{"iopub.status.busy":"2021-11-24T18:44:57.105493Z","iopub.execute_input":"2021-11-24T18:44:57.105759Z","iopub.status.idle":"2021-11-24T18:44:57.118094Z","shell.execute_reply.started":"2021-11-24T18:44:57.105731Z","shell.execute_reply":"2021-11-24T18:44:57.117346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The ratio of images with tumors to those without is 2327:372, or 6.255:1.","metadata":{}},{"cell_type":"code","source":"train_tumors.rename(columns={0:'Tumor/No Tumor'}, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T18:33:34.860138Z","iopub.execute_input":"2021-11-23T18:33:34.860846Z","iopub.status.idle":"2021-11-23T18:33:34.866837Z","shell.execute_reply.started":"2021-11-23T18:33:34.860804Z","shell.execute_reply":"2021-11-23T18:33:34.866055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_tumors[train_tumors['Tumor/No Tumor'] == 0]","metadata":{"execution":{"iopub.status.busy":"2021-11-23T18:33:44.849433Z","iopub.execute_input":"2021-11-23T18:33:44.849686Z","iopub.status.idle":"2021-11-23T18:33:44.869583Z","shell.execute_reply.started":"2021-11-23T18:33:44.849657Z","shell.execute_reply":"2021-11-23T18:33:44.868649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_no_tumor = len(train_tumors[train_tumors['Tumor/No Tumor'] == 1])\ntrain_tumor = len(train_tumors[train_tumors['Tumor/No Tumor'] == 0])","metadata":{"execution":{"iopub.status.busy":"2021-11-23T18:33:47.798591Z","iopub.execute_input":"2021-11-23T18:33:47.798852Z","iopub.status.idle":"2021-11-23T18:33:47.805715Z","shell.execute_reply.started":"2021-11-23T18:33:47.798821Z","shell.execute_reply":"2021-11-23T18:33:47.804561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plt.figure(figsize=(10,6))\n#sns.set(font_scale=1.4)\n#sns.barplot(tumors.index, tumors.values)\n#plt.ylabel(\"Number of Images\")\n#plt.title('Distribution of Brain MRIs with and without Tumor');\n\nfig, ax = plt.subplots(figsize=(10,8))\nax.bar(x=['No Tumor', 'Tumor'],height = [train_no_tumor, train_tumor])\nax.set(xlabel='', ylabel='Number of Images', title='Distribution of Brain MRIs with and without Tumor');","metadata":{"execution":{"iopub.status.busy":"2021-11-23T18:34:04.436315Z","iopub.execute_input":"2021-11-23T18:34:04.436583Z","iopub.status.idle":"2021-11-23T18:34:04.627427Z","shell.execute_reply.started":"2021-11-23T18:34:04.436552Z","shell.execute_reply":"2021-11-23T18:34:04.626744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now taking a look at the test data imbalance","metadata":{}},{"cell_type":"code","source":"test_tumors = pd.DataFrame(test_generator.classes)\ntest_values = test_tumors.value_counts()\ntest_values","metadata":{"execution":{"iopub.status.busy":"2021-11-24T18:35:29.054029Z","iopub.execute_input":"2021-11-24T18:35:29.0543Z","iopub.status.idle":"2021-11-24T18:35:29.071402Z","shell.execute_reply.started":"2021-11-24T18:35:29.054273Z","shell.execute_reply":"2021-11-24T18:35:29.07061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"the ratio of images with tumors to those without is 289:105, or 2.75:1","metadata":{}},{"cell_type":"code","source":"test_tumors.rename(columns={0:'Tumor/No Tumor'}, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T18:35:56.658726Z","iopub.execute_input":"2021-11-24T18:35:56.659424Z","iopub.status.idle":"2021-11-24T18:35:56.666481Z","shell.execute_reply.started":"2021-11-24T18:35:56.659386Z","shell.execute_reply":"2021-11-24T18:35:56.665507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_no_tumor = len(test_tumors[test_tumors['Tumor/No Tumor'] == 1])\ntest_tumor = len(test_tumors[test_tumors['Tumor/No Tumor'] == 0])","metadata":{"execution":{"iopub.status.busy":"2021-11-24T18:36:26.681854Z","iopub.execute_input":"2021-11-24T18:36:26.68212Z","iopub.status.idle":"2021-11-24T18:36:26.691224Z","shell.execute_reply.started":"2021-11-24T18:36:26.682091Z","shell.execute_reply":"2021-11-24T18:36:26.690093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfig, ax = plt.subplots(figsize=(10,8))\nax.bar(x=['No Tumor', 'Tumor'],height = [test_no_tumor, test_tumor])\nax.set(xlabel='', ylabel='Number of Images', title='Distribution of Brain MRIs with and without Tumor in Testing Data');","metadata":{"execution":{"iopub.status.busy":"2021-11-24T18:36:51.234446Z","iopub.execute_input":"2021-11-24T18:36:51.234704Z","iopub.status.idle":"2021-11-24T18:36:51.426277Z","shell.execute_reply.started":"2021-11-24T18:36:51.234676Z","shell.execute_reply":"2021-11-24T18:36:51.425541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Baseline CNN Model**","metadata":{}},{"cell_type":"code","source":"# Building the first baseline model; structure is modified from one shown on:\n# https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\nbaseline = keras.Sequential()\nbaseline.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(200,200,3)))\nbaseline.add(layers.MaxPooling2D(2,2))\nbaseline.add(layers.Conv2D(64, (3,3), activation='relu'))\nbaseline.add(layers.MaxPooling2D(2,2))\n\nbaseline.add(layers.Flatten())\nbaseline.add(layers.Dense(128, activation='relu'))\nbaseline.add(layers.Dense(1, activation='sigmoid'))\n\nbaseline.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])","metadata":{"execution":{"iopub.status.busy":"2021-11-24T02:45:33.336344Z","iopub.execute_input":"2021-11-24T02:45:33.33662Z","iopub.status.idle":"2021-11-24T02:45:33.407653Z","shell.execute_reply.started":"2021-11-24T02:45:33.336589Z","shell.execute_reply":"2021-11-24T02:45:33.406686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"baseline_results = baseline.fit_generator(train_generator,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=10,\n                                         validation_data=test_generator)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T02:45:36.641381Z","iopub.execute_input":"2021-11-24T02:45:36.642247Z","iopub.status.idle":"2021-11-24T02:52:53.595216Z","shell.execute_reply.started":"2021-11-24T02:45:36.642183Z","shell.execute_reply":"2021-11-24T02:52:53.594217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(baseline_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T02:53:36.320213Z","iopub.execute_input":"2021-11-24T02:53:36.320509Z","iopub.status.idle":"2021-11-24T02:53:36.675247Z","shell.execute_reply.started":"2021-11-24T02:53:36.320477Z","shell.execute_reply":"2021-11-24T02:53:36.674256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Analysis of Model**\n\nLooking at the above graphs, it is obvious that this first baseline cnn model is overfitting; accuracy for training data ends up at around 94%, whereas testing data ends up at around 65%. Additionally, the loss for testing data is fairly high; for training the loss ends up at 15%, and for testing it ends up at 69%. In the next model iteration, I will add another dense layer, which will hopefully help the model pick up on more patterns, and some dropout layers for a form of regularization.","metadata":{}},{"cell_type":"markdown","source":"## **Adding another Dense layer and Dropout layers**","metadata":{}},{"cell_type":"code","source":"# Adding another dense layer and a couple of dropout layers; structure is modified from one shown on:\n# https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\nnp.random.seed(42)\nlayers_drop = keras.Sequential()\nlayers_drop.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(200,200,3)))\nlayers_drop.add(layers.MaxPooling2D(2,2))\nlayers_drop.add(layers.Conv2D(64, (3,3), activation='relu'))\nlayers_drop.add(layers.MaxPooling2D(2,2))\n\nlayers_drop.add(layers.Flatten())\nlayers_drop.add(layers.Dense(128, activation='relu'))\nlayers_drop.add(layers.Dropout(0.3))\nlayers_drop.add(layers.Dense(64, activation='relu'))\nlayers_drop.add(layers.Dropout(0.3))\nlayers_drop.add(layers.Dense(1, activation='sigmoid'))\n\nlayers_drop.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])","metadata":{"execution":{"iopub.status.busy":"2021-11-24T02:54:28.093148Z","iopub.execute_input":"2021-11-24T02:54:28.093473Z","iopub.status.idle":"2021-11-24T02:54:28.179478Z","shell.execute_reply.started":"2021-11-24T02:54:28.093441Z","shell.execute_reply":"2021-11-24T02:54:28.178548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fitting the model\nlayers_drop_results = layers_drop.fit_generator(train_generator,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=10,\n                                         validation_data=test_generator)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T02:54:31.190723Z","iopub.execute_input":"2021-11-24T02:54:31.191013Z","iopub.status.idle":"2021-11-24T03:02:25.353712Z","shell.execute_reply.started":"2021-11-24T02:54:31.190981Z","shell.execute_reply":"2021-11-24T03:02:25.352707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(layers_drop_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T03:02:25.35707Z","iopub.execute_input":"2021-11-24T03:02:25.357721Z","iopub.status.idle":"2021-11-24T03:02:25.713956Z","shell.execute_reply.started":"2021-11-24T03:02:25.357652Z","shell.execute_reply":"2021-11-24T03:02:25.712924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Analysis of Model**\n\nIn this iteration, training accuracy ends up at 93%, and testing ends up at 73%, so the model is overfitting, but less so than the baseline model. As for loss, training loss is 14% and testing loss is 65%, which is not drastically different from the last model. Adding another layer and dropout layers helped decrease overfitting. In the next model iteration I am going to account for the class imabalance, and the added layer and dropout layers might perform better in this iteration.","metadata":{}},{"cell_type":"markdown","source":"## **Accounting for class imbalance**","metadata":{}},{"cell_type":"code","source":"# Accounting for class imbalance; structure is modified from one shown on:\n# https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\n\nclass_ld = keras.Sequential()\nclass_ld.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(200,200,3)))\nclass_ld.add(layers.MaxPooling2D(2,2))\nclass_ld.add(layers.Conv2D(64, (3,3), activation='relu'))\nclass_ld.add(layers.MaxPooling2D(2,2))\n\nclass_ld.add(layers.Flatten())\nclass_ld.add(layers.Dense(128, activation='relu'))\nclass_ld.add(layers.Dropout(0.3))\nclass_ld.add(layers.Dense(64, activation='relu'))\nclass_ld.add(layers.Dropout(0.3))\nclass_ld.add(layers.Dense(1, activation='sigmoid'))\n\nclass_ld.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])\nweights = {0: 1, # TUMOR\n          1:6.255} # NO TUMOR \n# there are 6.255 times as many images of MRIs with tumors than without","metadata":{"execution":{"iopub.status.busy":"2021-11-26T04:45:28.543324Z","iopub.execute_input":"2021-11-26T04:45:28.544119Z","iopub.status.idle":"2021-11-26T04:45:28.612144Z","shell.execute_reply.started":"2021-11-26T04:45:28.544084Z","shell.execute_reply":"2021-11-26T04:45:28.611491Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Fitting the model\nclass_ld_results = class_ld.fit_generator(train_generator,\n                                          class_weight=weights,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=10,\n                                         validation_data=test_generator)","metadata":{"execution":{"iopub.status.busy":"2021-11-26T04:45:37.116738Z","iopub.execute_input":"2021-11-26T04:45:37.117004Z","iopub.status.idle":"2021-11-26T04:52:22.550519Z","shell.execute_reply.started":"2021-11-26T04:45:37.116974Z","shell.execute_reply":"2021-11-26T04:52:22.549758Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(class_ld_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T03:13:43.566832Z","iopub.execute_input":"2021-11-24T03:13:43.567244Z","iopub.status.idle":"2021-11-24T03:13:44.024906Z","shell.execute_reply.started":"2021-11-24T03:13:43.567184Z","shell.execute_reply":"2021-11-24T03:13:44.023198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Analysis of Model**\n\nIn this model iteration, training accuracy was about 89% and testing accuracy is about 57%, so the model is still overfitting compared to the last model. Loss for training is at around 51% and testing loss is around 99%. In terms of acuracy and loss, the model is doing worse than the previous model. However, recall has increased significantly, so it seems that adding class weights is beneficial to the model, even though it requires further tuning.","metadata":{}},{"cell_type":"markdown","source":"## **Adding another Convolution layer**","metadata":{}},{"cell_type":"code","source":"# Another Convolution layer; structure is modified from one shown on:\n# https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\nnp.random.seed(42)\nclass_con = keras.Sequential()\nclass_con.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(200,200,3)))\nclass_con.add(layers.MaxPooling2D(2,2))\nclass_con.add(layers.Conv2D(64, (3,3), activation='relu'))\nclass_con.add(layers.MaxPooling2D(2,2))\nclass_con.add(layers.Conv2D(128, (3,3), activation='relu'))\nclass_con.add(layers.MaxPooling2D(2,2))\n\nclass_con.add(layers.Flatten())\nclass_con.add(layers.Dense(128, activation='relu'))\nclass_con.add(layers.Dropout(0.3))\nclass_con.add(layers.Dense(64, activation='relu'))\nclass_con.add(layers.Dropout(0.3))\nclass_con.add(layers.Dense(1, activation='sigmoid'))\n\nclass_con.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])\nweights = {0: 1, \n          1:6.255}","metadata":{"execution":{"iopub.status.busy":"2021-11-24T03:14:05.878911Z","iopub.execute_input":"2021-11-24T03:14:05.879766Z","iopub.status.idle":"2021-11-24T03:14:06.063157Z","shell.execute_reply.started":"2021-11-24T03:14:05.879717Z","shell.execute_reply":"2021-11-24T03:14:06.062124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_con_results = class_con.fit_generator(train_generator,\n                                          class_weight=weights,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=10,\n                                         validation_data=test_generator)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T03:14:12.111234Z","iopub.execute_input":"2021-11-24T03:14:12.111527Z","iopub.status.idle":"2021-11-24T03:25:18.319845Z","shell.execute_reply.started":"2021-11-24T03:14:12.111496Z","shell.execute_reply":"2021-11-24T03:25:18.318546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(class_con_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T03:27:36.196Z","iopub.execute_input":"2021-11-24T03:27:36.19698Z","iopub.status.idle":"2021-11-24T03:27:36.549589Z","shell.execute_reply.started":"2021-11-24T03:27:36.19693Z","shell.execute_reply":"2021-11-24T03:27:36.548584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Analysis of Model**\n\nTraining accuracy is at 89% while testing accuracy is at 50%, so model is still overfitting, slightly worse than the previous model. Training loss is 50%, and testing loss is 93%; training loss is 50% and testing loss is 93%, which is similar to the loss values of the previous model. In the next model iteration, I will see if changing the dimensions of the pooling layer will improve the model.\n","metadata":{}},{"cell_type":"markdown","source":"## **Adjusting the Pooling Strategy**","metadata":{}},{"cell_type":"code","source":"# Another Convolution layer; structure is modified from one shown on:\n# https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\nclass_pool = keras.Sequential()\nclass_pool.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(200,200,3)))\nclass_pool.add(layers.MaxPooling2D(2,2))\nclass_pool.add(layers.Conv2D(64, (3,3), activation='relu'))\nclass_pool.add(layers.MaxPooling2D(3,3))\nclass_pool.add(layers.Conv2D(128, (3,3), activation='relu'))\nclass_pool.add(layers.MaxPooling2D(5,5))\n\nclass_pool.add(layers.Flatten())\nclass_pool.add(layers.Dense(128, activation='relu'))\nclass_pool.add(layers.Dropout(0.3))\nclass_pool.add(layers.Dense(64, activation='relu'))\nclass_pool.add(layers.Dropout(0.3))\nclass_pool.add(layers.Dense(1, activation='sigmoid'))\n\nclass_pool.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])\nweights = {0: 1, # TUMOR\n          1:6.255} # NO TUMOR\n# there are 6.255 times as many images of MRIs with tumors than without","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:24:02.186653Z","iopub.execute_input":"2021-11-24T15:24:02.187103Z","iopub.status.idle":"2021-11-24T15:24:02.264486Z","shell.execute_reply.started":"2021-11-24T15:24:02.187067Z","shell.execute_reply":"2021-11-24T15:24:02.263742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_pool_results = class_pool.fit_generator(train_generator,\n                                          class_weight=weights,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=10,\n                                         validation_data=test_generator)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:24:08.574651Z","iopub.execute_input":"2021-11-24T15:24:08.574914Z","iopub.status.idle":"2021-11-24T15:31:30.586701Z","shell.execute_reply.started":"2021-11-24T15:24:08.574885Z","shell.execute_reply":"2021-11-24T15:31:30.585989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(class_pool_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:32:11.71962Z","iopub.execute_input":"2021-11-24T15:32:11.719903Z","iopub.status.idle":"2021-11-24T15:32:12.00353Z","shell.execute_reply.started":"2021-11-24T15:32:11.719871Z","shell.execute_reply":"2021-11-24T15:32:12.002842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Analysis of Model**\n\nTraining accuracy is at about 89%, and testing accuracy is at about 48%, so model is still overfitting quite a bit. Training loss is 48%, and testing loss is 101%; testing loss has increased quite a lot since the last model. Maybe increasing the pooling matrix is not beneficial to the model,so I will return the pooling strategy to all be (2,2) matrices and introduce padding, as this may help.. In this next model, I will introduce some padding to reduce image loss, to see if this improves model.","metadata":{}},{"cell_type":"markdown","source":"## **Model with Padding**","metadata":{}},{"cell_type":"code","source":"# Another Convolution layer; structure is modified from one shown on:\n# https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\nnp.random.seed(42)\nclass_pad = keras.Sequential()\nclass_pad.add(layers.Conv2D(32, (3,3), activation='relu', padding='same', input_shape=(200,200,3)))\nclass_pad.add(layers.MaxPooling2D(2,2))\nclass_pad.add(layers.Conv2D(64, (3,3), activation='relu', padding='same'))\nclass_pad.add(layers.MaxPooling2D(2,2))\nclass_pad.add(layers.Conv2D(128, (3,3), activation='relu', padding='same'))\nclass_pad.add(layers.MaxPooling2D(2,2))\n\nclass_pad.add(layers.Flatten())\nclass_pad.add(layers.Dense(128, activation='relu'))\nclass_pad.add(layers.Dropout(0.3))\nclass_pad.add(layers.Dense(64, activation='relu'))\nclass_pad.add(layers.Dropout(0.3))\nclass_pad.add(layers.Dense(1, activation='sigmoid'))\n\nclass_pad.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])\nweights = {0: 1, # TUMOR\n          1:6.255} # NO TUMOR\n# there are 6.255 times as many images of MRIs with tumors than without","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:32:31.33241Z","iopub.execute_input":"2021-11-24T15:32:31.332959Z","iopub.status.idle":"2021-11-24T15:32:31.408883Z","shell.execute_reply.started":"2021-11-24T15:32:31.332915Z","shell.execute_reply":"2021-11-24T15:32:31.408165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stop = [EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n            ModelCheckpoint(filepath='best_model.h5', monitor='val_loss',\n                           save_best_only=True)]","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:32:35.347465Z","iopub.execute_input":"2021-11-24T15:32:35.347722Z","iopub.status.idle":"2021-11-24T15:32:35.352267Z","shell.execute_reply.started":"2021-11-24T15:32:35.347693Z","shell.execute_reply":"2021-11-24T15:32:35.351054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_pad_results = class_pad.fit_generator(train_generator,\n                                          class_weight=weights,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=10,\n                                         validation_data=test_generator)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-11-24T15:32:53.418499Z","iopub.execute_input":"2021-11-24T15:32:53.419181Z","iopub.status.idle":"2021-11-24T15:39:39.820639Z","shell.execute_reply.started":"2021-11-24T15:32:53.419142Z","shell.execute_reply":"2021-11-24T15:39:39.81988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(class_pad_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:40:34.568115Z","iopub.execute_input":"2021-11-24T15:40:34.568831Z","iopub.status.idle":"2021-11-24T15:40:34.8518Z","shell.execute_reply.started":"2021-11-24T15:40:34.56879Z","shell.execute_reply":"2021-11-24T15:40:34.851097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Analysis of Model**\n\nTraining accuracy is 89%, testing accuracy is 40%, so the model is overfitting more so than in the \"Adding another Convolutional layer\" model, which is identical to this one excpet for the padding. Training loss is 50% and testing loss is 129%; testing loss increased significantly from the \"Adding another Convolutional Layer\" model. It looks like this strategy of padding is making the model worse, so I will remove it. Additionally, because loss is a big problem, I am going to try decreasing network size and increasing dropout layers.","metadata":{}},{"cell_type":"markdown","source":"## **Model without Padding, a deleted Dense layer, Early Stopping, and more Epochs**","metadata":{}},{"cell_type":"code","source":"# Another Convolution layer; structure is modified from one shown on:\n# https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\nclass_ee = keras.Sequential()\nclass_ee.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(200,200,3)))\nclass_ee.add(layers.MaxPooling2D(2,2))\nclass_ee.add(layers.Conv2D(64, (3,3), activation='relu'))\nclass_ee.add(layers.MaxPooling2D(2,2))\nclass_ee.add(layers.Conv2D(128, (3,3), activation='relu'))\nclass_ee.add(layers.MaxPooling2D(2,2))\n\nclass_ee.add(layers.Flatten())\nclass_ee.add(layers.Dense(128, activation='relu'))\nclass_ee.add(layers.Dropout(0.3))\nclass_ee.add(layers.Dense(1, activation='sigmoid'))\n\nclass_ee.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])\nweights = {0: 1, # TUMOR\n          1:6.255} # NO TUMOR\n# there are 6.255 times as many images of MRIs with tumors than without","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:49:18.106011Z","iopub.execute_input":"2021-11-24T15:49:18.106705Z","iopub.status.idle":"2021-11-24T15:49:18.176293Z","shell.execute_reply.started":"2021-11-24T15:49:18.106666Z","shell.execute_reply":"2021-11-24T15:49:18.175564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stop2 = [EarlyStopping(monitor='val_loss', patience=12, restore_best_weights=True),\n            ModelCheckpoint(filepath='best_model.h5', monitor='val_loss',\n                           save_best_only=True)]","metadata":{"execution":{"iopub.status.busy":"2021-11-26T04:29:09.418251Z","iopub.execute_input":"2021-11-26T04:29:09.418500Z","iopub.status.idle":"2021-11-26T04:29:09.423508Z","shell.execute_reply.started":"2021-11-26T04:29:09.418472Z","shell.execute_reply":"2021-11-26T04:29:09.422233Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class_ee_results = class_ee.fit_generator(train_generator,\n                                          class_weight=weights,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=50,\n                                         validation_data=test_generator)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:49:24.335841Z","iopub.execute_input":"2021-11-24T15:49:24.336092Z","iopub.status.idle":"2021-11-24T15:54:51.330888Z","shell.execute_reply.started":"2021-11-24T15:49:24.336062Z","shell.execute_reply":"2021-11-24T15:54:51.330009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(class_ee_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T15:56:15.911933Z","iopub.execute_input":"2021-11-24T15:56:15.912213Z","iopub.status.idle":"2021-11-24T15:56:16.212917Z","shell.execute_reply.started":"2021-11-24T15:56:15.912184Z","shell.execute_reply":"2021-11-24T15:56:16.212124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Analysis of Model**\n\nTraining accuracy of the best epoch (epoch4) is around 88%, and testing accuracy is around 50%. Training loss is around 60% and testing loss is around 113%. Testing accuracy has improved by 10% since the last model, and testing loss has decreased by about sixteen percentage points, so removing a dense layer seems to be a slight improvement. I will try batch normalization to see if this helps train the model faster.","metadata":{}},{"cell_type":"markdown","source":"## **Model with Batch Normalization** ","metadata":{}},{"cell_type":"code","source":"# Another Convolution layer; structure is modified from one shown on:\n# https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\nclass_n = keras.Sequential()\nclass_n.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(200,200,3)))\nclass_n.add(layers.BatchNormalization())\nclass_n.add(layers.MaxPooling2D(2,2))\nclass_n.add(layers.Conv2D(64, (3,3), activation='relu'))\nclass_n.add(layers.BatchNormalization())\nclass_n.add(layers.MaxPooling2D(2,2))\nclass_n.add(layers.Conv2D(128, (3,3), activation='relu'))\nclass_n.add(layers.BatchNormalization())\nclass_n.add(layers.MaxPooling2D(2,2))\n\nclass_n.add(layers.Flatten())\nclass_n.add(layers.Dense(128, activation='relu'))\nclass_n.add(layers.Dropout(0.3))\nclass_n.add(layers.Dense(1, activation='sigmoid'))\n\nclass_n.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])\nweights = {0: 1, # TUMOR\n          1:6.255} # NO TUMOR\n# there are 6.255 times as many images of MRIs with tumors than without","metadata":{"execution":{"iopub.status.busy":"2021-11-24T16:05:30.443029Z","iopub.execute_input":"2021-11-24T16:05:30.443316Z","iopub.status.idle":"2021-11-24T16:05:30.831081Z","shell.execute_reply.started":"2021-11-24T16:05:30.443284Z","shell.execute_reply":"2021-11-24T16:05:30.830285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_n_results = class_n.fit_generator(train_generator,\n                                          class_weight=weights,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=20,\n                                         callbacks=early_stop2,\n                                         validation_data=test_generator)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T16:41:12.069124Z","iopub.execute_input":"2021-11-24T16:41:12.069453Z","iopub.status.idle":"2021-11-24T16:55:23.585424Z","shell.execute_reply.started":"2021-11-24T16:41:12.069417Z","shell.execute_reply":"2021-11-24T16:55:23.584724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(class_n_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T16:55:43.00109Z","iopub.execute_input":"2021-11-24T16:55:43.001723Z","iopub.status.idle":"2021-11-24T16:55:43.297814Z","shell.execute_reply.started":"2021-11-24T16:55:43.001684Z","shell.execute_reply":"2021-11-24T16:55:43.297117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The best model from epoch 14 had a training accuracy of around 94%, a testing accuracy of around 70%, a training loss of 30%, and a testing loss of around 84%. Accuracy and loss for both training and testing data is much improved since the last model and it is less overfit, so batch normalization is definitely an improvement. \nBecause batch normalization makes the network more stable, it is possible to use larger learning rates, which could potentially help the model reach optimal accuracy and minimal loss more quickly, so that is what I will try next.","metadata":{}},{"cell_type":"markdown","source":"## **Using a Bigger Learning Rate since I am using Batch Normalization**","metadata":{}},{"cell_type":"code","source":"adam_mlr = keras.optimizers.Adam(epsilon=0.01)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T20:35:11.092629Z","iopub.execute_input":"2021-11-24T20:35:11.092904Z","iopub.status.idle":"2021-11-24T20:35:11.09773Z","shell.execute_reply.started":"2021-11-24T20:35:11.092873Z","shell.execute_reply":"2021-11-24T20:35:11.096463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Another Convolution layer; structure is modified from one shown on:\n# https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\nclass_na = keras.Sequential()\nclass_na.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(200,200,3)))\nclass_na.add(layers.BatchNormalization())\nclass_na.add(layers.MaxPooling2D(2,2))\nclass_na.add(layers.Conv2D(64, (3,3), activation='relu'))\nclass_na.add(layers.BatchNormalization())\nclass_na.add(layers.MaxPooling2D(2,2))\nclass_na.add(layers.Conv2D(128, (3,3), activation='relu'))\nclass_na.add(layers.BatchNormalization())\nclass_na.add(layers.MaxPooling2D(2,2))\n\nclass_na.add(layers.Flatten())\nclass_na.add(layers.Dense(128, activation='relu'))\nclass_na.add(layers.Dropout(0.3))\nclass_na.add(layers.Dense(1, activation='sigmoid'))\n\nclass_na.compile(loss='binary_crossentropy',\n                optimizer=adam_mlr,\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])\nweights = {0: 1, # TUMOR\n          1:6.255} # NO TUMOR\n# there are 6.255 times as many images of MRIs with tumors than without","metadata":{"execution":{"iopub.status.busy":"2021-11-24T20:37:38.586941Z","iopub.execute_input":"2021-11-24T20:37:38.587241Z","iopub.status.idle":"2021-11-24T20:38:27.859592Z","shell.execute_reply.started":"2021-11-24T20:37:38.587208Z","shell.execute_reply":"2021-11-24T20:38:27.858869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_na_results = class_na.fit_generator(train_generator,\n                                          class_weight=weights,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=20,\n                                         callbacks=early_stop2,\n                                         validation_data=test_generator)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T20:38:32.583159Z","iopub.execute_input":"2021-11-24T20:38:32.584003Z","iopub.status.idle":"2021-11-24T20:58:02.248221Z","shell.execute_reply.started":"2021-11-24T20:38:32.583948Z","shell.execute_reply":"2021-11-24T20:58:02.247411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(class_na_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T20:59:06.074505Z","iopub.execute_input":"2021-11-24T20:59:06.074784Z","iopub.status.idle":"2021-11-24T20:59:06.404638Z","shell.execute_reply.started":"2021-11-24T20:59:06.074756Z","shell.execute_reply":"2021-11-24T20:59:06.403949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the best epoch of the model (epoch 20) training accuracy is 95% while testing accuracy is 74%. Training loss is 33%, while testing loss is 55%. Testing accuracy is higher by four percentage points than the last model, and loss has decreased by about 30%! Additionally, testing recall is 93%, which is important for the context of this problem. Since the last epoch was the best, it might be that the model has not yet reached optimal accuracy and minimal loss, so I am going to increase the number of epochs in the next model iteration.","metadata":{}},{"cell_type":"markdown","source":"## **Model with Batch Normalization, bigger learning rate, and more Epochs**","metadata":{}},{"cell_type":"code","source":"# Another Convolution layer; structure is modified from one shown on:\n# https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\nclass_nae = keras.Sequential()\nclass_nae.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(200,200,3)))\nclass_nae.add(layers.BatchNormalization())\nclass_nae.add(layers.MaxPooling2D(2,2))\nclass_nae.add(layers.Conv2D(64, (3,3), activation='relu'))\nclass_nae.add(layers.BatchNormalization())\nclass_nae.add(layers.MaxPooling2D(2,2))\nclass_nae.add(layers.Conv2D(128, (3,3), activation='relu'))\nclass_nae.add(layers.BatchNormalization())\nclass_nae.add(layers.MaxPooling2D(2,2))\n\nclass_nae.add(layers.Flatten())\nclass_nae.add(layers.Dense(128, activation='relu'))\nclass_nae.add(layers.Dropout(0.3))\nclass_nae.add(layers.Dense(1, activation='sigmoid'))\n\nclass_nae.compile(loss='binary_crossentropy',\n                optimizer=adam_mlr,\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])\nweights = {0: 1, # TUMOR\n          1:6.255} # NO TUMOR\n# there are 6.255 times as many images of MRIs with tumors than without","metadata":{"execution":{"iopub.status.busy":"2021-11-24T21:02:11.067909Z","iopub.execute_input":"2021-11-24T21:02:11.068417Z","iopub.status.idle":"2021-11-24T21:02:11.169888Z","shell.execute_reply.started":"2021-11-24T21:02:11.06838Z","shell.execute_reply":"2021-11-24T21:02:11.168969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_nae_results = class_nae.fit_generator(train_generator,\n                                          class_weight=weights,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=50,\n                                         callbacks=early_stop2,\n                                         validation_data=test_generator)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T21:02:58.392174Z","iopub.execute_input":"2021-11-24T21:02:58.392426Z","iopub.status.idle":"2021-11-24T21:33:45.998534Z","shell.execute_reply.started":"2021-11-24T21:02:58.392395Z","shell.execute_reply":"2021-11-24T21:33:45.997842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(class_nae_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T21:42:39.777787Z","iopub.execute_input":"2021-11-24T21:42:39.778071Z","iopub.status.idle":"2021-11-24T21:43:27.489562Z","shell.execute_reply.started":"2021-11-24T21:42:39.778042Z","shell.execute_reply":"2021-11-24T21:43:27.488863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Model with Batch Normalization and more Dropout Layers**","metadata":{}},{"cell_type":"code","source":"# Another Convolution layer; structure is modified from one shown on:\n# https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\nclass_nd = keras.Sequential()\n\nclass_nd.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(200,200,3)))\nclass_nd.add(layers.BatchNormalization())\nclass_nd.add(layers.MaxPooling2D(2,2))\nclass_nd.add(layers.Dropout(0.25))\n\nclass_nd.add(layers.Conv2D(64, (3,3), activation='relu'))\nclass_nd.add(layers.BatchNormalization())\nclass_nd.add(layers.MaxPooling2D(2,2))\nclass_nd.add(layers.Dropout(0.25))\n\nclass_nd.add(layers.Conv2D(128, (3,3), activation='relu'))\nclass_nd.add(layers.BatchNormalization())\nclass_nd.add(layers.MaxPooling2D(2,2))\nclass_nd.add(layers.Dropout(0.25))\n\nclass_nd.add(layers.Flatten())\nclass_nd.add(layers.Dense(128, activation='relu'))\nclass_nd.add(layers.Dropout(0.4))\nclass_nd.add(layers.Dense(1, activation='sigmoid'))\n\nclass_nd.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])\nweights = {0: 1, # TUMOR\n          1:6.255} # NO TUMOR\n# there are 6.255 times as many images of MRIs with tumors than without","metadata":{"execution":{"iopub.status.busy":"2021-11-24T18:13:21.068639Z","iopub.execute_input":"2021-11-24T18:13:21.069188Z","iopub.status.idle":"2021-11-24T18:13:21.173025Z","shell.execute_reply.started":"2021-11-24T18:13:21.06915Z","shell.execute_reply":"2021-11-24T18:13:21.172321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_nd_results = class_nd.fit_generator(train_generator,\n                                          class_weight=weights,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=20,\n                                          callbacks=early_stop2,\n                                         validation_data=test_generator)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T16:56:31.74861Z","iopub.execute_input":"2021-11-24T16:56:31.748868Z","iopub.status.idle":"2021-11-24T17:05:06.030348Z","shell.execute_reply.started":"2021-11-24T16:56:31.748838Z","shell.execute_reply":"2021-11-24T17:05:06.029565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(class_nd_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T19:12:36.682836Z","iopub.execute_input":"2021-11-24T19:12:36.683404Z","iopub.status.idle":"2021-11-24T19:12:36.705413Z","shell.execute_reply.started":"2021-11-24T19:12:36.683362Z","shell.execute_reply":"2021-11-24T19:12:36.704411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Training accuracy of the best epoch (epoch 1) is 91% while testing accuracy is 73%. Training loss is 56% while testing loss is 82%. This model is similar to the last one, except for the fact that training loss is significantly increased. The dropout layers added after each max pooling step may not be particularly beneficial to the model.","metadata":{}},{"cell_type":"markdown","source":"## **Going Back to Baseline, but adding Batch Normalization Layers**","metadata":{}},{"cell_type":"code","source":"# Building the first baseline model; structure is modified from one shown on:\n# https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\nbaseline_n = keras.Sequential()\nbaseline_n.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(200,200,3)))\nbaseline_n.add(layers.BatchNormalization())\nbaseline_n.add(layers.MaxPooling2D(2,2))\n\nbaseline_n.add(layers.Conv2D(64, (3,3), activation='relu'))\nbaseline_n.add(layers.BatchNormalization())\nbaseline_n.add(layers.MaxPooling2D(2,2))\n\nbaseline_n.add(layers.Flatten())\nbaseline_n.add(layers.Dense(128, activation='relu'))\nbaseline_n.add(layers.BatchNormalization())\nbaseline_n.add(layers.Dense(1, activation='sigmoid'))\n\nbaseline_n.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])","metadata":{"execution":{"iopub.status.busy":"2021-11-26T04:29:52.795160Z","iopub.execute_input":"2021-11-26T04:29:52.795622Z","iopub.status.idle":"2021-11-26T04:29:55.517069Z","shell.execute_reply.started":"2021-11-26T04:29:52.795584Z","shell.execute_reply":"2021-11-26T04:29:55.515446Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"baseline_n_results = baseline_n.fit_generator(train_generator,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=20,\n                                        callbacks=early_stop2,\n                                         validation_data=test_generator)","metadata":{"execution":{"iopub.status.busy":"2021-11-26T04:29:59.303924Z","iopub.execute_input":"2021-11-26T04:29:59.304821Z","iopub.status.idle":"2021-11-26T04:41:23.210233Z","shell.execute_reply.started":"2021-11-26T04:29:59.304771Z","shell.execute_reply":"2021-11-26T04:41:23.209475Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(baseline_n_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T18:03:17.838564Z","iopub.execute_input":"2021-11-24T18:03:17.838846Z","iopub.status.idle":"2021-11-24T18:03:18.160765Z","shell.execute_reply.started":"2021-11-24T18:03:17.838799Z","shell.execute_reply":"2021-11-24T18:03:18.159315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"baseline_n_pred = baseline_n.predict(test_generator)","metadata":{"execution":{"iopub.status.busy":"2021-11-26T05:07:00.205494Z","iopub.execute_input":"2021-11-26T05:07:00.205787Z","iopub.status.idle":"2021-11-26T05:07:04.801602Z","shell.execute_reply.started":"2021-11-26T05:07:00.205755Z","shell.execute_reply":"2021-11-26T05:07:04.800780Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# need to figure out how to get rid of the decimal point!\nnp.round(baseline_n_pred)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-11-26T05:13:48.958104Z","iopub.execute_input":"2021-11-26T05:13:48.958639Z","iopub.status.idle":"2021-11-26T05:13:48.970444Z","shell.execute_reply.started":"2021-11-26T05:13:48.958599Z","shell.execute_reply":"2021-11-26T05:13:48.969629Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"test_generator.classes","metadata":{"execution":{"iopub.status.busy":"2021-11-26T05:08:44.234792Z","iopub.execute_input":"2021-11-26T05:08:44.235419Z","iopub.status.idle":"2021-11-26T05:08:44.243232Z","shell.execute_reply.started":"2021-11-26T05:08:44.235377Z","shell.execute_reply":"2021-11-26T05:08:44.242533Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"wrong_index = []\nwrong_entry = []\nfor index, entry in enumerate(baseline_n_pred):\n    if entry != test_generator.classes[index]:\n        wrong_index.append(index)\n        wrong_entry.append(entry)","metadata":{"execution":{"iopub.status.busy":"2021-11-26T05:12:58.411508Z","iopub.execute_input":"2021-11-26T05:12:58.412084Z","iopub.status.idle":"2021-11-26T05:12:58.418471Z","shell.execute_reply.started":"2021-11-26T05:12:58.412045Z","shell.execute_reply":"2021-11-26T05:12:58.417591Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"wrong_index","metadata":{"execution":{"iopub.status.busy":"2021-11-26T05:13:06.681175Z","iopub.execute_input":"2021-11-26T05:13:06.681447Z","iopub.status.idle":"2021-11-26T05:13:06.695398Z","shell.execute_reply.started":"2021-11-26T05:13:06.681417Z","shell.execute_reply":"2021-11-26T05:13:06.694626Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# this code is from https://stackoverflow.com/questions/39300880/how-to-find-wrong-prediction-cases-in-test-set-cnns-using-keras\nfnames = test_generator.filenames ## fnames is all the filenames/samples used in testing\nerrors = np.where(baseline_n_pred != test_generator.classes)[0] ## misclassifications done on the test data where y_pred is the predicted values\nfor i in errors:\n    print(fnames[i])\n    ","metadata":{"execution":{"iopub.status.busy":"2021-11-26T05:01:30.374251Z","iopub.execute_input":"2021-11-26T05:01:30.374511Z","iopub.status.idle":"2021-11-26T05:01:49.618583Z","shell.execute_reply.started":"2021-11-26T05:01:30.374480Z","shell.execute_reply":"2021-11-26T05:01:49.617878Z"},"scrolled":true,"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"The best epoch of this model has a training accuracy of 93% and a testing accuracy of 80%. It has a training loss of 17% and a testing loss of 54%. This model has much better accuracy and much less loss than the last model, so adding batch normalization really helped.\n* look at epoch 10!","metadata":{}},{"cell_type":"markdown","source":"## **Going Back to Baseline, but adding Batch Normalization and a Dropout layer**","metadata":{}},{"cell_type":"code","source":"# Building the first baseline model; structure is modified from one shown on:\n# https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\nbaseline_nd = keras.Sequential()\nbaseline_nd.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(200,200,3)))\nbaseline_nd.add(layers.BatchNormalization())\nbaseline_nd.add(layers.MaxPooling2D(2,2))\n\nbaseline_nd.add(layers.Conv2D(64, (3,3), activation='relu'))\nbaseline_nd.add(layers.BatchNormalization())\nbaseline_nd.add(layers.MaxPooling2D(2,2))\n\nbaseline_nd.add(layers.Flatten())\nbaseline_nd.add(layers.Dense(128, activation='relu'))\nbaseline_nd.add(layers.Dropout(0.3))\nbaseline_nd.add(layers.BatchNormalization())\nbaseline_nd.add(layers.Dense(1, activation='sigmoid'))\n\nbaseline_nd.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])","metadata":{"execution":{"iopub.status.busy":"2021-11-24T18:19:34.322848Z","iopub.execute_input":"2021-11-24T18:19:34.323564Z","iopub.status.idle":"2021-11-24T18:19:34.408757Z","shell.execute_reply.started":"2021-11-24T18:19:34.323528Z","shell.execute_reply":"2021-11-24T18:19:34.408036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"baseline_nd_results = baseline_nd.fit_generator(train_generator,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=20,\n                                        callbacks=early_stop2,\n                                         validation_data=test_generator)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T18:19:38.541124Z","iopub.execute_input":"2021-11-24T18:19:38.541667Z","iopub.status.idle":"2021-11-24T18:33:28.949374Z","shell.execute_reply.started":"2021-11-24T18:19:38.541629Z","shell.execute_reply":"2021-11-24T18:33:28.948603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(baseline_nd_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T18:47:43.989569Z","iopub.execute_input":"2021-11-24T18:47:43.9902Z","iopub.status.idle":"2021-11-24T18:47:44.320407Z","shell.execute_reply.started":"2021-11-24T18:47:43.990159Z","shell.execute_reply":"2021-11-24T18:47:44.319676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The epoch with the best model (epoch 20) had a training accuracy of 94% and a testing accuracy of 76%. Training loss is 16% and testing loss is 54%.Testing accuracy is slightly less than the last model, so further tuning is necessary. Next I will try incorporating the class weights to account for the class imbalance.","metadata":{}},{"cell_type":"markdown","source":"## **Going back to Baseline, adding Class Weights**","metadata":{}},{"cell_type":"code","source":"\nbase_class = keras.Sequential()\nbase_class.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(200,200,3)))\nbase_class.add(layers.BatchNormalization())\nbase_class.add(layers.MaxPooling2D(2,2))\n\nbase_class.add(layers.Conv2D(64, (3,3), activation='relu'))\nbase_class.add(layers.BatchNormalization())\nbase_class.add(layers.MaxPooling2D(2,2))\n\nbase_class.add(layers.Flatten())\nbase_class.add(layers.Dense(128, activation='relu'))\nbase_class.add(layers.Dropout(0.3))\nbase_class.add(layers.BatchNormalization())\nbase_class.add(layers.Dense(1, activation='sigmoid'))\n\nbase_class.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])\nclass_weights2 = {0:1,\n                 1:4}","metadata":{"execution":{"iopub.status.busy":"2021-11-24T19:52:21.511695Z","iopub.execute_input":"2021-11-24T19:52:21.512412Z","iopub.status.idle":"2021-11-24T19:52:21.599912Z","shell.execute_reply.started":"2021-11-24T19:52:21.512375Z","shell.execute_reply":"2021-11-24T19:52:21.599213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_class_results =base_class.fit_generator(train_generator,\n                                        class_weight = weights,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=20,\n                                        callbacks=early_stop2,\n                                         validation_data=test_generator)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T21:49:10.411455Z","iopub.execute_input":"2021-11-24T21:49:10.4117Z","iopub.status.idle":"2021-11-24T21:57:55.584864Z","shell.execute_reply.started":"2021-11-24T21:49:10.411672Z","shell.execute_reply":"2021-11-24T21:57:55.584049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ihkhh","metadata":{"execution":{"iopub.status.busy":"2021-11-24T20:11:41.921375Z","iopub.execute_input":"2021-11-24T20:11:41.921882Z","iopub.status.idle":"2021-11-24T20:11:41.943521Z","shell.execute_reply.started":"2021-11-24T20:11:41.92184Z","shell.execute_reply":"2021-11-24T20:11:41.942711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}