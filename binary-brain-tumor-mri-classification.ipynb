{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","scrolled":true,"execution":{"iopub.status.busy":"2021-11-30T18:25:15.479665Z","iopub.execute_input":"2021-11-30T18:25:15.479984Z","iopub.status.idle":"2021-11-30T18:25:19.832013Z","shell.execute_reply.started":"2021-11-30T18:25:15.479902Z","shell.execute_reply":"2021-11-30T18:25:19.831326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set random state for numpy operations\nfrom numpy.random import seed\nseed(2)\n# Set random state for tensorflow operations\nfrom tensorflow.random import set_seed\nset_seed(3)\n# General imports\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import regularizers\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.models import load_model\nimport seaborn as sns\nfrom mlxtend.plotting import plot_decision_regions\nfrom sklearn.metrics import confusion_matrix\nimport cv2\nimport PIL","metadata":{"execution":{"iopub.status.busy":"2021-11-30T21:03:04.755679Z","iopub.execute_input":"2021-11-30T21:03:04.756268Z","iopub.status.idle":"2021-11-30T21:03:11.500218Z","shell.execute_reply.started":"2021-11-30T21:03:04.756234Z","shell.execute_reply":"2021-11-30T21:03:11.499337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Business Understanding**\n\nBrain tumors in particular are very difficult to diagnose from an MRI image, and artificial intelligence methods of identifying and classifying tumors are oftentimes more accurate than manual identification by a radiologist. That is why the development of neural networks and other AI processes for tumor classification is so valuable and important.\n\nThe survival rate for patients diagnosed with a brain tumor is around 35%. This survival rate could be increased if tumors could be identified earlier and more accurately, which AI methods could help with. Additionally, in third world countries, seasoned neurosurgeons (a neurosurgeon is required to make the diagnoses from looking at the MRI) are hard to come by, so a machine learning tool (Decision Support Tool) which could accurately identify tumors would be of great value in these developing nations. This decision support tool would be beneficial to the health industry, and the target audience would be Doctors without Borders, an organization which sends doctors from the US to developing countries to help improve their healthcare. ","metadata":{}},{"cell_type":"code","source":"\ndef visualize_training_results(history):\n    '''\n    From https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/\n    \n    Input: keras history object (output from trained model)\n    '''\n    fig, (ax1, ax2) = plt.subplots(2, sharex=True)\n    fig.suptitle('Model Results')\n\n    # summarize history for accuracy\n    ax1.plot(history.history['acc'])\n    ax1.plot(history.history['val_acc'])\n    ax1.set_ylabel('Accuracy')\n    ax1.legend(['train', 'test'], loc='upper left')\n    # summarize history for loss\n    ax2.plot(history.history['loss'])\n    ax2.plot(history.history['val_loss'])\n    ax2.set_ylabel('Loss')\n    ax2.legend(['train', 'test'], loc='upper left')\n    \n    plt.xlabel('Epoch')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-30T21:03:15.557635Z","iopub.execute_input":"2021-11-30T21:03:15.557982Z","iopub.status.idle":"2021-11-30T21:03:15.569102Z","shell.execute_reply.started":"2021-11-30T21:03:15.55793Z","shell.execute_reply":"2021-11-30T21:03:15.56776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set up ImageDataGenerator\ntrain_imagegen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\n                                   zoom_range=([0.6,1]),\n                                   rotation_range=10,                           \n                                   brightness_range=([0.6, 1.5]),\n                                   horizontal_flip=True,\n                                   validation_split=0.06) # this will set aside a part of training set for validation data\ntest_imagegen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\n                                   zoom_range=([0.6,1]),\n                                   rotation_range=10,\n                                   brightness_range=([0.6,1.5]),\n                                   horizontal_flip=True)\n# Bring the data in\ntrain_generator = train_imagegen.flow_from_directory(\n                                    '../input/resortedbraintumorclassificationmridata/Brain_MRI_Tumor_Images/Training',\n                                    target_size=(200,200),\n                                    batch_size=20,\n                                    seed=42,\n                                    class_mode='binary',\n                                    subset='training')\n\ntest_generator = test_imagegen.flow_from_directory(\n                                    '../input/resortedbraintumorclassificationmridata/Brain_MRI_Tumor_Images/Testing',\n                                    target_size=(200,200),\n                                    batch_size=20,\n                                    seed=42,\n                                    class_mode='binary')\n\nval_generator = train_imagegen.flow_from_directory(\n                                    '../input/resortedbraintumorclassificationmridata/Brain_MRI_Tumor_Images/Training',\n                                    target_size=(200,200),\n                                    batch_size=20,\n                                    seed=42,\n                                    class_mode='binary',\n                                    subset='validation')","metadata":{"execution":{"iopub.status.busy":"2021-11-30T21:03:19.837173Z","iopub.execute_input":"2021-11-30T21:03:19.837496Z","iopub.status.idle":"2021-11-30T21:03:21.612073Z","shell.execute_reply.started":"2021-11-30T21:03:19.837467Z","shell.execute_reply":"2021-11-30T21:03:21.609862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Data Understanding**","metadata":{}},{"cell_type":"markdown","source":"One important thing to note is that throughout the modelling process, I use train_generator as my training data images, and testing_generator as my testing set which I use every time I run a model to asses overfitting. Val_generator data is used only once on the final model, to asses how well the model does on data is has never seen before. This clarification is important because for every model that is run, all of the epochs are printed out, and the metrics/results for testing data are referred to as 'val.' Unless otherwise specified, any metric starting with 'val' in the epich print outs is really testing data.","metadata":{}},{"cell_type":"markdown","source":"## **Taking a Look at a few different individual images**","metadata":{}},{"cell_type":"code","source":"tumor1 = PIL.Image.open('../input/resortedbraintumorclassificationmridata/Brain_MRI_Tumor_Images/Training/AllTumorsTrain/p (274).jpg')\ntumor1","metadata":{"execution":{"iopub.status.busy":"2021-11-30T18:49:14.653592Z","iopub.execute_input":"2021-11-30T18:49:14.654161Z","iopub.status.idle":"2021-11-30T18:49:14.740142Z","shell.execute_reply.started":"2021-11-30T18:49:14.654117Z","shell.execute_reply":"2021-11-30T18:49:14.739489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Figuring out the number of color channels\ntumor1.mode\n# It is 'RGB', meaning that there are three color channels","metadata":{"execution":{"iopub.status.busy":"2021-11-30T18:51:52.443646Z","iopub.execute_input":"2021-11-30T18:51:52.443914Z","iopub.status.idle":"2021-11-30T18:51:52.450018Z","shell.execute_reply.started":"2021-11-30T18:51:52.443883Z","shell.execute_reply":"2021-11-30T18:51:52.449349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from https://stackoverflow.com/questions/48435229/how-to-plot-a-list-of-image-in-loop-using-matplotlib/48435411\nfig, axes = plt.subplots(2, 6, figsize=(18, 10))\nrows = 2\n\nfor num, x in enumerate(images):\n    img = PIL.Image.open(x)\n    re_img = img.resize((200,200))\n    ax = axes[num // 6, num % 6]\n    ax.imshow(re_img)\n    \n\nfig.suptitle('Normal Images on Top Row, Tumor Images on Bottom Row', fontsize=20)\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-30T18:48:05.852797Z","iopub.execute_input":"2021-11-30T18:48:05.85336Z","iopub.status.idle":"2021-11-30T18:48:07.417965Z","shell.execute_reply.started":"2021-11-30T18:48:05.85332Z","shell.execute_reply":"2021-11-30T18:48:07.417347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Taking a look at the class imbalance**","metadata":{}},{"cell_type":"markdown","source":"### **First looking at training data imbalance**","metadata":{}},{"cell_type":"code","source":"# looking at how the categories are encoded\ntrain_generator.class_indices\n# Tumor data is encoded as zero, no tumor data is encoded as one","metadata":{"execution":{"iopub.status.busy":"2021-11-30T18:51:58.557412Z","iopub.execute_input":"2021-11-30T18:51:58.55801Z","iopub.status.idle":"2021-11-30T18:51:58.562936Z","shell.execute_reply.started":"2021-11-30T18:51:58.557972Z","shell.execute_reply":"2021-11-30T18:51:58.562248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Looking at the place where all labels for training data are stored \ntrain_generator.classes","metadata":{"execution":{"iopub.status.busy":"2021-11-30T19:06:16.112995Z","iopub.execute_input":"2021-11-30T19:06:16.113283Z","iopub.status.idle":"2021-11-30T19:06:16.118291Z","shell.execute_reply.started":"2021-11-30T19:06:16.113239Z","shell.execute_reply":"2021-11-30T19:06:16.117457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Making a DataFrame out of the training data labels\ntrain_tumors = pd.DataFrame(train_generator.classes)\ntrain_values = train_tumors.value_counts()\ntrain_values","metadata":{"execution":{"iopub.status.busy":"2021-11-30T18:52:04.71711Z","iopub.execute_input":"2021-11-30T18:52:04.717689Z","iopub.status.idle":"2021-11-30T18:52:04.734154Z","shell.execute_reply.started":"2021-11-30T18:52:04.717649Z","shell.execute_reply":"2021-11-30T18:52:04.733481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **The ratio of images with tumors to those without is 2327:372, or 6.255:1.**","metadata":{}},{"cell_type":"code","source":"# Making subsets of the dataframe for visualization purposes\ntrain_tumors.rename(columns={0:'Tumor/No Tumor'}, inplace=True)\ntrain_no_tumor = len(train_tumors[train_tumors['Tumor/No Tumor'] == 1])\ntrain_tumor = len(train_tumors[train_tumors['Tumor/No Tumor'] == 0])","metadata":{"execution":{"iopub.status.busy":"2021-11-30T18:52:15.487178Z","iopub.execute_input":"2021-11-30T18:52:15.487451Z","iopub.status.idle":"2021-11-30T18:52:15.493137Z","shell.execute_reply.started":"2021-11-30T18:52:15.48742Z","shell.execute_reply":"2021-11-30T18:52:15.492343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Barplot for visually assessing the training data class imbalance\nplt.figure(figsize=(10,8))\nsns.set(font_scale=1.4)\nsns.barplot(['No Tumor', 'Tumor'], [train_no_tumor, train_tumor])\nplt.ylabel(\"Number of Images\")\nplt.title('Distribution of Brain MRIs with and without Tumor');\n","metadata":{"execution":{"iopub.status.busy":"2021-11-30T19:01:59.878214Z","iopub.execute_input":"2021-11-30T19:01:59.878833Z","iopub.status.idle":"2021-11-30T19:02:00.08256Z","shell.execute_reply.started":"2021-11-30T19:01:59.878795Z","shell.execute_reply":"2021-11-30T19:02:00.081869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Now taking a look at the test data imbalance**","metadata":{}},{"cell_type":"code","source":"# Making a DataFrame of testing data labels\ntest_tumors = pd.DataFrame(test_generator.classes)\ntest_values = test_tumors.value_counts()\ntest_values","metadata":{"execution":{"iopub.status.busy":"2021-11-30T18:52:30.674772Z","iopub.execute_input":"2021-11-30T18:52:30.67533Z","iopub.status.idle":"2021-11-30T18:52:30.686803Z","shell.execute_reply.started":"2021-11-30T18:52:30.675286Z","shell.execute_reply":"2021-11-30T18:52:30.686052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **The ratio of images with tumors to those without is 289:105, or 2.75:1**","metadata":{}},{"cell_type":"code","source":"# Making subsets of the dataframe for plotting purposes\ntest_tumors.rename(columns={0:'Tumor/No Tumor'}, inplace=True)\ntest_no_tumor = len(test_tumors[test_tumors['Tumor/No Tumor'] == 1])\ntest_tumor = len(test_tumors[test_tumors['Tumor/No Tumor'] == 0])","metadata":{"execution":{"iopub.status.busy":"2021-11-30T18:52:36.025889Z","iopub.execute_input":"2021-11-30T18:52:36.026387Z","iopub.status.idle":"2021-11-30T18:52:36.032597Z","shell.execute_reply.started":"2021-11-30T18:52:36.02635Z","shell.execute_reply":"2021-11-30T18:52:36.031465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Barplot for visually assessing the class imbalance in the testing data\nplt.figure(figsize=(10,8))\nsns.set(font_scale=1.4)\nsns.barplot(['No Tumor', 'Tumor'], [test_no_tumor, test_tumor])\nplt.ylabel(\"Number of Images\")\nplt.title('Distribution of Brain MRIs with and without Tumor in Testing Data');\n","metadata":{"execution":{"iopub.status.busy":"2021-11-30T19:03:24.482661Z","iopub.execute_input":"2021-11-30T19:03:24.483445Z","iopub.status.idle":"2021-11-30T19:03:24.692239Z","shell.execute_reply.started":"2021-11-30T19:03:24.483392Z","shell.execute_reply":"2021-11-30T19:03:24.691448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Baseline CNN Model**","metadata":{}},{"cell_type":"code","source":"# Building the first baseline model; structure is modified from one shown on:\n# https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\nbaseline = keras.Sequential()\nbaseline.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(200,200,3)))\nbaseline.add(layers.MaxPooling2D(2,2))\nbaseline.add(layers.Conv2D(64, (3,3), activation='relu'))\nbaseline.add(layers.MaxPooling2D(2,2))\n\nbaseline.add(layers.Flatten())\nbaseline.add(layers.Dense(128, activation='relu'))\nbaseline.add(layers.Dense(1, activation='sigmoid'))\n\nbaseline.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])","metadata":{"execution":{"iopub.status.busy":"2021-11-24T02:45:33.336344Z","iopub.execute_input":"2021-11-24T02:45:33.33662Z","iopub.status.idle":"2021-11-24T02:45:33.407653Z","shell.execute_reply.started":"2021-11-24T02:45:33.336589Z","shell.execute_reply":"2021-11-24T02:45:33.406686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"baseline_results = baseline.fit_generator(train_generator,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=10,\n                                         validation_data=test_generator)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T02:45:36.641381Z","iopub.execute_input":"2021-11-24T02:45:36.642247Z","iopub.status.idle":"2021-11-24T02:52:53.595216Z","shell.execute_reply.started":"2021-11-24T02:45:36.642183Z","shell.execute_reply":"2021-11-24T02:52:53.594217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(baseline_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T02:53:36.320213Z","iopub.execute_input":"2021-11-24T02:53:36.320509Z","iopub.status.idle":"2021-11-24T02:53:36.675247Z","shell.execute_reply.started":"2021-11-24T02:53:36.320477Z","shell.execute_reply":"2021-11-24T02:53:36.674256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Analysis of Model**\n\nLooking at the above graphs, it is obvious that this first baseline cnn model is overfitting; accuracy for training data ends up at around 94%, whereas testing data ends up at around 65%. Additionally, the loss for testing data is fairly high; for training the loss ends up at 15%, and for testing it ends up at 69%. In the next model iteration, I will add another dense layer, which will hopefully help the model pick up on more patterns, and some dropout layers for a form of regularization.","metadata":{}},{"cell_type":"markdown","source":"## **Adding another Dense layer and Dropout layers**","metadata":{}},{"cell_type":"code","source":"# Adding another dense layer and a couple of dropout layers; structure is modified from one shown on:\n# https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\nlayers_drop = keras.Sequential()\nlayers_drop.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(200,200,3)))\nlayers_drop.add(layers.MaxPooling2D(2,2))\nlayers_drop.add(layers.Conv2D(64, (3,3), activation='relu'))\nlayers_drop.add(layers.MaxPooling2D(2,2))\n\nlayers_drop.add(layers.Flatten())\nlayers_drop.add(layers.Dense(128, activation='relu'))\nlayers_drop.add(layers.Dropout(0.3))\nlayers_drop.add(layers.Dense(64, activation='relu'))\nlayers_drop.add(layers.Dropout(0.3))\nlayers_drop.add(layers.Dense(1, activation='sigmoid'))\n\nlayers_drop.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])","metadata":{"execution":{"iopub.status.busy":"2021-11-24T02:54:28.093148Z","iopub.execute_input":"2021-11-24T02:54:28.093473Z","iopub.status.idle":"2021-11-24T02:54:28.179478Z","shell.execute_reply.started":"2021-11-24T02:54:28.093441Z","shell.execute_reply":"2021-11-24T02:54:28.178548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fitting the model\nlayers_drop_results = layers_drop.fit_generator(train_generator,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=10,\n                                         validation_data=test_generator)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T02:54:31.190723Z","iopub.execute_input":"2021-11-24T02:54:31.191013Z","iopub.status.idle":"2021-11-24T03:02:25.353712Z","shell.execute_reply.started":"2021-11-24T02:54:31.190981Z","shell.execute_reply":"2021-11-24T03:02:25.352707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Look at how accuracy and loss change across the epochs, for training and testing data\nvisualize_training_results(layers_drop_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T03:02:25.35707Z","iopub.execute_input":"2021-11-24T03:02:25.357721Z","iopub.status.idle":"2021-11-24T03:02:25.713956Z","shell.execute_reply.started":"2021-11-24T03:02:25.357652Z","shell.execute_reply":"2021-11-24T03:02:25.712924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Analysis of Model**\n\nIn this iteration, training accuracy ends up at 93%, and testing ends up at 73%, so the model is overfitting, but less so than the baseline model. As for loss, training loss is 14% and testing loss is 65%, which is not drastically different from the last model. Adding another layer and dropout layers helped decrease overfitting. In the next model iteration I am going to account for the class imabalance, and the added layer and dropout layers might perform better in this iteration.","metadata":{}},{"cell_type":"markdown","source":"## **Accounting for class imbalance**","metadata":{}},{"cell_type":"code","source":"# Accounting for class imbalance; structure is modified from one shown on:\n# https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\n\nclass_ld = keras.Sequential()\nclass_ld.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(200,200,3)))\nclass_ld.add(layers.MaxPooling2D(2,2))\nclass_ld.add(layers.Conv2D(64, (3,3), activation='relu'))\nclass_ld.add(layers.MaxPooling2D(2,2))\n\nclass_ld.add(layers.Flatten())\nclass_ld.add(layers.Dense(128, activation='relu'))\nclass_ld.add(layers.Dropout(0.3))\nclass_ld.add(layers.Dense(64, activation='relu'))\nclass_ld.add(layers.Dropout(0.3))\nclass_ld.add(layers.Dense(1, activation='sigmoid'))\n\nclass_ld.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])\nweights = {0: 1, # TUMOR\n          1:6.255} # NO TUMOR \n# there are 6.255 times as many images of MRIs with tumors than without","metadata":{"execution":{"iopub.status.busy":"2021-11-26T09:50:15.985361Z","iopub.execute_input":"2021-11-26T09:50:15.985895Z","iopub.status.idle":"2021-11-26T09:50:16.057161Z","shell.execute_reply.started":"2021-11-26T09:50:15.985855Z","shell.execute_reply":"2021-11-26T09:50:16.056473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fitting the model\nclass_ld_results = class_ld.fit_generator(train_generator,\n                                          class_weight=weights,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=10,\n                                         validation_data=test_generator)","metadata":{"execution":{"iopub.status.busy":"2021-11-26T09:50:21.032446Z","iopub.execute_input":"2021-11-26T09:50:21.033137Z","iopub.status.idle":"2021-11-26T09:57:13.911394Z","shell.execute_reply.started":"2021-11-26T09:50:21.033085Z","shell.execute_reply":"2021-11-26T09:57:13.910554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Look at how accuracy and loss change across the epochs, for training and testing data\nvisualize_training_results(class_ld_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T03:13:43.566832Z","iopub.execute_input":"2021-11-24T03:13:43.567244Z","iopub.status.idle":"2021-11-24T03:13:44.024906Z","shell.execute_reply.started":"2021-11-24T03:13:43.567184Z","shell.execute_reply":"2021-11-24T03:13:44.023198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Analysis of Model**\n\nIn this model iteration, training accuracy was about 89% and testing accuracy is about 57%, so the model is still overfitting compared to the last model. Loss for training is at around 51% and testing loss is around 99%. In terms of acuracy and loss, the model is doing worse than the previous model. However, recall has increased significantly, so it seems that adding class weights is beneficial to the model, even though it requires further tuning.","metadata":{}},{"cell_type":"markdown","source":"## **Model with Batch Normalization** ","metadata":{}},{"cell_type":"code","source":"# Adding Batch Normalization; structure is modified from one shown on:\n# https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\nclass_n = keras.Sequential()\nclass_n.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(200,200,3)))\nclass_n.add(layers.BatchNormalization())\nclass_n.add(layers.MaxPooling2D(2,2))\nclass_n.add(layers.Conv2D(64, (3,3), activation='relu'))\nclass_n.add(layers.BatchNormalization())\nclass_n.add(layers.MaxPooling2D(2,2))\nclass_n.add(layers.Conv2D(128, (3,3), activation='relu'))\nclass_n.add(layers.BatchNormalization())\nclass_n.add(layers.MaxPooling2D(2,2))\n\nclass_n.add(layers.Flatten())\nclass_n.add(layers.Dense(128, activation='relu'))\nclass_n.add(layers.Dropout(0.3))\nclass_n.add(layers.Dense(1, activation='sigmoid'))\n\nclass_n.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])\nweights = {0: 1, # TUMOR\n          1:6.255} # NO TUMOR\n# there are 6.255 times as many images of MRIs with tumors than without","metadata":{"execution":{"iopub.status.busy":"2021-11-24T16:05:30.443029Z","iopub.execute_input":"2021-11-24T16:05:30.443316Z","iopub.status.idle":"2021-11-24T16:05:30.831081Z","shell.execute_reply.started":"2021-11-24T16:05:30.443284Z","shell.execute_reply":"2021-11-24T16:05:30.830285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stop2 = [EarlyStopping(monitor='val_loss', patience=12, restore_best_weights=True),\n            ModelCheckpoint(filepath='best_model.h5', monitor='val_loss',\n                           save_best_only=True)]","metadata":{"execution":{"iopub.status.busy":"2021-11-30T21:05:28.018453Z","iopub.execute_input":"2021-11-30T21:05:28.018747Z","iopub.status.idle":"2021-11-30T21:05:28.025008Z","shell.execute_reply.started":"2021-11-30T21:05:28.018707Z","shell.execute_reply":"2021-11-30T21:05:28.023794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_n_results = class_n.fit_generator(train_generator,\n                                          class_weight=weights,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=20,\n                                         callbacks=early_stop2,\n                                         validation_data=test_generator)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T16:41:12.069124Z","iopub.execute_input":"2021-11-24T16:41:12.069453Z","iopub.status.idle":"2021-11-24T16:55:23.585424Z","shell.execute_reply.started":"2021-11-24T16:41:12.069417Z","shell.execute_reply":"2021-11-24T16:55:23.584724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Look at how accuracy and loss change across the epochs, for training and testing data\nvisualize_training_results(class_n_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T16:55:43.00109Z","iopub.execute_input":"2021-11-24T16:55:43.001723Z","iopub.status.idle":"2021-11-24T16:55:43.297814Z","shell.execute_reply.started":"2021-11-24T16:55:43.001684Z","shell.execute_reply":"2021-11-24T16:55:43.297117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Analysis of Model**\n\nThe best model from epoch 14 had a training accuracy of around 94%, a testing accuracy of around 70%, a training loss of 30%, and a testing loss of around 84%. Accuracy and loss for both training and testing data is much improved since the last model and it is less overfit, so batch normalization is definitely an improvement.\nBecause batch normalization makes the network more stable, it is possible to use larger learning rates, which could potentially help the model reach optimal accuracy and minimal loss more quickly, so that is what I will try next.","metadata":{}},{"cell_type":"markdown","source":"## **Using a Bigger Learning Rate since I am using Batch Normalization**","metadata":{}},{"cell_type":"code","source":"# Establishing an instance of Adam with a bigger learning rate\nadam_mlr = keras.optimizers.Adam(epsilon=0.01)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T20:35:11.092629Z","iopub.execute_input":"2021-11-24T20:35:11.092904Z","iopub.status.idle":"2021-11-24T20:35:11.09773Z","shell.execute_reply.started":"2021-11-24T20:35:11.092873Z","shell.execute_reply":"2021-11-24T20:35:11.096463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using Batch Normalization; structure is modified from one shown on:\n# https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\nclass_na = keras.Sequential()\nclass_na.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(200,200,3)))\nclass_na.add(layers.BatchNormalization())\nclass_na.add(layers.MaxPooling2D(2,2))\nclass_na.add(layers.Conv2D(64, (3,3), activation='relu'))\nclass_na.add(layers.BatchNormalization())\nclass_na.add(layers.MaxPooling2D(2,2))\nclass_na.add(layers.Conv2D(128, (3,3), activation='relu'))\nclass_na.add(layers.BatchNormalization())\nclass_na.add(layers.MaxPooling2D(2,2))\n\nclass_na.add(layers.Flatten())\nclass_na.add(layers.Dense(128, activation='relu'))\nclass_na.add(layers.Dropout(0.3))\nclass_na.add(layers.Dense(1, activation='sigmoid'))\n\nclass_na.compile(loss='binary_crossentropy',\n                optimizer=adam_mlr,\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])\nweights = {0: 1, # TUMOR\n          1:6.255} # NO TUMOR\n# there are 6.255 times as many images of MRIs with tumors than without","metadata":{"execution":{"iopub.status.busy":"2021-11-24T20:37:38.586941Z","iopub.execute_input":"2021-11-24T20:37:38.587241Z","iopub.status.idle":"2021-11-24T20:38:27.859592Z","shell.execute_reply.started":"2021-11-24T20:37:38.587208Z","shell.execute_reply":"2021-11-24T20:38:27.858869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using a bigger learning rate; fitting the model\nclass_na_results = class_na.fit_generator(train_generator,\n                                          class_weight=weights,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=20,\n                                         callbacks=early_stop2,\n                                         validation_data=test_generator)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T20:38:32.583159Z","iopub.execute_input":"2021-11-24T20:38:32.584003Z","iopub.status.idle":"2021-11-24T20:58:02.248221Z","shell.execute_reply.started":"2021-11-24T20:38:32.583948Z","shell.execute_reply":"2021-11-24T20:58:02.247411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Look at how accuracy and loss change across the epochs, for training and testing data\nvisualize_training_results(class_na_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T20:59:06.074505Z","iopub.execute_input":"2021-11-24T20:59:06.074784Z","iopub.status.idle":"2021-11-24T20:59:06.404638Z","shell.execute_reply.started":"2021-11-24T20:59:06.074756Z","shell.execute_reply":"2021-11-24T20:59:06.403949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Analysis of Model**\n\nIn the best epoch of the model (epoch 20) training accuracy is 95% while testing accuracy is 74%. Training loss is 33%, while testing loss is 55%. Testing accuracy is higher by four percentage points than the last model, and loss has decreased by about 30%! Additionally, testing recall is 93%, which is important for the context of this problem. In the next iteration I am going to see if adding more dropout layers will be beneficial.","metadata":{}},{"cell_type":"markdown","source":"## **Model with Batch Normalization and more Dropout Layers**","metadata":{}},{"cell_type":"code","source":"# Accounting for the class imbalance; structure is modified from one shown on:\n# https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\nclass_nd = keras.Sequential()\n\nclass_nd.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(200,200,3)))\nclass_nd.add(layers.BatchNormalization())\nclass_nd.add(layers.MaxPooling2D(2,2))\nclass_nd.add(layers.Dropout(0.25))\n\nclass_nd.add(layers.Conv2D(64, (3,3), activation='relu'))\nclass_nd.add(layers.BatchNormalization())\nclass_nd.add(layers.MaxPooling2D(2,2))\nclass_nd.add(layers.Dropout(0.25))\n\nclass_nd.add(layers.Conv2D(128, (3,3), activation='relu'))\nclass_nd.add(layers.BatchNormalization())\nclass_nd.add(layers.MaxPooling2D(2,2))\nclass_nd.add(layers.Dropout(0.25))\n\nclass_nd.add(layers.Flatten())\nclass_nd.add(layers.Dense(128, activation='relu'))\nclass_nd.add(layers.Dropout(0.4))\nclass_nd.add(layers.Dense(1, activation='sigmoid'))\n\nclass_nd.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])\nweights = {0: 1, # TUMOR\n          1:6.255} # NO TUMOR\n# there are 6.255 times as many images of MRIs with tumors than without","metadata":{"execution":{"iopub.status.busy":"2021-11-24T18:13:21.068639Z","iopub.execute_input":"2021-11-24T18:13:21.069188Z","iopub.status.idle":"2021-11-24T18:13:21.173025Z","shell.execute_reply.started":"2021-11-24T18:13:21.06915Z","shell.execute_reply":"2021-11-24T18:13:21.172321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fitting the model\nclass_nd_results = class_nd.fit_generator(train_generator,\n                                          class_weight=weights,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=20,\n                                          callbacks=early_stop2,\n                                         validation_data=test_generator)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T16:56:31.74861Z","iopub.execute_input":"2021-11-24T16:56:31.748868Z","iopub.status.idle":"2021-11-24T17:05:06.030348Z","shell.execute_reply.started":"2021-11-24T16:56:31.748838Z","shell.execute_reply":"2021-11-24T17:05:06.029565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Look at how accuracy and loss change across the epochs, for training and testing data\nvisualize_training_results(class_nd_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T19:12:36.682836Z","iopub.execute_input":"2021-11-24T19:12:36.683404Z","iopub.status.idle":"2021-11-24T19:12:36.705413Z","shell.execute_reply.started":"2021-11-24T19:12:36.683362Z","shell.execute_reply":"2021-11-24T19:12:36.704411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Analysis of Model**\n\nTraining accuracy of the best epoch is 91% while testing accuracy is 73%. Training loss is 56% while testing loss is 82%. This model is similar to the last one, except for the fact that training loss is significantly increased. The dropout layers added after each max pooling step may not be particularly beneficial to the model.","metadata":{}},{"cell_type":"code","source":"# Getting the predicted labels for all images in testing data\nbaseline_n_pred = baseline_n.predict(test_generator)\nlen(baseline_n_pred)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-11-26T21:11:02.067353Z","iopub.execute_input":"2021-11-26T21:11:02.067707Z","iopub.status.idle":"2021-11-26T21:11:07.267239Z","shell.execute_reply.started":"2021-11-26T21:11:02.067661Z","shell.execute_reply":"2021-11-26T21:11:07.266256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Rounding the predictions and making sure all values are integer type so that they can be directly compared to the true labels, which are all ints\nbase_npred_round = np.round(baseline_n_pred)\nnpred_int = []\nfor entry in base_npred_round:\n    npred_int.append(int(entry))\nnpred_int","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-11-26T09:17:08.969587Z","iopub.execute_input":"2021-11-26T09:17:08.970185Z","iopub.status.idle":"2021-11-26T09:17:08.988228Z","shell.execute_reply.started":"2021-11-26T09:17:08.970137Z","shell.execute_reply":"2021-11-26T09:17:08.987532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Looking at true labels\ntest_generator.classes","metadata":{"execution":{"iopub.status.busy":"2021-11-26T09:13:10.584739Z","iopub.execute_input":"2021-11-26T09:13:10.585145Z","iopub.status.idle":"2021-11-26T09:13:10.591006Z","shell.execute_reply.started":"2021-11-26T09:13:10.585111Z","shell.execute_reply":"2021-11-26T09:13:10.590368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# I want to find out all of the indices of the incorrectly classified images, as well as their label\nwrong_index = []\nwrong_entry = []\nfor index, entry in enumerate(npred_int):\n    if entry != test_generator.classes[index]:\n        wrong_index.append(index)\n        wrong_entry.append(entry)\nwrong_index_entry = list(zip(wrong_index, wrong_entry))","metadata":{"execution":{"iopub.status.busy":"2021-11-26T22:03:59.328834Z","iopub.execute_input":"2021-11-26T22:03:59.329199Z","iopub.status.idle":"2021-11-26T22:03:59.358381Z","shell.execute_reply.started":"2021-11-26T22:03:59.329154Z","shell.execute_reply":"2021-11-26T22:03:59.356676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Getting a list of all file names of incorrectly classified tumors, so that I can view the images\nfnames = test_generator.filenames \nwrong_fnames = []\nfor i in wrong_index:\n    wrong_fnames.append(fnames[i])\nwrong_fnames","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-11-26T09:28:41.651268Z","iopub.execute_input":"2021-11-26T09:28:41.651964Z","iopub.status.idle":"2021-11-26T09:28:41.661439Z","shell.execute_reply.started":"2021-11-26T09:28:41.651921Z","shell.execute_reply":"2021-11-26T09:28:41.660575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Getting the predicted labels for all images in testing data\nbaseline_n_pred = baseline_n.predict(test_generator)\nlen(baseline_n_pred)\n\n# Rounding the predictions and making sure all values are integer type so that they can be directly compared to the true labels, which are all ints\nbase_npred_round = np.round(baseline_n_pred)\nnpred_int = []\nfor entry in base_npred_round:\n    npred_int.append(int(entry))\nnpred_int\n\n# Looking at true labels\ntest_generator.classes\n\n# I want to find out all of the indices of the incorrectly classified images, as well as their label\nwrong_index = []\nwrong_entry = []\nfor index, entry in enumerate(npred_int):\n    if entry != test_generator.classes[index]:\n        wrong_index.append(index)\n        wrong_entry.append(entry)\nwrong_index_entry = list(zip(wrong_index, wrong_entry))\n\n# Getting a list of all file names of incorrectly classified tumors, so that I can view the images\nfnames = test_generator.filenames \nwrong_fnames = []\nfor i in wrong_index:\n    wrong_fnames.append(fnames[i])\nwrong_fnames\n\n# A Glioma the network mislabelled as not having a tumor\nPIL.Image.open('../input/resortedbraintumorclassificationmridata/Brain_MRI_Tumor_Images/Testing/AllTumorsTest/Glioma14.jpg')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# A Glioma the network mislabelled as not having a tumor\nPIL.Image.open('../input/resortedbraintumorclassificationmridata/Brain_MRI_Tumor_Images/Testing/AllTumorsTest/Glioma14.jpg')","metadata":{"execution":{"iopub.status.busy":"2021-11-26T09:25:14.141862Z","iopub.execute_input":"2021-11-26T09:25:14.142606Z","iopub.status.idle":"2021-11-26T09:25:14.196823Z","shell.execute_reply.started":"2021-11-26T09:25:14.142567Z","shell.execute_reply":"2021-11-26T09:25:14.196122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# A Glioma the network mislabelled as not having a tumor\nPIL.Image.open('../input/resortedbraintumorclassificationmridata/Brain_MRI_Tumor_Images/Testing/AllTumorsTest/Glioma2.jpg')","metadata":{"execution":{"iopub.status.busy":"2021-11-26T09:36:41.928684Z","iopub.execute_input":"2021-11-26T09:36:41.929134Z","iopub.status.idle":"2021-11-26T09:36:42.017869Z","shell.execute_reply.started":"2021-11-26T09:36:41.929094Z","shell.execute_reply":"2021-11-26T09:36:42.017153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# A Glioma the network mislabelled as not having a tumor\nPIL.Image.open('../input/resortedbraintumorclassificationmridata/Brain_MRI_Tumor_Images/Testing/AllTumorsTest/Glioma23.jpg')","metadata":{"execution":{"iopub.status.busy":"2021-11-26T09:37:24.266691Z","iopub.execute_input":"2021-11-26T09:37:24.267213Z","iopub.status.idle":"2021-11-26T09:37:24.342003Z","shell.execute_reply.started":"2021-11-26T09:37:24.267177Z","shell.execute_reply":"2021-11-26T09:37:24.341216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# A Meningioma the network mislabelled as not having a tumor\nPIL.Image.open('../input/resortedbraintumorclassificationmridata/Brain_MRI_Tumor_Images/Testing/AllTumorsTest/Meningioma10.jpg')","metadata":{"execution":{"iopub.status.busy":"2021-11-26T09:38:10.570886Z","iopub.execute_input":"2021-11-26T09:38:10.571155Z","iopub.status.idle":"2021-11-26T09:38:10.594268Z","shell.execute_reply.started":"2021-11-26T09:38:10.571114Z","shell.execute_reply":"2021-11-26T09:38:10.593601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# A Meningioma the network mislabelled as not having a tumor\nPIL.Image.open('../input/resortedbraintumorclassificationmridata/Brain_MRI_Tumor_Images/Testing/AllTumorsTest/Meningioma17.jpg')","metadata":{"execution":{"iopub.status.busy":"2021-11-26T09:38:48.959811Z","iopub.execute_input":"2021-11-26T09:38:48.960067Z","iopub.status.idle":"2021-11-26T09:38:48.983851Z","shell.execute_reply.started":"2021-11-26T09:38:48.960038Z","shell.execute_reply":"2021-11-26T09:38:48.983156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# A Meningioma the network correctly identified as having a tumor\nPIL.Image.open('../input/resortedbraintumorclassificationmridata/Brain_MRI_Tumor_Images/Testing/AllTumorsTest/Meningioma19.jpg')","metadata":{"execution":{"iopub.status.busy":"2021-11-26T09:40:06.562196Z","iopub.execute_input":"2021-11-26T09:40:06.563079Z","iopub.status.idle":"2021-11-26T09:40:06.585006Z","shell.execute_reply.started":"2021-11-26T09:40:06.563037Z","shell.execute_reply":"2021-11-26T09:40:06.584362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The best epoch of this model has a training accuracy of 93% and a testing accuracy of 80%. It has a training loss of 17% and a testing loss of 54%. This model has much better accuracy and much less loss than the last model, so adding batch normalization really helped.\n* look at epoch 10!","metadata":{}},{"cell_type":"markdown","source":"## **Using the Pre-Trained VGG-19 Weights (this is my FSM)**","metadata":{"execution":{"iopub.status.busy":"2021-11-24T20:11:41.921375Z","iopub.execute_input":"2021-11-24T20:11:41.921882Z","iopub.status.idle":"2021-11-24T20:11:41.943521Z","shell.execute_reply.started":"2021-11-24T20:11:41.92184Z","shell.execute_reply":"2021-11-24T20:11:41.942711Z"}}},{"cell_type":"code","source":"from keras.applications.vgg19 import VGG19\ncnn_vgg = VGG19(weights='imagenet',\n               include_top=False,\n               input_shape=(200,200,3))","metadata":{"execution":{"iopub.status.busy":"2021-11-30T21:05:37.398027Z","iopub.execute_input":"2021-11-30T21:05:37.398307Z","iopub.status.idle":"2021-11-30T21:05:41.46886Z","shell.execute_reply.started":"2021-11-30T21:05:37.398277Z","shell.execute_reply":"2021-11-30T21:05:41.467872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn_vgg.summary()\n","metadata":{"execution":{"iopub.status.busy":"2021-11-30T04:18:42.504976Z","iopub.execute_input":"2021-11-30T04:18:42.505259Z","iopub.status.idle":"2021-11-30T04:18:42.522456Z","shell.execute_reply.started":"2021-11-30T04:18:42.50523Z","shell.execute_reply":"2021-11-30T04:18:42.521617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build first model using pretrained VGG 19 as first layer, and then some dense layers on top\npretrained = keras.Sequential()\npretrained.add(cnn_vgg)\npretrained.add(layers.Flatten())\npretrained.add(layers.Dense(128, activation='relu'))\npretrained.add(layers.Dense(1, activation='sigmoid'))","metadata":{"execution":{"iopub.status.busy":"2021-11-30T00:59:25.806903Z","iopub.execute_input":"2021-11-30T00:59:25.807332Z","iopub.status.idle":"2021-11-30T00:59:26.145142Z","shell.execute_reply.started":"2021-11-30T00:59:25.807288Z","shell.execute_reply":"2021-11-30T00:59:26.144376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Freeze_Pretrained_Base(pretrain, network):\n    pretrain.trainable = False\n    for layer in network.layers:\n        print(layer.name, layer.trainable)\n    print(len(network.trainable_weights))","metadata":{"execution":{"iopub.status.busy":"2021-11-30T21:05:45.482863Z","iopub.execute_input":"2021-11-30T21:05:45.483158Z","iopub.status.idle":"2021-11-30T21:05:45.48968Z","shell.execute_reply.started":"2021-11-30T21:05:45.483114Z","shell.execute_reply":"2021-11-30T21:05:45.488449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Freeze_Pretrained_Base(cnn_vgg, pretrained)","metadata":{"execution":{"iopub.status.busy":"2021-11-30T00:59:40.39203Z","iopub.execute_input":"2021-11-30T00:59:40.392283Z","iopub.status.idle":"2021-11-30T00:59:40.399368Z","shell.execute_reply.started":"2021-11-30T00:59:40.392255Z","shell.execute_reply":"2021-11-30T00:59:40.39824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\npretrained.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])\n\npretrained_results = pretrained.fit_generator(train_generator,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=20,\n                                        callbacks= early_stop2,\n                                         validation_data=test_generator)","metadata":{"execution":{"iopub.status.busy":"2021-11-30T00:59:46.050978Z","iopub.execute_input":"2021-11-30T00:59:46.05152Z","iopub.status.idle":"2021-11-30T01:04:44.507182Z","shell.execute_reply.started":"2021-11-30T00:59:46.051486Z","shell.execute_reply":"2021-11-30T01:04:44.504743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Look at how accuracy and loss change across the epochs, for training and testing data\nvisualize_training_results(pretrained_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-26T22:24:37.259247Z","iopub.execute_input":"2021-11-26T22:24:37.259579Z","iopub.status.idle":"2021-11-26T22:24:37.647134Z","shell.execute_reply.started":"2021-11-26T22:24:37.259548Z","shell.execute_reply":"2021-11-26T22:24:37.646176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Analysis of Model**\nThe epoch with the lowest loss had a training accuracy of ~98% and a loss of ~4%, while the testing data had an accuracy of ~93% and a loss of ~21%! This is the best model yet! Additionally, testing recall is ~95%, which means that false negatives are being minimized. Using the VGG19 pretrained weights was a game changer! However, it would be great if the testing loss could be just a bit lower, so in the next model iteration I will use the SGD optimizer with momentum, since it is known for rapidly decreasing loss.","metadata":{}},{"cell_type":"markdown","source":"## **Unfreezing Layers in the Pretrained VGG-19 Network**","metadata":{}},{"cell_type":"code","source":"# Build first model using pretrained VGG 19 as first layer, and then some dense layers on top\nb5c1c2 = keras.Sequential()\nb5c1c2.add(cnn_vgg)\nb5c1c2.add(layers.Flatten())\nb5c1c2.add(layers.Dense(128, activation='relu'))\nb5c1c2.add(layers.Dense(1, activation='sigmoid'))","metadata":{"execution":{"iopub.status.busy":"2021-11-30T01:08:54.431012Z","iopub.execute_input":"2021-11-30T01:08:54.431267Z","iopub.status.idle":"2021-11-30T01:08:54.508865Z","shell.execute_reply.started":"2021-11-30T01:08:54.431238Z","shell.execute_reply":"2021-11-30T01:08:54.508158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# List for unfreezing of layers function\nunfreeze = ['block5_conv1', 'block5_conv2']","metadata":{"execution":{"iopub.status.busy":"2021-11-30T21:05:54.998336Z","iopub.execute_input":"2021-11-30T21:05:54.998587Z","iopub.status.idle":"2021-11-30T21:05:55.005044Z","shell.execute_reply.started":"2021-11-30T21:05:54.99856Z","shell.execute_reply":"2021-11-30T21:05:55.002209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Re-freezing everything except for the last layer of the pretrained CNN\n# Code structure from https://github.com/learn-co-curriculum/dsc-using-pretrained-networks-codealong\ndef Unfreeze_Layers(pretrain, layer_list):\n    pretrain.trainable = True\n    for layer in  pretrain.layers:\n        if layer.name in layer_list:\n            layer.trainable = True\n        else:\n            layer.trainable = False\n        \n    for layer in pretrain.layers:\n        print(layer.name, layer.trainable)\n    print(len(pretrain.trainable_weights))","metadata":{"execution":{"iopub.status.busy":"2021-11-30T21:05:50.606256Z","iopub.execute_input":"2021-11-30T21:05:50.606797Z","iopub.status.idle":"2021-11-30T21:05:50.613627Z","shell.execute_reply.started":"2021-11-30T21:05:50.606697Z","shell.execute_reply":"2021-11-30T21:05:50.612323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Unfreezing some of outer layers of VGG19 pretrained network\nUnfreeze_Layers(cnn_vgg, unfreeze)","metadata":{"execution":{"iopub.status.busy":"2021-11-30T04:19:23.962868Z","iopub.execute_input":"2021-11-30T04:19:23.96367Z","iopub.status.idle":"2021-11-30T04:19:23.9777Z","shell.execute_reply.started":"2021-11-30T04:19:23.963618Z","shell.execute_reply":"2021-11-30T04:19:23.976588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compiling and Fitting the model\nb5c1c2.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])\n\nb5c1c2_results = b5c1c2.fit_generator(train_generator,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=20,\n                                        callbacks= early_stop2,\n                                         validation_data=test_generator)","metadata":{"execution":{"iopub.status.busy":"2021-11-30T01:09:17.539772Z","iopub.execute_input":"2021-11-30T01:09:17.540564Z","iopub.status.idle":"2021-11-30T01:10:13.761025Z","shell.execute_reply.started":"2021-11-30T01:09:17.540518Z","shell.execute_reply":"2021-11-30T01:10:13.75673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Analysis of Model**\n\nThe epoch with the lowest testing los has a trining accuracy of 98% and a testing accuracy of 92%, with a training loss of 5% and a testing loss of 27%. Testing recall is 75%. Other than recall, the results are similar to the previous model; maybe including class weights will help improve the model.","metadata":{}},{"cell_type":"markdown","source":"## **Incorporating Class Weights into Pretrained VGG19 model**","metadata":{}},{"cell_type":"code","source":"# Build first model using pretrained VGG 19 as first layer, and then some dense layers on top\nw_b5c1c2 = keras.Sequential()\nw_b5c1c2.add(cnn_vgg)\nw_b5c1c2.add(layers.Flatten())\nw_b5c1c2.add(layers.Dense(128, activation='relu'))\nw_b5c1c2.add(layers.Dense(1, activation='sigmoid'))","metadata":{"execution":{"iopub.status.busy":"2021-11-30T15:03:23.467919Z","iopub.execute_input":"2021-11-30T15:03:23.468472Z","iopub.status.idle":"2021-11-30T15:03:23.545456Z","shell.execute_reply.started":"2021-11-30T15:03:23.468433Z","shell.execute_reply":"2021-11-30T15:03:23.544798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Incorporating class weights; compiling and fitting the model\nweights = {0: 1, # TUMOR\n          1:6.255} # NO TUMOR \n# there are 6.255 times as many images of MRIs with tumors than without\n\n\nw_b5c1c2.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])\n\nw_b5c1c2_results = w_b5c1c2.fit_generator(train_generator,\n                                          class_weight = weights,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=20,\n                                        callbacks= early_stop2,\n                                         validation_data=test_generator)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-30T15:03:30.058262Z","iopub.execute_input":"2021-11-30T15:03:30.058516Z","iopub.status.idle":"2021-11-30T15:25:31.568002Z","shell.execute_reply.started":"2021-11-30T15:03:30.058488Z","shell.execute_reply":"2021-11-30T15:25:31.567221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Analysis of Model**\n\nThe epoch with the lowest testing loss had a training accuracy of 98% and a testing accuracy of 94%, with a training loss of 7% and a testing loss of 22%. Testing recall 97%. Overall, because the recall is higher, this model is better than the first model iteration done using the pretrained VGG19 network.","metadata":{}},{"cell_type":"markdown","source":"## **Adjusting Class Weights and adding a Dropout Layer**","metadata":{}},{"cell_type":"code","source":"# Build first model using pretrained VGG 19 as first layer, and then some dense layers on top\nw2_b5c1c2 = keras.Sequential()\nw2_b5c1c2.add(cnn_vgg)\nw2_b5c1c2.add(layers.Dropout(0.4))\nw2_b5c1c2.add(layers.Flatten())\nw2_b5c1c2.add(layers.Dense(128, activation='relu'))\nw2_b5c1c2.add(layers.Dense(1, activation='sigmoid'))","metadata":{"execution":{"iopub.status.busy":"2021-11-30T21:06:15.111668Z","iopub.execute_input":"2021-11-30T21:06:15.112551Z","iopub.status.idle":"2021-11-30T21:06:15.227621Z","shell.execute_reply.started":"2021-11-30T21:06:15.112502Z","shell.execute_reply":"2021-11-30T21:06:15.226463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Freeze_Pretrained_Base(cnn_vgg, w2_b5c1c2 )","metadata":{"execution":{"iopub.status.busy":"2021-11-30T21:06:17.27138Z","iopub.execute_input":"2021-11-30T21:06:17.271724Z","iopub.status.idle":"2021-11-30T21:06:17.283466Z","shell.execute_reply.started":"2021-11-30T21:06:17.271676Z","shell.execute_reply":"2021-11-30T21:06:17.282069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Unfreeze_Layers(cnn_vgg, unfreeze)","metadata":{"execution":{"iopub.status.busy":"2021-11-30T21:06:19.710451Z","iopub.execute_input":"2021-11-30T21:06:19.710989Z","iopub.status.idle":"2021-11-30T21:06:19.730224Z","shell.execute_reply.started":"2021-11-30T21:06:19.710957Z","shell.execute_reply":"2021-11-30T21:06:19.729047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nweights2 = {0: 1, # TUMOR\n          1:4} # NO TUMOR \n\n\n\nw2_b5c1c2.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])\n\nw2_b5c1c2_results = w2_b5c1c2.fit_generator(train_generator,\n                                          class_weight = weights2,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=20,\n                                        callbacks= early_stop2,\n                                         validation_data=test_generator)","metadata":{"execution":{"iopub.status.busy":"2021-11-30T19:29:24.543696Z","iopub.execute_input":"2021-11-30T19:29:24.543951Z","iopub.status.idle":"2021-11-30T19:52:46.496388Z","shell.execute_reply.started":"2021-11-30T19:29:24.543922Z","shell.execute_reply":"2021-11-30T19:52:46.495692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Analysis of Model**\n\nThe epoch with the lowest testing loss has a training accuracy of 98% and a testing accuracy of 95%, with a training loss of 8% and a testing loss of 19%. Testing recall is 97%. This model is better than all iterations using VGG19 thus far, due to the high recall percentage in this epoch, as well as all epochs","metadata":{}},{"cell_type":"code","source":"w2_b5c1c2.save(\"w2_b5c1c2.h5\")","metadata":{"execution":{"iopub.status.busy":"2021-11-30T21:08:00.469388Z","iopub.execute_input":"2021-11-30T21:08:00.469735Z","iopub.status.idle":"2021-11-30T21:08:00.67447Z","shell.execute_reply.started":"2021-11-30T21:08:00.469676Z","shell.execute_reply":"2021-11-30T21:08:00.673469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = keras.models.load_model(\"../input/resortedbraintumorclassificationmridata/w2_b5c1c2.h5\")\n#'../input/resortedbraintumorclassificationmridata/Brain_MRI_Tumor_Images/Training'","metadata":{"execution":{"iopub.status.busy":"2021-11-30T21:12:07.572426Z","iopub.execute_input":"2021-11-30T21:12:07.572758Z","iopub.status.idle":"2021-11-30T21:12:07.602225Z","shell.execute_reply.started":"2021-11-30T21:12:07.5727Z","shell.execute_reply":"2021-11-30T21:12:07.601011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Now testing out final model on Validation data**","metadata":{}},{"cell_type":"code","source":"# Build first model using pretrained VGG 19 as first layer, and then some dense layers on top\nval_w2_b5c1c2 = keras.Sequential()\nval_w2_b5c1c2.add(cnn_vgg)\nval_w2_b5c1c2.add(layers.Dropout(0.4))\nval_w2_b5c1c2.add(layers.Flatten())\nval_w2_b5c1c2.add(layers.Dense(128, activation='relu'))\nval_w2_b5c1c2.add(layers.Dense(1, activation='sigmoid'))","metadata":{"execution":{"iopub.status.busy":"2021-11-30T19:57:58.831665Z","iopub.execute_input":"2021-11-30T19:57:58.831985Z","iopub.status.idle":"2021-11-30T19:57:58.954086Z","shell.execute_reply.started":"2021-11-30T19:57:58.831943Z","shell.execute_reply":"2021-11-30T19:57:58.953338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Freeze_Pretrained_Base(cnn_vgg, val_w2_b5c1c2 )","metadata":{"execution":{"iopub.status.busy":"2021-11-30T19:58:03.793009Z","iopub.execute_input":"2021-11-30T19:58:03.793283Z","iopub.status.idle":"2021-11-30T19:58:03.801727Z","shell.execute_reply.started":"2021-11-30T19:58:03.793239Z","shell.execute_reply":"2021-11-30T19:58:03.800299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Unfreeze_Layers(cnn_vgg, unfreeze)","metadata":{"execution":{"iopub.status.busy":"2021-11-30T19:58:05.60041Z","iopub.execute_input":"2021-11-30T19:58:05.601017Z","iopub.status.idle":"2021-11-30T19:58:05.614937Z","shell.execute_reply.started":"2021-11-30T19:58:05.60098Z","shell.execute_reply":"2021-11-30T19:58:05.61394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nweights2 = {0: 1, # TUMOR\n          1:4} # NO TUMOR \n\n\n\nval_w2_b5c1c2.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])\n\nval_w2_b5c1c2_results = val_w2_b5c1c2.fit_generator(train_generator,\n                                          class_weight = weights2,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=20,\n                                        callbacks= early_stop2,\n                                         validation_data=val_generator)","metadata":{"execution":{"iopub.status.busy":"2021-11-30T19:58:21.085139Z","iopub.execute_input":"2021-11-30T19:58:21.085725Z","iopub.status.idle":"2021-11-30T20:12:27.955136Z","shell.execute_reply.started":"2021-11-30T19:58:21.085685Z","shell.execute_reply":"2021-11-30T20:12:27.954339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Analysis of Model**\n\nThe epoch with the lowest validation loss had a training accuracy of 97% and a validation accuracy of 99%, with a training loss of 12% and a validation loss of 2%. Validation recall is 100%. The model has excellent performance on data it has not seen before! However, because the validation set was drawn from the training set in the image data generator (before the training data had actually been used to train any models) the class imbalance should be very similar to the class imbalance of the training data, so this is probably a big reason why the model is performing so well on the validation data.","metadata":{}},{"cell_type":"markdown","source":"## **Using the Pretrained VGG-19 network again, but with an SGD Optimizer**","metadata":{}},{"cell_type":"code","source":"# Build first model using pretrained VGG 19 as first layer, and then some dense layers on top\nvgg19_sgd = keras.Sequential()\nvgg19_sgd.add(cnn_vgg)\nvgg19_sgd.add(layers.Flatten())\nvgg19_sgd.add(layers.Dense(128, activation='relu'))\nvgg19_sgd.add(layers.Dense(1, activation='sigmoid'))","metadata":{"execution":{"iopub.status.busy":"2021-11-30T20:56:21.708198Z","iopub.execute_input":"2021-11-30T20:56:21.708507Z","iopub.status.idle":"2021-11-30T20:56:21.795041Z","shell.execute_reply.started":"2021-11-30T20:56:21.708408Z","shell.execute_reply":"2021-11-30T20:56:21.793617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make the pretrianed layer untrainable so that during optimization, its weights don't change\ncnn_vgg.trainable = False","metadata":{"execution":{"iopub.status.busy":"2021-11-28T21:57:30.618449Z","iopub.execute_input":"2021-11-28T21:57:30.619255Z","iopub.status.idle":"2021-11-28T21:57:30.624643Z","shell.execute_reply.started":"2021-11-28T21:57:30.619205Z","shell.execute_reply":"2021-11-28T21:57:30.623936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check to see that the pretrained layer is not trainable but that all others are\nfor layer in vgg19_sgd.layers:\n    print(layer.name, layer.trainable)\n    \nprint(len(vgg19_sgd.trainable_weights))","metadata":{"execution":{"iopub.status.busy":"2021-11-28T21:57:32.742766Z","iopub.execute_input":"2021-11-28T21:57:32.743383Z","iopub.status.idle":"2021-11-28T21:57:32.75018Z","shell.execute_reply.started":"2021-11-28T21:57:32.743342Z","shell.execute_reply":"2021-11-28T21:57:32.749121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sgd_momen = keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n\n\n\nvgg19_sgd.compile(loss='binary_crossentropy',\n                optimizer= sgd_momen,\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])\n\nvgg19_sgd_results = vgg19_sgd.fit_generator(train_generator,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=20,\n                                        callbacks= early_stop2,\n                                         validation_data=test_generator)","metadata":{"execution":{"iopub.status.busy":"2021-11-28T22:14:02.14284Z","iopub.execute_input":"2021-11-28T22:14:02.143511Z","iopub.status.idle":"2021-11-28T22:28:33.71107Z","shell.execute_reply.started":"2021-11-28T22:14:02.143474Z","shell.execute_reply":"2021-11-28T22:28:33.710353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Analysis of Model**\n\nThe epoch with the lowest testing loss had a training accuracy of 96% and a testing accuracy of 83%, with a training loss of 11% and a testing loss of 33%. Testing recall is 71%. Although the results from this model iteration, using SGD with momentum instead of Adam as an optimizer, they are not as good as the previous model iteration which used Adam, so it looks like Adam is the best optimizer to use in this situation.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}