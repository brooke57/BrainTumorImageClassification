{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Brain Tumor MRI Multiclass Classification**","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","scrolled":true,"execution":{"iopub.status.busy":"2022-02-09T04:42:09.921747Z","iopub.execute_input":"2022-02-09T04:42:09.924900Z","iopub.status.idle":"2022-02-09T04:42:11.480573Z","shell.execute_reply.started":"2022-02-09T04:42:09.924737Z","shell.execute_reply":"2022-02-09T04:42:11.479562Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Re-freezing everything except for the last layer of the pretrained CNN\ndef Unfreeze_Layers(pretrain, layer_list):\n    \n    '''pretrain: takes as an argument an imported, pretrained neural network\n        layer_list: take a list with the layers that are to be unfrozen\n    '''\n    pretrain.trainable = True\n    for layer in  pretrain.layers:\n        if layer.name in layer_list:\n            layer.trainable = True\n        else:\n            layer.trainable = False\n        \n    for layer in pretrain.layers:\n        print(layer.name, layer.trainable)\n    print(len(pretrain.trainable_weights))","metadata":{"execution":{"iopub.status.busy":"2022-02-09T04:42:17.806019Z","iopub.execute_input":"2022-02-09T04:42:17.806378Z","iopub.status.idle":"2022-02-09T04:42:17.812895Z","shell.execute_reply.started":"2022-02-09T04:42:17.806348Z","shell.execute_reply":"2022-02-09T04:42:17.811905Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def Freeze_Pretrained_Base(pretrain, network):\n    \n    '''pretrain: takes as an argument an imported, pretrained neural network\n       network: take the name of an established neural network\n    '''\n    pretrain.trainable = False\n    for layer in network.layers:\n        print(layer.name, layer.trainable)\n    print(len(network.trainable_weights))","metadata":{"execution":{"iopub.status.busy":"2022-02-09T04:42:19.862359Z","iopub.execute_input":"2022-02-09T04:42:19.863364Z","iopub.status.idle":"2022-02-09T04:42:19.869582Z","shell.execute_reply.started":"2022-02-09T04:42:19.863320Z","shell.execute_reply":"2022-02-09T04:42:19.868743Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def visualize_training_results(history):\n    '''\n    From https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/\n    \n    Input: keras history object (output from trained model)\n    '''\n    fig, (ax1, ax2) = plt.subplots(2, sharex=True)\n    fig.suptitle('Model Results')\n\n    # summarize history for accuracy\n    ax1.plot(history.history['acc'])\n    ax1.plot(history.history['val_acc'])\n    ax1.set_ylabel('Accuracy')\n    ax1.legend(['train', 'test'], loc='upper left')\n    # summarize history for loss\n    ax2.plot(history.history['loss'])\n    ax2.plot(history.history['val_loss'])\n    ax2.set_ylabel('Loss')\n    ax2.legend(['train', 'test'], loc='upper left')\n    \n    plt.xlabel('Epoch')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-09T04:42:22.615064Z","iopub.execute_input":"2022-02-09T04:42:22.615950Z","iopub.status.idle":"2022-02-09T04:42:22.625357Z","shell.execute_reply.started":"2022-02-09T04:42:22.615914Z","shell.execute_reply":"2022-02-09T04:42:22.624353Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def f1_score(model_eval):\n    \n    '''takes as an argument a model that has been evaluated with the \".evaluate\" method'''\n    \n    return 'F1 Score:',(2* model_eval[4]*model_eval[3])/(model_eval[3]+model_eval[4])","metadata":{"execution":{"iopub.status.busy":"2022-02-09T04:42:25.215773Z","iopub.execute_input":"2022-02-09T04:42:25.216423Z","iopub.status.idle":"2022-02-09T04:42:25.221597Z","shell.execute_reply.started":"2022-02-09T04:42:25.216387Z","shell.execute_reply":"2022-02-09T04:42:25.220090Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Set random state for numpy operations\nfrom numpy.random import seed\nseed(2)\n# Set random state for tensorflow operations\nfrom tensorflow.random import set_seed\nset_seed(3)\n# General imports\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow import keras\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import regularizers\nfrom keras.regularizers import l2\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom keras.models import load_model\nimport seaborn as sns\nfrom mlxtend.plotting import plot_decision_regions\nfrom sklearn.metrics import multilabel_confusion_matrix, ConfusionMatrixDisplay\nimport cv2\nimport PIL","metadata":{"execution":{"iopub.status.busy":"2022-02-09T04:42:27.593028Z","iopub.execute_input":"2022-02-09T04:42:27.593634Z","iopub.status.idle":"2022-02-09T04:42:34.832129Z","shell.execute_reply.started":"2022-02-09T04:42:27.593597Z","shell.execute_reply":"2022-02-09T04:42:34.831241Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## **Data Augmentation and Resizing**","metadata":{}},{"cell_type":"markdown","source":"Because a total of 2,870 files (number of files in the training set) is a pretty small number of images to use for training a neural network, data augmentation is key, since it can help mimic the effect of having a larger number of images. The way I implemented these techiques was by using the ImageDataGenerator from Keras. The features I decided to tweak for augmentation were zoom range, rotation range, brightness range, and horizontal flipping. I decided to provided a range of different zoom values and rotation degrees because how much zoom and the angle of how the brain is positioned in an MRI image can vary a little, and so producing images with varying levels of zoom and rotation is a realistic way to mimic the effect of having more images. I decided to provide a range for brightness level because the dataset contains a variety of images with different levels of brightness and contrast, and so producing images with different levels of brightness is a realistic way to mimic the effect of having more images. I decided to flip some images along the horizontal axis, which translates to a left right flip, because regions of the brain are very symmetrical along the left/right axis. I did not include vertical flipping as part of data augmentation, because top/bottom parts of the brain are not symmetrical. I also decided not to shear any images, because shearing stretches and distorts regions of an image, and for brain scans it is very important to preserve the correct anatomical structure of the brain, as discussed in [this reresearch article](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6917660/).\nI also used to ImageDataGenerator to resize the MRIs since they are all different sizes. Because a bigger image means greater model complexity (and therefore harder to fine tune), I decided on a relatively small image size of 150x150x3.","metadata":{}},{"cell_type":"code","source":"# Set up ImageDataGenerator\ntrain_imagegen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\n                                   zoom_range=[0.6,1],\n                                   rotation_range=10,\n                                   brightness_range=([0.6, 1.2]),\n                                   horizontal_flip=True,\n                                   validation_split=0.06) # this will set aside a part of training set for validation data\ntest_imagegen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\n                                   zoom_range=[0.6,1],\n                                   rotation_range=10,\n                                   brightness_range=([0.6, 1.2]),\n                                   horizontal_flip=True)\n# Bring the data in\ntrain_generator = train_imagegen.flow_from_directory(\n                                    '../input/brain-tumor-classification-mri/Training',\n                                    classes={'no_tumor': 0,\n                                            'glioma_tumor':1,\n                                            'meningioma_tumor':2,\n                                            'pituitary_tumor':3},\n                                    target_size=(150,150),\n                                    batch_size=2700,# number of training images\n                                    seed=42,\n                                    class_mode='categorical',\n                                    subset='training')\n\ntest_generator = test_imagegen.flow_from_directory(\n                                    '../input/brain-tumor-classification-mri/Testing',\n                                    classes={'no_tumor': 0,\n                                            'glioma_tumor':1,\n                                            'meningioma_tumor':2,\n                                            'pituitary_tumor':3},\n                                    target_size=(150,150),\n                                    batch_size=394,# number of images\n                                    seed=42,\n                                    class_mode='categorical')\n\nval_generator = train_imagegen.flow_from_directory(\n                                    '../input/brain-tumor-classification-mri/Training',\n                                    classes={'no_tumor': 0,\n                                            'glioma_tumor':1,\n                                            'meningioma_tumor':2,\n                                            'pituitary_tumor':3},\n                                    target_size=(150,150),\n                                    batch_size=170,# number of images\n                                    seed=42,\n                                    class_mode='categorical',\n                                    subset='validation')\n# First run-throughs were not done with a random seed, so model analysis may be slightly different from what will be the \n# actual numbers after running models with the random seed.","metadata":{"execution":{"iopub.status.busy":"2022-02-09T04:42:41.123310Z","iopub.execute_input":"2022-02-09T04:42:41.123897Z","iopub.status.idle":"2022-02-09T04:42:41.549735Z","shell.execute_reply.started":"2022-02-09T04:42:41.123863Z","shell.execute_reply":"2022-02-09T04:42:41.548741Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# # Creating variables to contain image vectors and labels for the different training sets\ntrain_img, train_lab = next(train_generator)\ntest_img, test_lab = next(test_generator)\nval_img, val_lab = next(val_generator)","metadata":{"execution":{"iopub.status.busy":"2022-02-09T04:42:43.719565Z","iopub.execute_input":"2022-02-09T04:42:43.719828Z","iopub.status.idle":"2022-02-09T04:43:30.177692Z","shell.execute_reply.started":"2022-02-09T04:42:43.719799Z","shell.execute_reply":"2022-02-09T04:43:30.176774Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## **Using Pre-Trained VGG-19 Weights**","metadata":{}},{"cell_type":"markdown","source":"Since the VGG-19 pre-trained network yielded good results when approaching these images as a binary classification problem (tumor or no tumor) I decided to first try this network when using the images divided up into different classes (glioma tumor, meningioma tumor, pituitary tumor, no tumor).","metadata":{}},{"cell_type":"code","source":"from keras.applications.vgg19 import VGG19\ncnn_vgg = VGG19(weights='imagenet',\n               include_top=False,\n               input_shape=(150,150,3))","metadata":{"execution":{"iopub.status.busy":"2022-02-09T04:44:11.587047Z","iopub.execute_input":"2022-02-09T04:44:11.587738Z","iopub.status.idle":"2022-02-09T04:44:17.665666Z","shell.execute_reply.started":"2022-02-09T04:44:11.587700Z","shell.execute_reply":"2022-02-09T04:44:17.664569Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"Here I am implementing early stopping on the condition of monitoring testing loss with a patience of 12, so that if more than 12 epochs occur without any drops in testing loss, the model will stop training and the weights of the epoch with the lowest testing loss will be saved.","metadata":{}},{"cell_type":"code","source":"# Making early stop for model\npre_early = [EarlyStopping(monitor='val_loss', patience=12, restore_best_weights=True),\n            ModelCheckpoint(filepath='pretrained_model.h5', monitor='val_loss',\n                           save_best_only=True)]","metadata":{"execution":{"iopub.status.busy":"2022-02-08T20:18:24.163229Z","iopub.execute_input":"2022-02-08T20:18:24.163843Z","iopub.status.idle":"2022-02-08T20:18:24.170587Z","shell.execute_reply.started":"2022-02-08T20:18:24.163802Z","shell.execute_reply":"2022-02-08T20:18:24.169781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn_vgg.summary()","metadata":{"execution":{"iopub.status.busy":"2022-02-08T20:18:28.293343Z","iopub.execute_input":"2022-02-08T20:18:28.294023Z","iopub.status.idle":"2022-02-08T20:18:28.309848Z","shell.execute_reply.started":"2022-02-08T20:18:28.293987Z","shell.execute_reply":"2022-02-08T20:18:28.309084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I'm going to start out by adding two dense layers after flattening. I will use the 'relu' activation function for the second to last dense layer, which often gives the best results. It gives negative values a value of zero and any positive number can range from zero to infinity. It is a simple function which does not require much computational time, and can help models train faster. I will use the 'softmax activation function in the last layer since this is a multiclass classification problem.","metadata":{}},{"cell_type":"code","source":"# Build first model using pretrained VGG 19 as first layer, and then some dense layers on top\npretrained = keras.Sequential()\npretrained.add(cnn_vgg)\npretrained.add(layers.Flatten())\npretrained.add(layers.Dense(128, activation='relu'))\npretrained.add(layers.Dense(4, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2022-02-08T20:18:32.139071Z","iopub.execute_input":"2022-02-08T20:18:32.139327Z","iopub.status.idle":"2022-02-08T20:18:32.213938Z","shell.execute_reply.started":"2022-02-08T20:18:32.139299Z","shell.execute_reply":"2022-02-08T20:18:32.213288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Will start by freezing all layers of pretrained network\nFreeze_Pretrained_Base(cnn_vgg, pretrained)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T20:18:34.393041Z","iopub.execute_input":"2022-02-08T20:18:34.393406Z","iopub.status.idle":"2022-02-08T20:18:34.400143Z","shell.execute_reply.started":"2022-02-08T20:18:34.393373Z","shell.execute_reply":"2022-02-08T20:18:34.399421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compiling and fitting the model\npretrained.compile(loss='categorical_crossentropy',\n                optimizer='adam',\n                metrics=['categorical_accuracy','acc', 'Recall', 'Precision'])\n\npretrained_results = pretrained.fit(x=train_img, y=train_lab,\n                                              batch_size = 32,\n                                         steps_per_epoch=2700//32+1,# number of samples / batch size\n                                         epochs=25,\n                                        callbacks= pre_early,\n                                         validation_data=(test_img, test_lab),\n                                        validation_steps = 394//32+1)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T20:18:42.887221Z","iopub.execute_input":"2022-02-08T20:18:42.887506Z","iopub.status.idle":"2022-02-08T20:19:39.878602Z","shell.execute_reply.started":"2022-02-08T20:18:42.887471Z","shell.execute_reply":"2022-02-08T20:19:39.877861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(pretrained_results)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T21:32:04.961806Z","iopub.execute_input":"2022-02-08T21:32:04.962065Z","iopub.status.idle":"2022-02-08T21:32:43.378152Z","shell.execute_reply.started":"2022-02-08T21:32:04.962036Z","shell.execute_reply":"2022-02-08T21:32:43.377412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluating pretrained model on testing images\npretrained_eval = pretrained.evaluate(test_img, test_lab)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T21:42:30.836329Z","iopub.execute_input":"2022-02-08T21:42:30.837103Z","iopub.status.idle":"2022-02-08T21:42:31.619734Z","shell.execute_reply.started":"2022-02-08T21:42:30.837058Z","shell.execute_reply":"2022-02-08T21:42:31.618817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f1_score(pretrained_eval)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T21:43:49.55325Z","iopub.execute_input":"2022-02-08T21:43:49.553822Z","iopub.status.idle":"2022-02-08T21:43:49.558891Z","shell.execute_reply.started":"2022-02-08T21:43:49.553788Z","shell.execute_reply":"2022-02-08T21:43:49.557988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Analysis**\n\nTesting accuracy is 71%, recall is 71%, precision is 72%, and the f1 score is 71%. It is clear from the graphs that the model is overfitting; there is a big gap between training and testing loss and accuracy. These are modest results for the first transfer learning model, but next I want to investigate whether or not unfreezing outer layers helps improve performance.","metadata":{}},{"cell_type":"markdown","source":"## **Unfreezing an outer Layer of the Pretrained Network**","metadata":{}},{"cell_type":"code","source":"# Making early stop for model\nb5c1_early = [EarlyStopping(monitor='val_loss', patience=12, restore_best_weights=True),\n            ModelCheckpoint(filepath='b5_c1_model.h5', monitor='val_loss',\n                           save_best_only=True)]","metadata":{"execution":{"iopub.status.busy":"2022-02-08T21:46:35.894619Z","iopub.execute_input":"2022-02-08T21:46:35.894906Z","iopub.status.idle":"2022-02-08T21:46:35.900597Z","shell.execute_reply.started":"2022-02-08T21:46:35.894875Z","shell.execute_reply":"2022-02-08T21:46:35.899689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build first model using pretrained VGG 19 as first layer, and then some dense layers on top\nb5_c1 = keras.Sequential()\nb5_c1.add(cnn_vgg)\nb5_c1.add(layers.Flatten())\nb5_c1.add(layers.Dense(128, activation='relu'))\nb5_c1.add(layers.Dense(4, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2022-02-08T21:46:40.865579Z","iopub.execute_input":"2022-02-08T21:46:40.865843Z","iopub.status.idle":"2022-02-08T21:46:40.941606Z","shell.execute_reply.started":"2022-02-08T21:46:40.865814Z","shell.execute_reply":"2022-02-08T21:46:40.94092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# freezing everything \nFreeze_Pretrained_Base(cnn_vgg, b5_c1)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T21:46:45.554978Z","iopub.execute_input":"2022-02-08T21:46:45.55535Z","iopub.status.idle":"2022-02-08T21:46:45.561743Z","shell.execute_reply.started":"2022-02-08T21:46:45.555316Z","shell.execute_reply":"2022-02-08T21:46:45.561017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Unfreezing the last layer of the pretrained CNN\nun_b5c1 = ['block5_conv1']\nUnfreeze_Layers(cnn_vgg, un_b5c1)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T21:46:51.827307Z","iopub.execute_input":"2022-02-08T21:46:51.827573Z","iopub.status.idle":"2022-02-08T21:46:51.8393Z","shell.execute_reply.started":"2022-02-08T21:46:51.827541Z","shell.execute_reply":"2022-02-08T21:46:51.838504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"b5_c1.compile(loss='categorical_crossentropy',\n                optimizer='adam',\n                metrics=['categorical_accuracy','acc', 'Recall', 'Precision'])\n\nb5_c1_results = b5_c1.fit(x=train_img, y=train_lab,\n                                         batch_size=32,\n                                         steps_per_epoch=2700//32+1,# number of samples / batch size\n                                         epochs=25,\n                                        callbacks= b5c1_early,\n                                         validation_data=(test_img, test_lab),\n                                        validation_steps=394//32+1)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T21:46:54.899162Z","iopub.execute_input":"2022-02-08T21:46:54.899418Z","iopub.status.idle":"2022-02-08T21:48:07.049007Z","shell.execute_reply.started":"2022-02-08T21:46:54.899389Z","shell.execute_reply":"2022-02-08T21:48:07.048259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(b5_c1_results)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T21:48:47.390677Z","iopub.execute_input":"2022-02-08T21:48:47.390924Z","iopub.status.idle":"2022-02-08T21:48:47.65391Z","shell.execute_reply.started":"2022-02-08T21:48:47.390895Z","shell.execute_reply":"2022-02-08T21:48:47.653205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"b5_c1_eval = b5_c1.evaluate(test_img, test_lab)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T21:48:59.121256Z","iopub.execute_input":"2022-02-08T21:48:59.121534Z","iopub.status.idle":"2022-02-08T21:48:59.900092Z","shell.execute_reply.started":"2022-02-08T21:48:59.121503Z","shell.execute_reply":"2022-02-08T21:48:59.899374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f1_score(b5_c1_eval)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T21:49:27.120754Z","iopub.execute_input":"2022-02-08T21:49:27.12142Z","iopub.status.idle":"2022-02-08T21:49:27.126871Z","shell.execute_reply.started":"2022-02-08T21:49:27.121382Z","shell.execute_reply":"2022-02-08T21:49:27.126199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Analysis**\n\nResults are very similar to hte last iteration; overfitting is still a problem, and all metrics are around 71%. Next I will see if adding dropout layers will help improve performance.","metadata":{}},{"cell_type":"markdown","source":"## **Adding Dropout layers to VGG-19 pretrained network (one layer unfrozen)**","metadata":{}},{"cell_type":"code","source":"# Making early stop for model\nvgg_drop_early = [EarlyStopping(monitor='val_loss', patience=12, restore_best_weights=True),\n            ModelCheckpoint(filepath='vgg_drop_model.h5', monitor='val_loss',\n                           save_best_only=True)]","metadata":{"execution":{"iopub.status.busy":"2022-02-08T21:51:00.497882Z","iopub.execute_input":"2022-02-08T21:51:00.498147Z","iopub.status.idle":"2022-02-08T21:51:00.503824Z","shell.execute_reply.started":"2022-02-08T21:51:00.498116Z","shell.execute_reply":"2022-02-08T21:51:00.502942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build first model using pretrained VGG 19 as first layer, and then some dense layers on top\nvgg_drop = keras.Sequential()\nvgg_drop.add(cnn_vgg)\nvgg_drop.add(layers.Flatten())\nvgg_drop.add(layers.Dropout(0.4))\nvgg_drop.add(layers.Dense(128, activation='relu'))\nvgg_drop.add(layers.Dropout(0.2))\nvgg_drop.add(layers.Dense(4, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2022-02-08T21:53:50.855918Z","iopub.execute_input":"2022-02-08T21:53:50.856164Z","iopub.status.idle":"2022-02-08T21:53:50.938379Z","shell.execute_reply.started":"2022-02-08T21:53:50.856135Z","shell.execute_reply":"2022-02-08T21:53:50.93761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Freeze all layers\nFreeze_Pretrained_Base(cnn_vgg, vgg_drop)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T21:53:52.868959Z","iopub.execute_input":"2022-02-08T21:53:52.869823Z","iopub.status.idle":"2022-02-08T21:53:52.877377Z","shell.execute_reply.started":"2022-02-08T21:53:52.869751Z","shell.execute_reply":"2022-02-08T21:53:52.876599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Unfreezing the last layer of the pretrained CNN\nun_b5c1 = ['block5_conv1']\nUnfreeze_Layers(cnn_vgg, un_b5c1)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T21:53:55.611188Z","iopub.execute_input":"2022-02-08T21:53:55.611723Z","iopub.status.idle":"2022-02-08T21:53:55.625356Z","shell.execute_reply.started":"2022-02-08T21:53:55.611683Z","shell.execute_reply":"2022-02-08T21:53:55.62451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg_drop.compile(loss='categorical_crossentropy',\n                optimizer='adam',\n                metrics=['categorical_accuracy','acc', 'Recall', 'Precision'])\n\nvgg_drop_results = vgg_drop.fit(x=train_img, y=train_lab,\n                                            batch_size=32,\n                                         steps_per_epoch=2700//32+1,# number of samples / batch size\n                                         epochs=25,\n                                        callbacks= vgg_drop_early,\n                                         validation_data=(test_img, test_lab),\n                                           validation_steps=394//32+1)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T21:53:59.146987Z","iopub.execute_input":"2022-02-08T21:53:59.147234Z","iopub.status.idle":"2022-02-08T21:55:01.931159Z","shell.execute_reply.started":"2022-02-08T21:53:59.147205Z","shell.execute_reply":"2022-02-08T21:55:01.93041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(vgg_drop_results)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T21:55:51.523149Z","iopub.execute_input":"2022-02-08T21:55:51.523408Z","iopub.status.idle":"2022-02-08T21:55:51.787779Z","shell.execute_reply.started":"2022-02-08T21:55:51.523378Z","shell.execute_reply":"2022-02-08T21:55:51.787098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg_drop_eval = vgg_drop.evaluate(test_img, test_lab)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T21:55:54.797249Z","iopub.execute_input":"2022-02-08T21:55:54.797529Z","iopub.status.idle":"2022-02-08T21:55:55.568162Z","shell.execute_reply.started":"2022-02-08T21:55:54.797498Z","shell.execute_reply":"2022-02-08T21:55:55.567494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f1_score(vgg_drop_eval)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T21:55:57.964167Z","iopub.execute_input":"2022-02-08T21:55:57.964458Z","iopub.status.idle":"2022-02-08T21:55:57.969599Z","shell.execute_reply.started":"2022-02-08T21:55:57.964413Z","shell.execute_reply":"2022-02-08T21:55:57.968888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Analysis**\n\nResults are still about the same in this iteration; overfitting is still a problem, and all metrics are around 70%. In the next iteration I will see if unfreezing yet another layer will improve performance of model.","metadata":{}},{"cell_type":"markdown","source":"## **Unfreezing another layer of VGG Pretrained Network**","metadata":{}},{"cell_type":"code","source":"# Making early stop for model\nb5_c1c2_early = [EarlyStopping(monitor='val_loss', patience=12, restore_best_weights=True),\n            ModelCheckpoint(filepath='b5c1c2_model.h5', monitor='val_acc',\n                           save_best_only=True)]","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:55:05.312676Z","iopub.execute_input":"2022-02-08T22:55:05.312938Z","iopub.status.idle":"2022-02-08T22:55:05.317277Z","shell.execute_reply.started":"2022-02-08T22:55:05.312907Z","shell.execute_reply":"2022-02-08T22:55:05.316253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build first model using pretrained VGG 19 as first layer, and then some dense layers on top\nb5_c1c2 = keras.Sequential()\nb5_c1c2.add(cnn_vgg)\nb5_c1c2.add(layers.Flatten())\nb5_c1c2.add(layers.Dropout(0.4))\nb5_c1c2.add(layers.Dense(128, activation='relu'))\nb5_c1c2.add(layers.Dropout(0.2))\nb5_c1c2.add(layers.Dense(4, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:55:08.086761Z","iopub.execute_input":"2022-02-08T22:55:08.087021Z","iopub.status.idle":"2022-02-08T22:55:08.168239Z","shell.execute_reply.started":"2022-02-08T22:55:08.086991Z","shell.execute_reply":"2022-02-08T22:55:08.167579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Freeze all layers\nFreeze_Pretrained_Base(cnn_vgg, b5_c1c2)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:55:10.291218Z","iopub.execute_input":"2022-02-08T22:55:10.291499Z","iopub.status.idle":"2022-02-08T22:55:10.299249Z","shell.execute_reply.started":"2022-02-08T22:55:10.291461Z","shell.execute_reply":"2022-02-08T22:55:10.298367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Unfreezing the last layer of the pretrained CNN\nun_b5c1c2 = ['block5_conv1', 'block5_conv2']\nUnfreeze_Layers(cnn_vgg, un_b5c1c2)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:55:15.745981Z","iopub.execute_input":"2022-02-08T22:55:15.746243Z","iopub.status.idle":"2022-02-08T22:55:15.758316Z","shell.execute_reply.started":"2022-02-08T22:55:15.746212Z","shell.execute_reply":"2022-02-08T22:55:15.757606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"b5_c1c2.compile(loss='categorical_crossentropy',\n                optimizer='adam',\n                metrics=['categorical_accuracy','acc', 'Recall', 'Precision'])\n\nb5_c1c2_results = b5_c1c2.fit(x=train_img, y=train_lab,\n                                            batch_size=32,\n                                         steps_per_epoch=2700//32+1,# number of samples / batch size\n                                         epochs=25,\n                                        callbacks= vgg_drop_early,\n                                         validation_data=(test_img, test_lab))\n                                           #validation_steps=394//32+1)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:55:19.966089Z","iopub.execute_input":"2022-02-08T22:55:19.966525Z","iopub.status.idle":"2022-02-08T22:57:44.044785Z","shell.execute_reply.started":"2022-02-08T22:55:19.966484Z","shell.execute_reply":"2022-02-08T22:57:44.043983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(b5_c1c2_results)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:57:44.046958Z","iopub.execute_input":"2022-02-08T22:57:44.047231Z","iopub.status.idle":"2022-02-08T22:57:44.297747Z","shell.execute_reply.started":"2022-02-08T22:57:44.047195Z","shell.execute_reply":"2022-02-08T22:57:44.297095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"b5_c1c2_eval = b5_c1c2.evaluate(test_img, test_lab)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:58:37.601152Z","iopub.execute_input":"2022-02-08T22:58:37.601855Z","iopub.status.idle":"2022-02-08T22:58:38.449027Z","shell.execute_reply.started":"2022-02-08T22:58:37.60182Z","shell.execute_reply":"2022-02-08T22:58:38.448167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f1_score(b5_c1c2_eval)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:58:45.977654Z","iopub.execute_input":"2022-02-08T22:58:45.978195Z","iopub.status.idle":"2022-02-08T22:58:45.983276Z","shell.execute_reply.started":"2022-02-08T22:58:45.978156Z","shell.execute_reply":"2022-02-08T22:58:45.98251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Analysis**\n\nIn this iteration, overfitting is still a problem and results are about the same, but there has been a slight improvement. Testing accuracy is 72%, recall is 71%, precision is 73%, and f1 score is 73%. In the next iteration I will see if implementing learning rate reduction and increasing the number of epochs will improve model performance.","metadata":{}},{"cell_type":"markdown","source":"## **Implementing Learning Rate Reduction**","metadata":{}},{"cell_type":"code","source":"# Making early stop for model\nred_c1c2_early = [EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True),\n            ModelCheckpoint(filepath='red_b5c1c2_model.h5', monitor='val_loss', save_best_only=True),\n            ReduceLROnPlateau(patience=12, verbose=1)]","metadata":{"execution":{"iopub.status.busy":"2022-02-09T04:52:54.457441Z","iopub.execute_input":"2022-02-09T04:52:54.457710Z","iopub.status.idle":"2022-02-09T04:52:54.463521Z","shell.execute_reply.started":"2022-02-09T04:52:54.457681Z","shell.execute_reply":"2022-02-09T04:52:54.462032Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Build first model using pretrained VGG 19 as first layer, and then some dense layers on top\nred_c1c2 = keras.Sequential()\nred_c1c2.add(cnn_vgg)\nred_c1c2.add(layers.Flatten())\nred_c1c2.add(layers.Dropout(0.4))\nred_c1c2.add(layers.Dense(128, activation='relu'))\nred_c1c2.add(layers.Dropout(0.2))\nred_c1c2.add(layers.Dense(4, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2022-02-09T04:52:56.498190Z","iopub.execute_input":"2022-02-09T04:52:56.498510Z","iopub.status.idle":"2022-02-09T04:52:56.610093Z","shell.execute_reply.started":"2022-02-09T04:52:56.498474Z","shell.execute_reply":"2022-02-09T04:52:56.609137Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Freeze all layers\nFreeze_Pretrained_Base(cnn_vgg, red_c1c2)","metadata":{"execution":{"iopub.status.busy":"2022-02-09T04:52:58.995596Z","iopub.execute_input":"2022-02-09T04:52:58.996430Z","iopub.status.idle":"2022-02-09T04:52:59.005781Z","shell.execute_reply.started":"2022-02-09T04:52:58.996393Z","shell.execute_reply":"2022-02-09T04:52:59.004409Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Unfreezing the last layer of the pretrained CNN\nun_b5c1c2 = ['block5_conv1', 'block5_conv2']\nUnfreeze_Layers(cnn_vgg, un_b5c1c2)","metadata":{"execution":{"iopub.status.busy":"2022-02-09T04:53:01.408450Z","iopub.execute_input":"2022-02-09T04:53:01.408910Z","iopub.status.idle":"2022-02-09T04:53:01.427403Z","shell.execute_reply.started":"2022-02-09T04:53:01.408875Z","shell.execute_reply":"2022-02-09T04:53:01.426125Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"red_c1c2.compile(loss='categorical_crossentropy',\n                optimizer='adam',\n                metrics=['acc','categorical_accuracy','Recall', 'Precision'])\n\nred_c1c2_results = red_c1c2.fit(x=train_img, y=train_lab,\n                                            batch_size=32,\n                                         steps_per_epoch=2700//32+1,# number of samples / batch size\n                                         epochs=100,\n                                        callbacks= red_c1c2_early,\n                                         validation_data=(test_img, test_lab),\n                                           validation_steps=394//32+1)","metadata":{"execution":{"iopub.status.busy":"2022-02-09T04:53:05.461909Z","iopub.execute_input":"2022-02-09T04:53:05.462570Z","iopub.status.idle":"2022-02-09T04:55:42.221906Z","shell.execute_reply.started":"2022-02-09T04:53:05.462533Z","shell.execute_reply":"2022-02-09T04:55:42.220968Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(red_c1c2_results)","metadata":{"execution":{"iopub.status.busy":"2022-02-09T04:55:51.732492Z","iopub.execute_input":"2022-02-09T04:55:51.732800Z","iopub.status.idle":"2022-02-09T04:56:30.528086Z","shell.execute_reply.started":"2022-02-09T04:55:51.732771Z","shell.execute_reply":"2022-02-09T04:56:30.527183Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"red_c1c2_eval = red_c1c2.evaluate(test_img, test_lab)","metadata":{"execution":{"iopub.status.busy":"2022-02-09T04:56:36.492880Z","iopub.execute_input":"2022-02-09T04:56:36.493820Z","iopub.status.idle":"2022-02-09T04:56:37.295333Z","shell.execute_reply.started":"2022-02-09T04:56:36.493782Z","shell.execute_reply":"2022-02-09T04:56:37.294438Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"f1_score(red_c1c2_eval)","metadata":{"execution":{"iopub.status.busy":"2022-02-09T04:56:45.983355Z","iopub.execute_input":"2022-02-09T04:56:45.983677Z","iopub.status.idle":"2022-02-09T04:56:45.990982Z","shell.execute_reply.started":"2022-02-09T04:56:45.983639Z","shell.execute_reply":"2022-02-09T04:56:45.989924Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"### **Analysis**\n\nIn this iteration, overfitting has improved slightly, and all metrics are better; testing accuracy is 77%, testing recall is 76%, precision is 78%, and the f1 score is 77%. It looks like implementing learning rate reduction and increasing number of epochs improved performance. In the next iteration I will see if batch normalization improves performance.","metadata":{}},{"cell_type":"markdown","source":"## **Adding Batch Normalization to VGG19 Pretrained Neural Network**","metadata":{}},{"cell_type":"code","source":"# Making early stop for model\nvgg_batch_early = [EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True),\n            ModelCheckpoint(filepath='vgg_batch_model.h5', monitor='val_loss', save_best_only=True),\n            ReduceLROnPlateau(patience=12, verbose=1)]","metadata":{"execution":{"iopub.status.busy":"2022-02-08T20:21:34.70382Z","iopub.execute_input":"2022-02-08T20:21:34.704087Z","iopub.status.idle":"2022-02-08T20:21:34.709738Z","shell.execute_reply.started":"2022-02-08T20:21:34.704057Z","shell.execute_reply":"2022-02-08T20:21:34.708673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build first model using pretrained VGG 19 as first layer, and then some dense layers on top\nvgg_batch = keras.Sequential()\nvgg_batch.add(cnn_vgg)\nvgg_batch.add(layers.Flatten())\nvgg_batch.add(layers.BatchNormalization())\nvgg_batch.add(layers.Dropout(0.4))\nvgg_batch.add(layers.Dense(128, activation='relu'))\nvgg_batch.add(layers.BatchNormalization())\nvgg_batch.add(layers.Dropout(0.2))\nvgg_batch.add(layers.Dense(4, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2022-02-08T20:21:41.604061Z","iopub.execute_input":"2022-02-08T20:21:41.604316Z","iopub.status.idle":"2022-02-08T20:22:06.948116Z","shell.execute_reply.started":"2022-02-08T20:21:41.604287Z","shell.execute_reply":"2022-02-08T20:22:06.947305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Re-freezing everything except for the last layer of the pretrained CNN\n# Code structure from https://github.com/learn-co-curriculum/dsc-using-pretrained-networks-codealong\nFreeze_Pretrained_Base(cnn_vgg, vgg_batch)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T20:22:36.157964Z","iopub.execute_input":"2022-02-08T20:22:36.158501Z","iopub.status.idle":"2022-02-08T20:22:36.166255Z","shell.execute_reply.started":"2022-02-08T20:22:36.158458Z","shell.execute_reply":"2022-02-08T20:22:36.165526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Unfreezing the last layer of the pretrained CNN\nun_b5c1c2 = ['block5_conv1', 'block5_conv2']\nUnfreeze_Layers(cnn_vgg, un_b5c1c2)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T20:22:38.848126Z","iopub.execute_input":"2022-02-08T20:22:38.84857Z","iopub.status.idle":"2022-02-08T20:22:38.862209Z","shell.execute_reply.started":"2022-02-08T20:22:38.84853Z","shell.execute_reply":"2022-02-08T20:22:38.861126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg_batch.compile(loss='categorical_crossentropy',\n                optimizer='adam',\n                metrics=['categorical_accuracy','acc', 'Recall', 'Precision'])\n\nvgg_batch_results = vgg_batch.fit(x=train_img, y=train_lab,\n                                         steps_per_epoch=2700//32+1,\n                                          batch_size=32,\n                                         epochs=100,\n                                        callbacks= vgg_batch_early,\n                                         validation_data=(test_img, test_lab),\n                                         validation_steps=394//32+1)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T20:23:08.978672Z","iopub.execute_input":"2022-02-08T20:23:08.978937Z","iopub.status.idle":"2022-02-08T20:24:54.329102Z","shell.execute_reply.started":"2022-02-08T20:23:08.978908Z","shell.execute_reply":"2022-02-08T20:24:54.328384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(vgg_batch_results)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T20:25:07.877436Z","iopub.execute_input":"2022-02-08T20:25:07.878144Z","iopub.status.idle":"2022-02-08T20:25:33.898979Z","shell.execute_reply.started":"2022-02-08T20:25:07.878107Z","shell.execute_reply":"2022-02-08T20:25:33.898291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg_batch_eval = vgg_batch.evaluate(test_img, test_lab)\nvgg_batch_eval","metadata":{"execution":{"iopub.status.busy":"2022-02-08T20:25:41.258135Z","iopub.execute_input":"2022-02-08T20:25:41.258384Z","iopub.status.idle":"2022-02-08T20:25:42.034417Z","shell.execute_reply.started":"2022-02-08T20:25:41.258353Z","shell.execute_reply":"2022-02-08T20:25:42.033767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f1_score(vgg_batch_eval)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T20:26:16.876342Z","iopub.execute_input":"2022-02-08T20:26:16.876901Z","iopub.status.idle":"2022-02-08T20:26:16.883027Z","shell.execute_reply.started":"2022-02-08T20:26:16.876864Z","shell.execute_reply":"2022-02-08T20:26:16.882351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Analysis**\n\nIn this iteration, testing accuracy is 66%, recall is 63%, precision is 71%, and the f1 score is 67%. It is clear that adding batch normalization decreased model performance. In the next iteration, I will remove batch normalization and see if unfreezing more layers will improve model performance.","metadata":{}},{"cell_type":"markdown","source":"## **Unfreezing Four Layers of the VGG19 Pretrained Network**","metadata":{}},{"cell_type":"code","source":"# Making early stop for model\nfour_vgg_early = [EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True),\n            ModelCheckpoint(filepath='vgg_four_model.h5', monitor='val_loss', save_best_only=True),\n            ReduceLROnPlateau(patience=12, verbose=1)]","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:12:46.637186Z","iopub.execute_input":"2022-02-08T22:12:46.637911Z","iopub.status.idle":"2022-02-08T22:12:46.642604Z","shell.execute_reply.started":"2022-02-08T22:12:46.63786Z","shell.execute_reply":"2022-02-08T22:12:46.641853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build first model using pretrained VGG 19 as first layer, and then some dense layers on top\nfour_vgg = keras.Sequential()\nfour_vgg.add(cnn_vgg)\nfour_vgg.add(layers.Dropout(0.4))\nfour_vgg.add(layers.Flatten())\nfour_vgg.add(layers.Dense(128, activation='relu'))\nfour_vgg.add(layers.Dropout(0.2))\nfour_vgg.add(layers.Dense(4, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:13:12.980678Z","iopub.execute_input":"2022-02-08T22:13:12.98177Z","iopub.status.idle":"2022-02-08T22:13:13.067248Z","shell.execute_reply.started":"2022-02-08T22:13:12.981723Z","shell.execute_reply":"2022-02-08T22:13:13.066589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Re-freezing everything except for the last layer of the pretrained CNN\n# Code structure from https://github.com/learn-co-curriculum/dsc-using-pretrained-networks-codealong\nFreeze_Pretrained_Base(cnn_vgg, four_vgg)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:13:18.864366Z","iopub.execute_input":"2022-02-08T22:13:18.864987Z","iopub.status.idle":"2022-02-08T22:13:18.875375Z","shell.execute_reply.started":"2022-02-08T22:13:18.864948Z","shell.execute_reply":"2022-02-08T22:13:18.874597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn_vgg.summary()","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:11:12.911323Z","iopub.execute_input":"2022-02-08T22:11:12.911892Z","iopub.status.idle":"2022-02-08T22:11:12.928157Z","shell.execute_reply.started":"2022-02-08T22:11:12.911856Z","shell.execute_reply":"2022-02-08T22:11:12.927494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"un_four_vgg = ['block5_conv1', 'block5_conv2','block5_conv3', 'block5_conv4']","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:12:28.650008Z","iopub.execute_input":"2022-02-08T22:12:28.650267Z","iopub.status.idle":"2022-02-08T22:12:28.654774Z","shell.execute_reply.started":"2022-02-08T22:12:28.650237Z","shell.execute_reply":"2022-02-08T22:12:28.653928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Unfreeze_Layers(cnn_vgg, un_four_vgg)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:13:44.174792Z","iopub.execute_input":"2022-02-08T22:13:44.175046Z","iopub.status.idle":"2022-02-08T22:13:44.185888Z","shell.execute_reply.started":"2022-02-08T22:13:44.175018Z","shell.execute_reply":"2022-02-08T22:13:44.185213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"four_vgg.compile(loss='categorical_crossentropy',\n                optimizer='adam',\n                metrics=['categorical_accuracy','acc', 'Recall', 'Precision'])\n\nfour_vgg_results = four_vgg.fit(x=train_img, y=train_lab,\n                              batch_size=32,\n                              steps_per_epoch=2700//32+1,# number of samples / batch size\n                              epochs=100,\n                             callbacks= four_vgg_early,\n                            validation_data= (test_img, test_lab),\n                            validation_steps = 394//32+1)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:14:39.66999Z","iopub.execute_input":"2022-02-08T22:14:39.670643Z","iopub.status.idle":"2022-02-08T22:18:51.693996Z","shell.execute_reply.started":"2022-02-08T22:14:39.670607Z","shell.execute_reply":"2022-02-08T22:18:51.693242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(four_vgg_results)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:24:16.81341Z","iopub.execute_input":"2022-02-08T22:24:16.814016Z","iopub.status.idle":"2022-02-08T22:25:04.067679Z","shell.execute_reply.started":"2022-02-08T22:24:16.813976Z","shell.execute_reply":"2022-02-08T22:25:04.066986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"four_vgg_eval = four_vgg.evaluate(test_img, test_lab)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:25:29.64885Z","iopub.execute_input":"2022-02-08T22:25:29.649117Z","iopub.status.idle":"2022-02-08T22:25:30.431006Z","shell.execute_reply.started":"2022-02-08T22:25:29.649088Z","shell.execute_reply":"2022-02-08T22:25:30.430331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f1_score(four_vgg_eval)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:25:49.516177Z","iopub.execute_input":"2022-02-08T22:25:49.516474Z","iopub.status.idle":"2022-02-08T22:25:49.522117Z","shell.execute_reply.started":"2022-02-08T22:25:49.516424Z","shell.execute_reply":"2022-02-08T22:25:49.521231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Analysis**\n\nIt looks like unfreezing four layers was not beneficial to model performance; testing accuracy is 68%, recall is 62%, precision is 78%, and f1 score is 78%. In the next iteration, I will start by just unfreezing the block5_conv4 layer, since this is the outer most layer. The first layer I unfroze was block5_conv1 layer, which is actually not the outer most layer. Maybe keeping the weights of the pretrained network for every layer but the most outer layer will be beneficial to model performance. ","metadata":{}},{"cell_type":"markdown","source":"## **Unfreezing Block 5, conv 4 layer of VGG-19 Network**","metadata":{}},{"cell_type":"code","source":"# Making early stop for model\nb5c4_vgg_early = [EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True),\n            ModelCheckpoint(filepath='vgg_b5c4_model.h5', monitor='val_loss', save_best_only=True),\n            ReduceLROnPlateau(patience=12, verbose=1)]","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:31:59.608192Z","iopub.execute_input":"2022-02-08T22:31:59.608471Z","iopub.status.idle":"2022-02-08T22:31:59.614539Z","shell.execute_reply.started":"2022-02-08T22:31:59.608425Z","shell.execute_reply":"2022-02-08T22:31:59.613637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build first model using pretrained VGG 19 as first layer, and then some dense layers on top\nb5c4_vgg = keras.Sequential()\nb5c4_vgg.add(cnn_vgg)\nb5c4_vgg.add(layers.Dropout(0.4))\nb5c4_vgg.add(layers.Flatten())\nb5c4_vgg.add(layers.Dense(128, activation='relu'))\nb5c4_vgg.add(layers.Dropout(0.2))\nb5c4_vgg.add(layers.Dense(4, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:32:34.975294Z","iopub.execute_input":"2022-02-08T22:32:34.975837Z","iopub.status.idle":"2022-02-08T22:32:35.056943Z","shell.execute_reply.started":"2022-02-08T22:32:34.975795Z","shell.execute_reply":"2022-02-08T22:32:35.056305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Re-freezing everything except for the last layer of the pretrained CNN\n# Code structure from https://github.com/learn-co-curriculum/dsc-using-pretrained-networks-codealong\nFreeze_Pretrained_Base(cnn_vgg, b5c4_vgg)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:32:37.543798Z","iopub.execute_input":"2022-02-08T22:32:37.544047Z","iopub.status.idle":"2022-02-08T22:32:37.551152Z","shell.execute_reply.started":"2022-02-08T22:32:37.544018Z","shell.execute_reply":"2022-02-08T22:32:37.550385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"un_b5c4 = ['block5_conv4']","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:32:51.296412Z","iopub.execute_input":"2022-02-08T22:32:51.296982Z","iopub.status.idle":"2022-02-08T22:32:51.300571Z","shell.execute_reply.started":"2022-02-08T22:32:51.296945Z","shell.execute_reply":"2022-02-08T22:32:51.299654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Unfreeze_Layers(cnn_vgg, un_b5c4)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:32:58.832909Z","iopub.execute_input":"2022-02-08T22:32:58.833726Z","iopub.status.idle":"2022-02-08T22:32:58.848476Z","shell.execute_reply.started":"2022-02-08T22:32:58.833687Z","shell.execute_reply":"2022-02-08T22:32:58.847698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"b5c4_vgg.compile(loss='categorical_crossentropy',\n                optimizer='adam',\n                metrics=['categorical_accuracy','acc', 'Recall', 'Precision'])\n\nb5c4_vgg_results = b5c4_vgg.fit(x=train_img, y=train_lab,\n                              batch_size=32,\n                              steps_per_epoch=2700//32+1,# number of samples / batch size\n                              epochs=100,\n                             callbacks= four_vgg_early,\n                            validation_data= (test_img, test_lab),\n                            validation_steps = 394//32+1)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:33:37.938685Z","iopub.execute_input":"2022-02-08T22:33:37.938948Z","iopub.status.idle":"2022-02-08T22:35:15.967904Z","shell.execute_reply.started":"2022-02-08T22:33:37.938919Z","shell.execute_reply":"2022-02-08T22:35:15.967175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(b5c4_vgg_results)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:36:02.233078Z","iopub.execute_input":"2022-02-08T22:36:02.233325Z","iopub.status.idle":"2022-02-08T22:36:02.481238Z","shell.execute_reply.started":"2022-02-08T22:36:02.233279Z","shell.execute_reply":"2022-02-08T22:36:02.480511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"b5c4_vgg_eval = b5c4_vgg.evaluate(test_img, test_lab)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:36:45.788973Z","iopub.execute_input":"2022-02-08T22:36:45.789232Z","iopub.status.idle":"2022-02-08T22:36:46.561286Z","shell.execute_reply.started":"2022-02-08T22:36:45.789202Z","shell.execute_reply":"2022-02-08T22:36:46.560475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f1_score(b5c4_vgg_eval)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:37:17.576022Z","iopub.execute_input":"2022-02-08T22:37:17.576273Z","iopub.status.idle":"2022-02-08T22:37:17.582115Z","shell.execute_reply.started":"2022-02-08T22:37:17.576242Z","shell.execute_reply":"2022-02-08T22:37:17.581437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Analysis**\n\nThis iteration performed worse than the last; overfitting has increased, testing accuracy is 69%, recall is 68%, precision is 69%, and f1 score is 70%. It is obvious that unfreezing the outermost layer has not improved model performance.","metadata":{}},{"cell_type":"markdown","source":"## **Evaluating Best Model (red_c1c2) on the holdout set**","metadata":{}},{"cell_type":"code","source":"best_model = load_model('red_b5c1c2_model.h5')\n# 'b5c1c2_model.h5'","metadata":{"execution":{"iopub.status.busy":"2022-02-09T04:57:00.831765Z","iopub.execute_input":"2022-02-09T04:57:00.832079Z","iopub.status.idle":"2022-02-09T04:57:01.265472Z","shell.execute_reply.started":"2022-02-09T04:57:00.832047Z","shell.execute_reply":"2022-02-09T04:57:01.264451Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"best_model_eval = best_model.evaluate(val_img, val_lab)","metadata":{"execution":{"iopub.status.busy":"2022-02-09T04:57:11.004824Z","iopub.execute_input":"2022-02-09T04:57:11.005127Z","iopub.status.idle":"2022-02-09T04:57:11.908711Z","shell.execute_reply.started":"2022-02-09T04:57:11.005094Z","shell.execute_reply":"2022-02-09T04:57:11.907655Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"f1_score(best_model_eval)","metadata":{"execution":{"iopub.status.busy":"2022-02-09T04:57:21.947106Z","iopub.execute_input":"2022-02-09T04:57:21.947435Z","iopub.status.idle":"2022-02-09T04:57:21.960520Z","shell.execute_reply.started":"2022-02-09T04:57:21.947404Z","shell.execute_reply":"2022-02-09T04:57:21.959255Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"### **Analysis**\n\nWhen the final model (red_b5c1c2_model) was evaluated on the hold out set (val_img and val_lab), loss was 0.56, accuracy was 78%, recall was 73%, precision was 85%, and the f1 score was 78%. These results are similar to when the model was evaluated on testing data, so this is good news. However for the sake of this task, it would have been better for recall to be higher, since it is worse to have a false negative ( meaning that a tumor was incorrectly diagnosed, either as having no tumor or the wrong tumor type) than a false positive (meaning that an MRI scan with no tumor was identified as containing one of the types of tumors).","metadata":{}},{"cell_type":"code","source":"# Predictions for Validation data\nval_preds_raw = best_model.predict(val_img)\nval_preds = (val_preds_raw > 0.5).astype('int32')","metadata":{"execution":{"iopub.status.busy":"2022-02-09T04:59:34.435352Z","iopub.execute_input":"2022-02-09T04:59:34.435639Z","iopub.status.idle":"2022-02-09T04:59:34.976419Z","shell.execute_reply.started":"2022-02-09T04:59:34.435608Z","shell.execute_reply":"2022-02-09T04:59:34.975522Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# Transforming one-hot encoded labels into a single numeric value for each label and converting labels to integers\nval_lab_ints = val_lab.astype('int32')\nfin_val_lab = np.argmax(val_lab_ints, axis=1)\n\n# Separating each label type into a separate list\nthree_lab = [i for i in fin_val_lab if i ==3]\ntwo_lab = [i for i in fin_val_lab if i==2]\none_lab = [i for i in fin_val_lab if i==1]\nzero_lab = [i for i in fin_val_lab if i==0]\n\n# Calculating the number of each type of tumor \nnum_pituitary = len(three_lab)\nnum_meningioma = len(two_lab)\nnum_glioma = len(one_lab)\nnum_no_tumor = len(zero_lab)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-02-09T04:59:36.251267Z","iopub.execute_input":"2022-02-09T04:59:36.251632Z","iopub.status.idle":"2022-02-09T04:59:36.268759Z","shell.execute_reply.started":"2022-02-09T04:59:36.251593Z","shell.execute_reply":"2022-02-09T04:59:36.267407Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# Printing the number of different tumor types\nprint('Number of Pituitary Tumors', num_pituitary)\nprint('Number of Meningioma Tumors', num_meningioma)\nprint('Number of Glioma Tumors', num_glioma)\nprint('Number of No Tumor Images', num_no_tumor)","metadata":{"execution":{"iopub.status.busy":"2022-02-09T04:59:38.723218Z","iopub.execute_input":"2022-02-09T04:59:38.723806Z","iopub.status.idle":"2022-02-09T04:59:38.732749Z","shell.execute_reply.started":"2022-02-09T04:59:38.723772Z","shell.execute_reply":"2022-02-09T04:59:38.730701Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"#### Number of Pituitary Tumors: 49\n#### Number of Meningioma Tumors: 49\n#### Number of Glioma Tumors: 49\n#### Number of No Tumor Images: 23","metadata":{}},{"cell_type":"code","source":"# Transforming one-hot encoded predictions into a single numeric value for each prediction\nfin_val_preds = np.argmax(val_preds, axis=1)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-02-09T04:59:41.864125Z","iopub.execute_input":"2022-02-09T04:59:41.864789Z","iopub.status.idle":"2022-02-09T04:59:41.869792Z","shell.execute_reply.started":"2022-02-09T04:59:41.864751Z","shell.execute_reply":"2022-02-09T04:59:41.868424Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# Adding correct predictions to a list\ncorrect = []\nfor i in range(len(fin_val_preds)):\n    if fin_val_preds[i] == fin_val_lab[i]:\n        correct.append(fin_val_preds[i])","metadata":{"execution":{"iopub.status.busy":"2022-02-09T04:59:48.781504Z","iopub.execute_input":"2022-02-09T04:59:48.781804Z","iopub.status.idle":"2022-02-09T04:59:48.788273Z","shell.execute_reply.started":"2022-02-09T04:59:48.781776Z","shell.execute_reply":"2022-02-09T04:59:48.787269Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# Separating each prediction type into a separate list\ng_correct = [i for i in correct if i == 1]\nm_correct = [i for i in correct if i == 2]\np_correct = [i for i in correct if i == 3]\nno_correct = [i for i in correct if i == 0]\n\n# Getting the number of correct predictions for each tumor type\nnum_g_corr = len(g_correct)\nnum_m_corr = len(m_correct)\nnum_p_corr = len(p_correct)\nnum_no_corr = len(no_correct)","metadata":{"execution":{"iopub.status.busy":"2022-02-09T04:59:53.317349Z","iopub.execute_input":"2022-02-09T04:59:53.318233Z","iopub.status.idle":"2022-02-09T04:59:53.324875Z","shell.execute_reply.started":"2022-02-09T04:59:53.318184Z","shell.execute_reply":"2022-02-09T04:59:53.323758Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# Printing the number of different tumor types from predictions\nprint('Number of Correct Pituitary Tumors', num_p_corr)\nprint('Number of Correct Meningioma Tumors', num_m_corr)\nprint('Number of Correct Glioma Tumors', num_g_corr)\nprint('Number of Correct No Tumor Images', num_no_tumor)","metadata":{"execution":{"iopub.status.busy":"2022-02-09T04:59:56.212982Z","iopub.execute_input":"2022-02-09T04:59:56.213338Z","iopub.status.idle":"2022-02-09T04:59:56.221304Z","shell.execute_reply.started":"2022-02-09T04:59:56.213308Z","shell.execute_reply":"2022-02-09T04:59:56.220081Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"#### Number of Correct Pituitary Tumors: 37\n#### Number of Correct Meningioma Tumors: 18\n#### Number of Correct Glioma Tumors: 40\n#### Number of Correct No Tumor Images: 23","metadata":{}},{"cell_type":"code","source":"# Printing the percent of correct predictions for each tumor type\nprint('Percent Gliomas Correct:', str(np.round((num_g_corr/num_glioma)*100))+' %')\nprint('Percent Meningioma Correct:', str(np.round((num_m_corr/num_meningioma)*100))+' %')\nprint('Percent Pituitary Correct:', str(np.round((num_p_corr/num_pituitary)*100))+' %')\nprint('Percent No Tumor Correct:', str(np.round((num_no_corr/num_no_tumor)*100))+' %')","metadata":{"execution":{"iopub.status.busy":"2022-02-09T05:00:08.761680Z","iopub.execute_input":"2022-02-09T05:00:08.761956Z","iopub.status.idle":"2022-02-09T05:00:08.773345Z","shell.execute_reply.started":"2022-02-09T05:00:08.761926Z","shell.execute_reply":"2022-02-09T05:00:08.771956Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"### **Percentage of Correct Predictions for each Tumor Type**\n\n#### - Percent Gliomas Correct: 82.0 %\n#### - Percent Meningioma Correct: 37.0 %\n#### - Percent Pituitary Correct: 76.0 %\n#### - Percent No Tumor Correct: 91.0 %","metadata":{}},{"cell_type":"code","source":"# Plotting double bar graph to illustrate actual vs. predicted brain tumor type\n# Code structure for graph from https://www.geeksforgeeks.org/plotting-multiple-bar-charts-using-matplotlib-in-python/#_=_\nlabels = ['No Tumor', 'Pituitary', 'Meningioma', 'Glioma']\nactual = [num_no_tumor, num_pituitary, num_meningioma, num_glioma]\npredicted = [num_no_corr, num_p_corr, num_m_corr, num_g_corr]\nx_axis = np.arange(len(labels))\nplt.figure(figsize=(12,8))\nplt.bar(x_axis - 0.2, actual, 0.4, label='Actual Labels')\nplt.bar(x_axis + 0.2, predicted, 0.4, label = 'Predicted Labels')\n\nplt.xticks(x_axis, labels, fontsize=14)\nplt.xlabel(\"Brain Tumor Type\", fontsize=14)\nplt.ylabel(\"Number of MRIs\", fontsize=14)\nplt.title(\"Comparison of Actual vs. Predicted Brain Tumor Type\", fontsize=16)\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-09T05:26:04.308703Z","iopub.execute_input":"2022-02-09T05:26:04.308990Z","iopub.status.idle":"2022-02-09T05:26:04.553270Z","shell.execute_reply.started":"2022-02-09T05:26:04.308946Z","shell.execute_reply":"2022-02-09T05:26:04.552136Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}