{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-30T21:39:35.003544Z","iopub.execute_input":"2021-11-30T21:39:35.004576Z","iopub.status.idle":"2021-11-30T21:39:38.355370Z","shell.execute_reply.started":"2021-11-30T21:39:35.004532Z","shell.execute_reply":"2021-11-30T21:39:38.354447Z"},"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set random state for numpy operations \n# Directions for random seed setting for neural networks from https://machinelearningmastery.com/reproducible-results-neural-networks-keras/\nfrom numpy.random import seed\nseed(2)\n# Set random state for tensorflow operations\nfrom tensorflow.random import set_seed\nset_seed(3)\n# General imports\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import regularizers\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.models import load_model\nimport seaborn as sns\nfrom mlxtend.plotting import plot_decision_regions\nfrom sklearn.metrics import confusion_matrix\nimport cv2\nimport PIL","metadata":{"execution":{"iopub.status.busy":"2021-11-30T21:39:44.255565Z","iopub.execute_input":"2021-11-30T21:39:44.256499Z","iopub.status.idle":"2021-11-30T21:39:44.271446Z","shell.execute_reply.started":"2021-11-30T21:39:44.256451Z","shell.execute_reply":"2021-11-30T21:39:44.270194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualize_training_results(history):\n    '''\n    From https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/\n    \n    Input: keras history object (output from trained model)\n    '''\n    fig, (ax1, ax2) = plt.subplots(2, sharex=True)\n    fig.suptitle('Model Results')\n\n    # summarize history for accuracy\n    ax1.plot(history.history['acc'])\n    ax1.plot(history.history['val_acc'])\n    ax1.set_ylabel('Accuracy')\n    ax1.legend(['train', 'test'], loc='upper left')\n    # summarize history for loss\n    ax2.plot(history.history['loss'])\n    ax2.plot(history.history['val_loss'])\n    ax2.set_ylabel('Loss')\n    ax2.legend(['train', 'test'], loc='upper left')\n    \n    plt.xlabel('Epoch')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-30T21:39:48.006707Z","iopub.execute_input":"2021-11-30T21:39:48.007004Z","iopub.status.idle":"2021-11-30T21:39:48.015499Z","shell.execute_reply.started":"2021-11-30T21:39:48.006974Z","shell.execute_reply":"2021-11-30T21:39:48.014039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set up ImageDataGenerator\ntrain_imagegen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\n                                   zoom_range=([0.6,1]),\n                                   rotation_range=10,                           \n                                   brightness_range=([0.6, 1.5]),\n                                   horizontal_flip=True,\n                                   validation_split=0.06) # this will set aside a part of training set for validation data\ntest_imagegen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\n                                   zoom_range=([0.6,1]),\n                                   rotation_range=10,\n                                   brightness_range=([0.6,1.5]),\n                                   horizontal_flip=True)\n# Bring the data in\ntrain_generator = train_imagegen.flow_from_directory(\n                                    '../input/resortedbraintumorclassificationmridata/Brain_MRI_Tumor_Images/Training',\n                                    target_size=(200,200),\n                                    batch_size=20,\n                                    seed=42,\n                                    class_mode='binary',\n                                    subset='training')\n\ntest_generator = test_imagegen.flow_from_directory(\n                                    '../input/resortedbraintumorclassificationmridata/Brain_MRI_Tumor_Images/Testing',\n                                    target_size=(200,200),\n                                    batch_size=20,\n                                    seed=42,\n                                    class_mode='binary')\n\nval_generator = train_imagegen.flow_from_directory(\n                                    '../input/resortedbraintumorclassificationmridata/Brain_MRI_Tumor_Images/Training',\n                                    target_size=(200,200),\n                                    batch_size=20,\n                                    seed=42,\n                                    class_mode='binary',\n                                    subset='validation')","metadata":{"execution":{"iopub.status.busy":"2021-11-30T21:39:51.705773Z","iopub.execute_input":"2021-11-30T21:39:51.706858Z","iopub.status.idle":"2021-11-30T21:39:52.558326Z","shell.execute_reply.started":"2021-11-30T21:39:51.706764Z","shell.execute_reply":"2021-11-30T21:39:52.557615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Neural Network Model Iterations**","metadata":{}},{"cell_type":"markdown","source":"## **Baseline CNN Model**","metadata":{}},{"cell_type":"code","source":"# Building the first baseline model; structure is modified from one shown on:\n# https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\nbaseline = keras.Sequential()\nbaseline.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(200,200,3)))\nbaseline.add(layers.MaxPooling2D(2,2))\nbaseline.add(layers.Conv2D(64, (3,3), activation='relu'))\nbaseline.add(layers.MaxPooling2D(2,2))\n\nbaseline.add(layers.Flatten())\nbaseline.add(layers.Dense(128, activation='relu'))\nbaseline.add(layers.Dense(1, activation='sigmoid'))\n\nbaseline.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"baseline_results = baseline.fit_generator(train_generator,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=10,\n                                         validation_data=test_generator)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(baseline_results)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Analysis of Model**\n\nLooking at the above graphs, it is obvious that this first baseline cnn model is overfitting; accuracy for training data ends up at around 94%, whereas testing data ends up at around 65%. Additionally, the loss for testing data is fairly high; for training the loss ends up at 15%, and for testing it ends up at 69%. In the next model iteration, I will add another dense layer, which will hopefully help the model pick up on more patterns, and some dropout layers for a form of regularization.","metadata":{}},{"cell_type":"markdown","source":"## **Adding another Dense layer and Dropout layers**","metadata":{}},{"cell_type":"code","source":"# Adding another dense layer and a couple of dropout layers; structure is modified from one shown on:\n# https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\nlayers_drop = keras.Sequential()\nlayers_drop.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(200,200,3)))\nlayers_drop.add(layers.MaxPooling2D(2,2))\nlayers_drop.add(layers.Conv2D(64, (3,3), activation='relu'))\nlayers_drop.add(layers.MaxPooling2D(2,2))\n\nlayers_drop.add(layers.Flatten())\nlayers_drop.add(layers.Dense(128, activation='relu'))\nlayers_drop.add(layers.Dropout(0.3))\nlayers_drop.add(layers.Dense(64, activation='relu'))\nlayers_drop.add(layers.Dropout(0.3))\nlayers_drop.add(layers.Dense(1, activation='sigmoid'))\n\nlayers_drop.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fitting the model\nlayers_drop_results = layers_drop.fit_generator(train_generator,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=10,\n                                         validation_data=test_generator)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(layers_drop_results)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Analysis of Model**\n\nIn this iteration, training accuracy ends up at 93%, and testing ends up at 73%, so the model is overfitting, but less so than the baseline model. As for loss, training loss is 14% and testing loss is 65%, which is not drastically different from the last model. Adding another layer and dropout layers helped decrease overfitting. In the next model iteration I am going to account for the class imabalance, and the added layer and dropout layers might perform better in this iteration.","metadata":{}},{"cell_type":"markdown","source":"## **Accounting for class imbalance**","metadata":{}},{"cell_type":"code","source":"# Accounting for class imbalance; structure is modified from one shown on:\n# https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\n\nclass_ld = keras.Sequential()\nclass_ld.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(200,200,3)))\nclass_ld.add(layers.MaxPooling2D(2,2))\nclass_ld.add(layers.Conv2D(64, (3,3), activation='relu'))\nclass_ld.add(layers.MaxPooling2D(2,2))\n\nclass_ld.add(layers.Flatten())\nclass_ld.add(layers.Dense(128, activation='relu'))\nclass_ld.add(layers.Dropout(0.3))\nclass_ld.add(layers.Dense(64, activation='relu'))\nclass_ld.add(layers.Dropout(0.3))\nclass_ld.add(layers.Dense(1, activation='sigmoid'))\n\nclass_ld.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])\nweights = {0: 1, # TUMOR\n          1:6.255} # NO TUMOR \n# there are 6.255 times as many images of MRIs with tumors than without","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fitting the model\nclass_ld_results = class_ld.fit_generator(train_generator,\n                                          class_weight=weights,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=10,\n                                         validation_data=test_generator)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(class_ld_results)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Analysis of Model**\n\nIn this model iteration, training accuracy was about 89% and testing accuracy is about 57%, so the model is still overfitting compared to the last model. Loss for training is at around 51% and testing loss is around 99%. In terms of acuracy and loss, the model is doing worse than the previous model. However, recall has increased significantly, so it seems that adding class weights is beneficial to the model, even though it requires further tuning.","metadata":{}},{"cell_type":"markdown","source":"## **Adding another Convolution layer**","metadata":{}},{"cell_type":"code","source":"# Another Convolution layer; structure is modified from one shown on:\n# https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\nnp.random.seed(42)\nclass_con = keras.Sequential()\nclass_con.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(200,200,3)))\nclass_con.add(layers.MaxPooling2D(2,2))\nclass_con.add(layers.Conv2D(64, (3,3), activation='relu'))\nclass_con.add(layers.MaxPooling2D(2,2))\nclass_con.add(layers.Conv2D(128, (3,3), activation='relu'))\nclass_con.add(layers.MaxPooling2D(2,2))\n\nclass_con.add(layers.Flatten())\nclass_con.add(layers.Dense(128, activation='relu'))\nclass_con.add(layers.Dropout(0.3))\nclass_con.add(layers.Dense(64, activation='relu'))\nclass_con.add(layers.Dropout(0.3))\nclass_con.add(layers.Dense(1, activation='sigmoid'))\n\nclass_con.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])\nweights = {0: 1, \n          1:6.255}","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_con_results = class_con.fit_generator(train_generator,\n                                          class_weight=weights,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=10,\n                                         validation_data=test_generator)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(class_con_results)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Analysis of Model**\n\nTraining accuracy is at 89% while testing accuracy is at 50%, so model is still overfitting, slightly worse than the previous model. Training loss is 50%, and testing loss is 93%; training loss is 50% and testing loss is 93%, which is similar to the loss values of the previous model. In the next model iteration, I will see if changing the dimensions of the pooling layer will improve the model.","metadata":{}},{"cell_type":"markdown","source":"## **Adjusting the Pooling Strategy**","metadata":{}},{"cell_type":"code","source":"# Another Convolution layer; structure is modified from one shown on:\n# https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\nclass_pool = keras.Sequential()\nclass_pool.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(200,200,3)))\nclass_pool.add(layers.MaxPooling2D(2,2))\nclass_pool.add(layers.Conv2D(64, (3,3), activation='relu'))\nclass_pool.add(layers.MaxPooling2D(3,3))\nclass_pool.add(layers.Conv2D(128, (3,3), activation='relu'))\nclass_pool.add(layers.MaxPooling2D(5,5))\n\nclass_pool.add(layers.Flatten())\nclass_pool.add(layers.Dense(128, activation='relu'))\nclass_pool.add(layers.Dropout(0.3))\nclass_pool.add(layers.Dense(64, activation='relu'))\nclass_pool.add(layers.Dropout(0.3))\nclass_pool.add(layers.Dense(1, activation='sigmoid'))\n\nclass_pool.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])\nweights = {0: 1, # TUMOR\n          1:6.255} # NO TUMOR\n# there are 6.255 times as many images of MRIs with tumors than without","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_pool_results = class_pool.fit_generator(train_generator,\n                                          class_weight=weights,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=10,\n                                         validation_data=test_generator)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(class_pool_results)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Analysis of Model**\n\nTraining accuracy is at about 89%, and testing accuracy is at about 48%, so model is still overfitting quite a bit. Training loss is 48%, and testing loss is 101%; testing loss has increased quite a lot since the last model. Maybe increasing the pooling matrix is not beneficial to the model,so I will return the pooling strategy to all be (2,2) matrices and introduce padding, as this may help.. In this next model, I will introduce some padding to reduce image loss, to see if this improves model.","metadata":{}},{"cell_type":"markdown","source":"## **Model with Padding**","metadata":{}},{"cell_type":"code","source":"# Another Convolution layer; structure is modified from one shown on:\n# https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\nnp.random.seed(42)\nclass_pad = keras.Sequential()\nclass_pad.add(layers.Conv2D(32, (3,3), activation='relu', padding='same', input_shape=(200,200,3)))\nclass_pad.add(layers.MaxPooling2D(2,2))\nclass_pad.add(layers.Conv2D(64, (3,3), activation='relu', padding='same'))\nclass_pad.add(layers.MaxPooling2D(2,2))\nclass_pad.add(layers.Conv2D(128, (3,3), activation='relu', padding='same'))\nclass_pad.add(layers.MaxPooling2D(2,2))\n\nclass_pad.add(layers.Flatten())\nclass_pad.add(layers.Dense(128, activation='relu'))\nclass_pad.add(layers.Dropout(0.3))\nclass_pad.add(layers.Dense(64, activation='relu'))\nclass_pad.add(layers.Dropout(0.3))\nclass_pad.add(layers.Dense(1, activation='sigmoid'))\n\nclass_pad.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])\nweights = {0: 1, # TUMOR\n          1:6.255} # NO TUMOR\n# there are 6.255 times as many images of MRIs with tumors than without","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stop = [EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n            ModelCheckpoint(filepath='best_model.h5', monitor='val_loss',\n                           save_best_only=True)]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_pad_results = class_pad.fit_generator(train_generator,\n                                          class_weight=weights,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=10,\n                                         validation_data=test_generator)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(class_pad_results)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Analysis of Model**\n\nTraining accuracy is 89%, testing accuracy is 40%, so the model is overfitting more so than in the \"Adding another Convolutional layer\" model, which is identical to this one excpet for the padding. Training loss is 50% and testing loss is 129%; testing loss increased significantly from the \"Adding another Convolutional Layer\" model. It looks like this strategy of padding is making the model worse, so I will remove it. Additionally, because loss and overfitting is a big problem, I am going to try decreasing network size and introducing early stopping, so that the weights of the epoch with the lowest testing loss will be saved to the model.","metadata":{}},{"cell_type":"markdown","source":"## **Model without Padding, a deleted Dense layer, Early Stopping, and more Epochs**","metadata":{}},{"cell_type":"code","source":"# Another Convolution layer; structure is modified from one shown on:\n# https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\nclass_ee = keras.Sequential()\nclass_ee.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(200,200,3)))\nclass_ee.add(layers.MaxPooling2D(2,2))\nclass_ee.add(layers.Conv2D(64, (3,3), activation='relu'))\nclass_ee.add(layers.MaxPooling2D(2,2))\nclass_ee.add(layers.Conv2D(128, (3,3), activation='relu'))\nclass_ee.add(layers.MaxPooling2D(2,2))\n\nclass_ee.add(layers.Flatten())\nclass_ee.add(layers.Dense(128, activation='relu'))\nclass_ee.add(layers.Dropout(0.3))\nclass_ee.add(layers.Dense(1, activation='sigmoid'))\n\nclass_ee.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])\nweights = {0: 1, # TUMOR\n          1:6.255} # NO TUMOR\n# there are 6.255 times as many images of MRIs with tumors than without","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stop2 = [EarlyStopping(monitor='val_loss', patience=12, restore_best_weights=True),\n            ModelCheckpoint(filepath='best_model.h5', monitor='val_loss',\n                           save_best_only=True)]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_ee_results = class_ee.fit_generator(train_generator,\n                                          class_weight=weights,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=50,\n                                         validation_data=test_generator)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(class_ee_results)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Analysis of Model**\n\nTraining accuracy of the best epoch is around 88%, and testing accuracy is around 50%. Training loss is around 60% and testing loss is around 113%. Testing accuracy has improved by 10% since the last model, and testing loss has decreased by about sixteen percentage points, so removing a dense layer seems to be a slight improvement. I will try batch normalization to see if this helps train the model faster.","metadata":{}},{"cell_type":"markdown","source":"## **Model with Batch Normalization** ","metadata":{}},{"cell_type":"code","source":"# Another Convolution layer; structure is modified from one shown on:\n# https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\nclass_n = keras.Sequential()\nclass_n.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(200,200,3)))\nclass_n.add(layers.BatchNormalization())\nclass_n.add(layers.MaxPooling2D(2,2))\nclass_n.add(layers.Conv2D(64, (3,3), activation='relu'))\nclass_n.add(layers.BatchNormalization())\nclass_n.add(layers.MaxPooling2D(2,2))\nclass_n.add(layers.Conv2D(128, (3,3), activation='relu'))\nclass_n.add(layers.BatchNormalization())\nclass_n.add(layers.MaxPooling2D(2,2))\n\nclass_n.add(layers.Flatten())\nclass_n.add(layers.Dense(128, activation='relu'))\nclass_n.add(layers.Dropout(0.3))\nclass_n.add(layers.Dense(1, activation='sigmoid'))\n\nclass_n.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])\nweights = {0: 1, # TUMOR\n          1:6.255} # NO TUMOR\n# there are 6.255 times as many images of MRIs with tumors than without","metadata":{"execution":{"iopub.status.busy":"2021-11-30T22:05:43.637707Z","iopub.execute_input":"2021-11-30T22:05:43.638052Z","iopub.status.idle":"2021-11-30T22:05:43.984780Z","shell.execute_reply.started":"2021-11-30T22:05:43.638019Z","shell.execute_reply":"2021-11-30T22:05:43.983837Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_n_results = class_n.fit_generator(train_generator,\n                                          class_weight=weights,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=20,\n                                         callbacks=early_stop2,\n                                         validation_data=test_generator)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(class_n_results)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Analysis of Model**\n\nThe best model from epoch 14 had a training accuracy of around 94%, a testing accuracy of around 70%, a training loss of 30%, and a testing loss of around 84%. Accuracy and loss for both training and testing data is much improved since the last model and it is less overfit, so batch normalization is definitely an improvement. \nBecause batch normalization makes the network more stable, it is possible to use larger learning rates, which could potentially help the model reach optimal accuracy and minimal loss more quickly, so that is what I will try next.","metadata":{}},{"cell_type":"markdown","source":"## **Using a Bigger Learning Rate since I am using Batch Normalization**","metadata":{}},{"cell_type":"code","source":"adam_mlr = keras.optimizers.Adam(epsilon=0.01)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Another Convolution layer; structure is modified from one shown on:\n# https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\nclass_na = keras.Sequential()\nclass_na.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(200,200,3)))\nclass_na.add(layers.BatchNormalization())\nclass_na.add(layers.MaxPooling2D(2,2))\nclass_na.add(layers.Conv2D(64, (3,3), activation='relu'))\nclass_na.add(layers.BatchNormalization())\nclass_na.add(layers.MaxPooling2D(2,2))\nclass_na.add(layers.Conv2D(128, (3,3), activation='relu'))\nclass_na.add(layers.BatchNormalization())\nclass_na.add(layers.MaxPooling2D(2,2))\n\nclass_na.add(layers.Flatten())\nclass_na.add(layers.Dense(128, activation='relu'))\nclass_na.add(layers.Dropout(0.3))\nclass_na.add(layers.Dense(1, activation='sigmoid'))\n\nclass_na.compile(loss='binary_crossentropy',\n                optimizer=adam_mlr,\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])\nweights = {0: 1, # TUMOR\n          1:6.255} # NO TUMOR\n# there are 6.255 times as many images of MRIs with tumors than without","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_na_results = class_na.fit_generator(train_generator,\n                                          class_weight=weights,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=20,\n                                         callbacks=early_stop2,\n                                         validation_data=test_generator)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(class_na_results)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Analysis of Model**\n\nIn the best epoch of the model (epoch 20) training accuracy is 95% while testing accuracy is 74%. Training loss is 33%, while testing loss is 55%. Testing accuracy is higher by four percentage points than the last model, and loss has decreased by about 30%! Additionally, testing recall is 93%, which is important for the context of this problem. In the next iteration I am going to see if adding more dropout layers will be beneficial.","metadata":{}},{"cell_type":"markdown","source":"## **Model with Batch Normalization and more Dropout Layers**","metadata":{}},{"cell_type":"code","source":"# Another Convolution layer; structure is modified from one shown on:\n# https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\nclass_nd = keras.Sequential()\n\nclass_nd.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(200,200,3)))\nclass_nd.add(layers.BatchNormalization())\nclass_nd.add(layers.MaxPooling2D(2,2))\nclass_nd.add(layers.Dropout(0.25))\n\nclass_nd.add(layers.Conv2D(64, (3,3), activation='relu'))\nclass_nd.add(layers.BatchNormalization())\nclass_nd.add(layers.MaxPooling2D(2,2))\nclass_nd.add(layers.Dropout(0.25))\n\nclass_nd.add(layers.Conv2D(128, (3,3), activation='relu'))\nclass_nd.add(layers.BatchNormalization())\nclass_nd.add(layers.MaxPooling2D(2,2))\nclass_nd.add(layers.Dropout(0.25))\n\nclass_nd.add(layers.Flatten())\nclass_nd.add(layers.Dense(128, activation='relu'))\nclass_nd.add(layers.Dropout(0.4))\nclass_nd.add(layers.Dense(1, activation='sigmoid'))\n\nclass_nd.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])\nweights = {0: 1, # TUMOR\n          1:6.255} # NO TUMOR\n# there are 6.255 times as many images of MRIs with tumors than without","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_nd_results = class_nd.fit_generator(train_generator,\n                                          class_weight=weights,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=20,\n                                          callbacks=early_stop2,\n                                         validation_data=test_generator)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(class_nd_results)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Analysis of Model**\n\nTraining accuracy of the best epoch is 91% while testing accuracy is 73%. Training loss is 56% while testing loss is 82%. This model is similar to the last one, except for the fact that training loss is significantly increased. The dropout layers added after each max pooling step may not be particularly beneficial to the model.","metadata":{}},{"cell_type":"markdown","source":"## **Going back to Baseline, adding Class Weights**","metadata":{}},{"cell_type":"code","source":"base_class = keras.Sequential()\nbase_class.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(200,200,3)))\nbase_class.add(layers.BatchNormalization())\nbase_class.add(layers.MaxPooling2D(2,2))\n\nbase_class.add(layers.Conv2D(64, (3,3), activation='relu'))\nbase_class.add(layers.BatchNormalization())\nbase_class.add(layers.MaxPooling2D(2,2))\n\nbase_class.add(layers.Flatten())\nbase_class.add(layers.Dense(128, activation='relu'))\nbase_class.add(layers.Dropout(0.3))\nbase_class.add(layers.BatchNormalization())\nbase_class.add(layers.Dense(1, activation='sigmoid'))\n\nbase_class.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])\nclass_weights2 = {0:1,\n                 1:6.255}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_class_results =base_class.fit_generator(train_generator,\n                                        class_weight = class_weights2,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=20,\n                                        callbacks=early_stop2,\n                                         validation_data=test_generator)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Analysis of Model**\n\nThe epoch with the lowest testing loss has a training accuracy of around 86% and a testing accuracy of around 62%, with a training loss of 55% and a testing loss of 76%. Testing recall is 76%. These results are worse than the last model iteration, so it looks like adding class weights did not help in this case.","metadata":{}},{"cell_type":"markdown","source":"## **Using the Pre-Trained VGG-19 Weights (this is my FSM)**","metadata":{}},{"cell_type":"code","source":"from keras.applications.vgg19 import VGG19\ncnn_vgg = VGG19(weights='imagenet',\n               include_top=False,\n               input_shape=(200,200,3))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn_vgg.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build first model using pretrained VGG 19 as first layer, and then some dense layers on top\npretrained = keras.Sequential()\npretrained.add(cnn_vgg)\npretrained.add(layers.Flatten())\npretrained.add(layers.Dense(128, activation='relu'))\npretrained.add(layers.Dense(1, activation='sigmoid'))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Freeze_Pretrained_Base(pretrain, network):\n    pretrain.trainable = False\n    for layer in network.layers:\n        print(layer.name, layer.trainable)\n    print(len(network.trainable_weights))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Freeze_Pretrained_Base(cnn_vgg, pretrained)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\npretrained.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])\n\npretrained_results = pretrained.fit_generator(train_generator,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=20,\n                                        callbacks= early_stop2,\n                                         validation_data=test_generator)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(pretrained_results)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Analysis of Model**\n\nThe epoch with the lowest loss had a training accuracy of ~98% and a loss of ~4%, while the testing data had an accuracy of ~93% and a loss of ~21%! This is the best model yet! Additionally, testing recall is ~95%, which means that false negatives are being minimized. Using the VGG19 pretrained weights was a game changer! However, it would be great if the testing loss could be just a bit lower, so in the next model iteration I will use the SGD optimizer with momentum, since it is known for rapidly decreasing loss.","metadata":{}},{"cell_type":"markdown","source":"## **Unfreezing Layers in the Pretrained VGG-19 Network**","metadata":{}},{"cell_type":"code","source":"# Build first model using pretrained VGG 19 as first layer, and then some dense layers on top\nb5c1c2 = keras.Sequential()\nb5c1c2.add(cnn_vgg)\nb5c1c2.add(layers.Flatten())\nb5c1c2.add(layers.Dense(128, activation='relu'))\nb5c1c2.add(layers.Dense(1, activation='sigmoid'))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unfreeze = ['block5_conv1', 'block5_conv2']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Re-freezing everything except for the last layer of the pretrained CNN\n# Code structure from https://github.com/learn-co-curriculum/dsc-using-pretrained-networks-codealong\ndef Unfreeze_Layers(pretrain, layer_list):\n    pretrain.trainable = True\n    for layer in  pretrain.layers:\n        if layer.name in layer_list:\n            layer.trainable = True\n        else:\n            layer.trainable = False\n        \n    for layer in pretrain.layers:\n        print(layer.name, layer.trainable)\n    print(len(pretrain.trainable_weights))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Unfreeze_Layers(cnn_vgg, unfreeze)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"b5c1c2.compile(loss='binary_crossentropy',\n                optimizer='adam',\n                metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])\n\nb5c1c2_results = b5c1c2.fit_generator(train_generator,\n                                         steps_per_epoch=2699/20,# number of samples / batch size\n                                         epochs=20,\n                                        callbacks= early_stop2,\n                                         validation_data=test_generator)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Analysis of Model**\n\nThe epoch with the lowest testing los has a trining accuracy of 98% and a testing accuracy of 92%, with a training loss of 5% and a testing loss of 27%. Testing recall is 75%. Other than recall, the results are similar to the previous model; maybe including class weights will help improve the model.","metadata":{}},{"cell_type":"markdown","source":"## **Incorporating Class Weights into Pretrained VGG19 model**","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}